{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zone-Level Occupancy Data Transformation\n",
    "\n",
    "This notebook creates **aggregated zone-level occupancy data** by combining all lots within each zone (e.g., \"Green 2\").\n",
    "\n",
    "**Why Zone-Level?**\n",
    "- The raw AMP data has 62 specific lot names (e.g., \"Green 2 KMac Lot\")\n",
    "- But lot_mapping has 186 lots organized into 28 aggregated zones\n",
    "- Only 46 lots have AMP data for occupancy\n",
    "- Aggregating to zones gives more robust predictions with more data per zone\n",
    "\n",
    "**Approach:**\n",
    "1. Load raw AMP session data (lot-level)\n",
    "2. Map lot names to aggregated zones using lot_mapping\n",
    "3. Sum occupancy across all lots in each zone for each hour\n",
    "4. Add temporal, calendar, and weather features\n",
    "5. Create train/val/test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ZONE-LEVEL OCCUPANCY DATA TRANSFORMATION\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ZONE-LEVEL OCCUPANCY DATA TRANSFORMATION\")\n",
    "print(\"=\"*80)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load and Map AMP Data to Zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading AMP session data...\n",
      "Total parking sessions: 1,683,018\n",
      "Date range: 2020-08-10 07:51:00 to 2025-10-31 14:57:00\n",
      "Unique AMP zones: 62\n",
      "\n",
      "Total lots in mapping: 186\n",
      "Aggregated zones: 28\n"
     ]
    }
   ],
   "source": [
    "# Load preprocessed AMP data\n",
    "print(\"Loading AMP session data...\")\n",
    "amp = pd.read_csv('../../data/processed/amp_preprocessed_clean.csv', parse_dates=['Start_Date', 'End_Date'])\n",
    "print(f\"Total parking sessions: {len(amp):,}\")\n",
    "print(f\"Date range: {amp['Start_Date'].min()} to {amp['Start_Date'].max()}\")\n",
    "print(f\"Unique AMP zones: {amp['Zone'].nunique()}\")\n",
    "\n",
    "# Load lot mapping\n",
    "lot_mapping = pd.read_csv('../../data/lot_mapping_enhanced_with_coords.csv')\n",
    "print(f\"\\nTotal lots in mapping: {len(lot_mapping)}\")\n",
    "print(f\"Aggregated zones: {lot_mapping['Zone_Name'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapped 57 AMP zone names to aggregated zones\n",
      "\n",
      "Sample mappings:\n",
      "  'Green 2 KMac Lot' -> 'Green 2'\n",
      "  'Green 2 McAllister' -> 'Green 2'\n",
      "  'McCoy Hall Lot: Football General Parking' -> 'Green 1'\n",
      "  'Bustad - AMP Marked spots' -> 'Green 1'\n",
      "  'Green 1 Bustad Lot' -> 'Green 1'\n",
      "  'Green 1 PACCAR South' -> 'Green 1'\n",
      "  'McCluskey Services Visitor Spaces' -> 'Buisness Parking'\n",
      "  'Wilson Road on Street Meters' -> 'Green 1'\n",
      "  'Perham Rear Entrance AMP spot' -> 'Green 5'\n",
      "  'Regents: AMP Marked Spot' -> 'Green 5'\n"
     ]
    }
   ],
   "source": [
    "# Create mapping from AMP zone names -> aggregated Zone_Name\n",
    "amp_to_zone = {}\n",
    "\n",
    "for _, row in lot_mapping.iterrows():\n",
    "    zone_name = row['Zone_Name']\n",
    "    alt_desc = row.get('alternative_location_description')\n",
    "    \n",
    "    if pd.notna(alt_desc):\n",
    "        # Map each alternative name to this zone\n",
    "        for name in str(alt_desc).split('|'):\n",
    "            name = name.strip()\n",
    "            if name:\n",
    "                amp_to_zone[name] = zone_name\n",
    "\n",
    "print(f\"Mapped {len(amp_to_zone)} AMP zone names to aggregated zones\")\n",
    "print(\"\\nSample mappings:\")\n",
    "for amp_zone, zone in list(amp_to_zone.items())[:10]:\n",
    "    print(f\"  '{amp_zone}' -> '{zone}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sessions mapped to zones: 1,659,706\n",
      "Unmapped sessions: 23,312\n",
      "\n",
      "Unmapped AMP zones:\n",
      "Zone\n",
      "Green 3: Washington St                                            11706\n",
      "Green 3: Football General Parking                                  6267\n",
      "Don't Activate: Lighty East Meters                                 4099\n",
      "PACCAR: (Don't Activate)                                            568\n",
      "Spring Street Lot                                                   482\n",
      "B St Lots: Football General Parking                                 159\n",
      "Testing Zone with an extra long label to read (Don't activate)       22\n",
      "Disability Parking CUE (Don't Activate)                               9\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Proceeding with 1,659,706 sessions across 19 zones\n"
     ]
    }
   ],
   "source": [
    "# Map AMP sessions to aggregated zones\n",
    "amp['Aggregated_Zone'] = amp['Zone'].map(amp_to_zone)\n",
    "\n",
    "# Check coverage\n",
    "unmapped = amp[amp['Aggregated_Zone'].isna()]\n",
    "print(f\"Sessions mapped to zones: {(~amp['Aggregated_Zone'].isna()).sum():,}\")\n",
    "print(f\"Unmapped sessions: {len(unmapped):,}\")\n",
    "\n",
    "if len(unmapped) > 0:\n",
    "    print(\"\\nUnmapped AMP zones:\")\n",
    "    print(unmapped['Zone'].value_counts().head(10))\n",
    "\n",
    "# Drop unmapped sessions\n",
    "amp = amp[amp['Aggregated_Zone'].notna()].copy()\n",
    "print(f\"\\nProceeding with {len(amp):,} sessions across {amp['Aggregated_Zone'].nunique()} zones\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create Hourly Time Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating hourly time grid...\n",
      "Zone-hour grid created: 870,504 combinations\n",
      "  19 zones\n",
      "  1909 days\n",
      "  24 hours per day\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating hourly time grid...\")\n",
    "\n",
    "start_date = amp['Start_Date'].min().date()\n",
    "end_date = amp['Start_Date'].max().date()\n",
    "\n",
    "date_range = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "hours = range(24)\n",
    "aggregated_zones = amp['Aggregated_Zone'].unique()\n",
    "\n",
    "# Create zone-hour grid\n",
    "zone_hour_grid = pd.MultiIndex.from_product(\n",
    "    [aggregated_zones, date_range, hours],\n",
    "    names=['Zone', 'date', 'hour']\n",
    ").to_frame(index=False)\n",
    "\n",
    "zone_hour_grid['interval_start'] = (\n",
    "    pd.to_datetime(zone_hour_grid['date']) +\n",
    "    pd.to_timedelta(zone_hour_grid['hour'], unit='h')\n",
    ")\n",
    "zone_hour_grid['interval_end'] = zone_hour_grid['interval_start'] + pd.Timedelta(hours=1)\n",
    "\n",
    "print(f\"Zone-hour grid created: {len(zone_hour_grid):,} combinations\")\n",
    "print(f\"  {len(aggregated_zones)} zones\")\n",
    "print(f\"  {len(date_range)} days\")\n",
    "print(f\"  24 hours per day\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Calculate Zone-Level Occupancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating zone-level occupancy...\n",
      "This may take several minutes...\n",
      "Processing zone 5/19: Green 5\n",
      "Processing zone 10/19: Orange 2\n",
      "Processing zone 15/19: Authorized Vehicles Only\n",
      "\n",
      "Zone-level occupancy data created: 870,504 zone-hour records\n",
      "Unique zones: 19\n"
     ]
    }
   ],
   "source": [
    "print(\"Calculating zone-level occupancy...\")\n",
    "print(\"This may take several minutes...\")\n",
    "\n",
    "occupancy_list = []\n",
    "zone_count = 0\n",
    "\n",
    "for zone in aggregated_zones:\n",
    "    zone_count += 1\n",
    "    if zone_count % 5 == 0:\n",
    "        print(f\"Processing zone {zone_count}/{len(aggregated_zones)}: {zone}\")\n",
    "    \n",
    "    # Filter sessions for this zone\n",
    "    zone_sessions = amp[amp['Aggregated_Zone'] == zone].copy()\n",
    "    zone_grid = zone_hour_grid[zone_hour_grid['Zone'] == zone].copy()\n",
    "    \n",
    "    # For each hour, count overlapping sessions\n",
    "    for idx, row in zone_grid.iterrows():\n",
    "        interval_start = row['interval_start']\n",
    "        interval_end = row['interval_end']\n",
    "        \n",
    "        # Count active sessions during this hour\n",
    "        active_sessions = zone_sessions[\n",
    "            (zone_sessions['Start_Date'] < interval_end) &\n",
    "            (zone_sessions['End_Date'] > interval_start)\n",
    "        ]\n",
    "        \n",
    "        occupancy_list.append({\n",
    "            'Zone': zone,\n",
    "            'date': row['date'],\n",
    "            'hour': row['hour'],\n",
    "            'datetime': interval_start,\n",
    "            'occupancy_count': len(active_sessions)\n",
    "        })\n",
    "\n",
    "occupancy_df = pd.DataFrame(occupancy_list)\n",
    "print(f\"\\nZone-level occupancy data created: {len(occupancy_df):,} zone-hour records\")\n",
    "print(f\"Unique zones: {occupancy_df['Zone'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Add Temporal Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding temporal features...\n",
      "  Temporal features added\n"
     ]
    }
   ],
   "source": [
    "print(\"Adding temporal features...\")\n",
    "\n",
    "occupancy_df['year'] = occupancy_df['datetime'].dt.year\n",
    "occupancy_df['month'] = occupancy_df['datetime'].dt.month\n",
    "occupancy_df['day'] = occupancy_df['datetime'].dt.day\n",
    "occupancy_df['day_of_week'] = occupancy_df['datetime'].dt.dayofweek\n",
    "occupancy_df['is_weekend'] = (occupancy_df['day_of_week'] >= 5).astype(int)\n",
    "\n",
    "def categorize_time_of_day(hour):\n",
    "    if 0 <= hour < 6:\n",
    "        return 'Late Night'\n",
    "    elif 6 <= hour < 12:\n",
    "        return 'Morning'\n",
    "    elif 12 <= hour < 18:\n",
    "        return 'Afternoon'\n",
    "    elif 18 <= hour < 22:\n",
    "        return 'Evening'\n",
    "    else:\n",
    "        return 'Night'\n",
    "\n",
    "occupancy_df['time_of_day'] = occupancy_df['hour'].apply(categorize_time_of_day)\n",
    "print(\"  Temporal features added\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Merge Calendar Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging calendar events...\n",
      "  Calendar events merged\n"
     ]
    }
   ],
   "source": [
    "print(\"Merging calendar events...\")\n",
    "\n",
    "games = pd.read_csv('../../data/football_games.csv')\n",
    "calendar = pd.read_csv('../../data/academic_calendar.csv')\n",
    "\n",
    "games['Date'] = pd.to_datetime(games['Date'])\n",
    "calendar['Start_Date'] = pd.to_datetime(calendar['Start_Date']).dt.normalize()\n",
    "calendar['End_Date'] = pd.to_datetime(calendar['End_Date']).dt.normalize()\n",
    "\n",
    "occupancy_df['date'] = pd.to_datetime(occupancy_df['date'])\n",
    "game_dates = games['Date'].dt.normalize()\n",
    "occupancy_df['is_game_day'] = occupancy_df['date'].isin(game_dates).astype(int)\n",
    "\n",
    "# Calendar events\n",
    "for event_type in ['Dead_Week', 'Finals_Week', 'Spring_Break', 'Thanksgiving_Break', 'Winter_Break']:\n",
    "    event_periods = calendar[calendar['Event_Type'] == event_type]\n",
    "    occupancy_df[f'is_{event_type.lower()}'] = 0\n",
    "    \n",
    "    for _, period in event_periods.iterrows():\n",
    "        mask = (occupancy_df['date'] >= period['Start_Date']) & \\\n",
    "               (occupancy_df['date'] <= period['End_Date'])\n",
    "        occupancy_df.loc[mask, f'is_{event_type.lower()}'] = 1\n",
    "\n",
    "occupancy_df['is_any_break'] = (\n",
    "    occupancy_df['is_spring_break'] |\n",
    "    occupancy_df['is_thanksgiving_break'] |\n",
    "    occupancy_df['is_winter_break']\n",
    ").astype(int)\n",
    "\n",
    "print(\"  Calendar events merged\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Merge Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging weather data...\n",
      "  Weather data merged\n"
     ]
    }
   ],
   "source": [
    "print(\"Merging weather data...\")\n",
    "\n",
    "weather = pd.read_csv('../../data/weather_pullman_2020_2025.csv')\n",
    "weather['date'] = pd.to_datetime(weather['date']).dt.normalize()\n",
    "\n",
    "occupancy_df = occupancy_df.merge(weather, left_on='date', right_on='date', how='left')\n",
    "print(\"  Weather data merged\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Add Zone Capacity and Availability Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding zone capacity...\n",
      "  Capacity and availability metrics added\n"
     ]
    }
   ],
   "source": [
    "print(\"Adding zone capacity...\")\n",
    "\n",
    "# Calculate total capacity per zone from lot_mapping\n",
    "zone_capacity = lot_mapping.groupby('Zone_Name')['capacity'].sum().to_dict()\n",
    "\n",
    "occupancy_df['Max_Capacity'] = occupancy_df['Zone'].map(zone_capacity)\n",
    "\n",
    "# For zones without capacity, estimate from 95th percentile\n",
    "zones_without_cap = occupancy_df[occupancy_df['Max_Capacity'].isna()]['Zone'].unique()\n",
    "if len(zones_without_cap) > 0:\n",
    "    print(f\"  Estimating capacity for {len(zones_without_cap)} zones without data...\")\n",
    "    for zone in zones_without_cap:\n",
    "        zone_data = occupancy_df[occupancy_df['Zone'] == zone]['occupancy_count']\n",
    "        estimated_cap = max(zone_data.quantile(0.95), 10)\n",
    "        occupancy_df.loc[occupancy_df['Zone'] == zone, 'Max_Capacity'] = estimated_cap\n",
    "\n",
    "# Calculate availability metrics\n",
    "occupancy_df['occupancy_ratio'] = occupancy_df['occupancy_count'] / occupancy_df['Max_Capacity'].replace(0, 1)\n",
    "occupancy_df['available_spaces'] = (occupancy_df['Max_Capacity'] - occupancy_df['occupancy_count']).clip(lower=0)\n",
    "occupancy_df['is_near_full'] = (occupancy_df['occupancy_ratio'] >= 0.85).astype(int)\n",
    "occupancy_df['is_very_full'] = (occupancy_df['occupancy_ratio'] >= 0.95).astype(int)\n",
    "\n",
    "print(\"  Capacity and availability metrics added\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Create Train/Validation/Test Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating train/validation/test splits...\n",
      "Training: 675,811 records (2020-08-10 00:00:00 to 2024-08-31 00:00:00)\n",
      "Validation: 124,488 records (2024-08-31 00:00:00 to 2025-05-31 00:00:00)\n",
      "Test: 70,205 records (2025-05-31 00:00:00 to 2025-10-31 00:00:00)\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating train/validation/test splits...\")\n",
    "\n",
    "train_end = pd.Timestamp('2024-08-31')\n",
    "val_end = pd.Timestamp('2025-05-31')\n",
    "\n",
    "occupancy_train = occupancy_df[occupancy_df['datetime'] <= train_end].copy()\n",
    "occupancy_val = occupancy_df[(occupancy_df['datetime'] > train_end) & (occupancy_df['datetime'] <= val_end)].copy()\n",
    "occupancy_test = occupancy_df[occupancy_df['datetime'] > val_end].copy()\n",
    "\n",
    "print(f\"Training: {len(occupancy_train):,} records ({occupancy_train['date'].min()} to {occupancy_train['date'].max()})\")\n",
    "print(f\"Validation: {len(occupancy_val):,} records ({occupancy_val['date'].min()} to {occupancy_val['date'].max()})\")\n",
    "print(f\"Test: {len(occupancy_test):,} records ({occupancy_test['date'].min()} to {occupancy_test['date'].max()})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Save Zone-Level Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving zone-level occupancy data...\n",
      "Full zone-level data saved: 870,504 records\n",
      "Train set saved: 675,811 records\n",
      "Validation set saved: 124,488 records\n",
      "Test set saved: 70,205 records\n"
     ]
    }
   ],
   "source": [
    "print(\"Saving zone-level occupancy data...\")\n",
    "\n",
    "occupancy_df.to_csv('../../data/processed/occupancy_zone_level_full.csv', index=False)\n",
    "occupancy_train.to_csv('../../data/processed/occupancy_zone_level_train.csv', index=False)\n",
    "occupancy_val.to_csv('../../data/processed/occupancy_zone_level_val.csv', index=False)\n",
    "occupancy_test.to_csv('../../data/processed/occupancy_zone_level_test.csv', index=False)\n",
    "\n",
    "print(f\"Full zone-level data saved: {len(occupancy_df):,} records\")\n",
    "print(f\"Train set saved: {len(occupancy_train):,} records\")\n",
    "print(f\"Validation set saved: {len(occupancy_val):,} records\")\n",
    "print(f\"Test set saved: {len(occupancy_test):,} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ZONE-LEVEL DATA SUMMARY\n",
      "================================================================================\n",
      "Aggregated zones: 19\n",
      "Average occupancy: 5.9 cars\n",
      "Date range: 2020-08-10 00:00:00 to 2025-10-31 00:00:00\n",
      "\n",
      "Top 10 busiest zones:\n",
      "Zone\n",
      "Paid        71.731295\n",
      "Green 5     12.515824\n",
      "Green 1      9.190959\n",
      "Green 3      6.563777\n",
      "Green 2      2.870133\n",
      "Yellow 3     1.624956\n",
      "Yellow 1     1.576283\n",
      "Red 5        1.174611\n",
      "Yellow 2     1.120547\n",
      "Green 4      0.868518\n",
      "Name: occupancy_count, dtype: float64\n",
      "\n",
      "================================================================================\n",
      "DONE!\n",
      "================================================================================\n",
      "\n",
      "Next step: Train zone-level model in notebook 04\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"ZONE-LEVEL DATA SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Aggregated zones: {occupancy_df['Zone'].nunique()}\")\n",
    "print(f\"Average occupancy: {occupancy_df['occupancy_count'].mean():.1f} cars\")\n",
    "print(f\"Date range: {occupancy_df['date'].min()} to {occupancy_df['date'].max()}\")\n",
    "print(\"\\nTop 10 busiest zones:\")\n",
    "print(occupancy_df.groupby('Zone')['occupancy_count'].mean().sort_values(ascending=False).head(10))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DONE!\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nNext step: Train zone-level model in notebook 04\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
