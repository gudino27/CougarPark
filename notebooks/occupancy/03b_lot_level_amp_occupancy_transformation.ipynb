{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lot-Level Occupancy Data Transformation (AMP Session-Based)\n",
    "\n",
    "This notebook creates **lot-level occupancy estimates** using AMP parking session data.\n",
    "\n",
    "**Why AMP Session-Based?**\n",
    "- AMP session data covers 59 specific parking zones/lots\n",
    "- Directly measures actual parking sessions (start/end times)\n",
    "- More accurate occupancy counts than LPR scans\n",
    "- Complements LPR-based approach (notebook 04) which covers 185 lots\n",
    "\n",
    "**Approach:**\n",
    "1. Load AMP parking session data\n",
    "2. Count active sessions per hour for each specific zone\n",
    "3. Add temporal, calendar, and weather features\n",
    "4. Map capacity data to specific zones\n",
    "5. Create train/val/test splits\n",
    "\n",
    "**Note:** This creates lot-level data parallel to zone-level aggregations. The 59 specific zones map to the 28 aggregated zones used elsewhere in the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"LOT-LEVEL OCCUPANCY TRANSFORMATION (AMP SESSION-BASED)\")\n",
    "print(\"=\"*80)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load AMP Session Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading AMP session data...\")\n",
    "amp = pd.read_csv('../../data/processed/amp_preprocessed_clean.csv', parse_dates=['Start_Date', 'End_Date'])\n",
    "print(f\"Total parking sessions: {len(amp):,}\")\n",
    "print(f\"Date range: {amp['Start_Date'].min()} to {amp['Start_Date'].max()}\")\n",
    "\n",
    "# The 'Zone' column contains SPECIFIC lot names (59 unique)\n",
    "print(f\"\\nSpecific zones in raw data: {amp['Zone'].nunique()}\")\n",
    "print(\"\\nTop 10 specific zones:\")\n",
    "print(amp['Zone'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create Hourly Time Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating hourly time grid...\")\n",
    "\n",
    "start_date = amp['Start_Date'].min().date()\n",
    "end_date = amp['Start_Date'].max().date()\n",
    "\n",
    "# Create all (date, hour) combinations\n",
    "date_range = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "hours = range(24)\n",
    "\n",
    "time_grid = pd.MultiIndex.from_product(\n",
    "    [date_range, hours],\n",
    "    names=['date', 'hour']\n",
    ").to_frame(index=False)\n",
    "\n",
    "time_grid['datetime'] = (\n",
    "    pd.to_datetime(time_grid['date']) +\n",
    "    pd.to_timedelta(time_grid['hour'], unit='h')\n",
    ")\n",
    "\n",
    "print(f\"Time grid created: {len(time_grid):,} hourly intervals\")\n",
    "print(f\"Intervals per day: {len(hours)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create Zone-Hour Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique specific zones (lot-level)\n",
    "specific_zones = amp['Zone'].unique()\n",
    "print(f\"{len(specific_zones)} specific zones (lot-level) will be processed\")\n",
    "\n",
    "# Create zone-hour grid\n",
    "print(\"\\nCreating zone-hour grid...\")\n",
    "zone_hour_grid = pd.MultiIndex.from_product(\n",
    "    [specific_zones, date_range, hours],\n",
    "    names=['Zone', 'date', 'hour']\n",
    ").to_frame(index=False)\n",
    "\n",
    "zone_hour_grid['interval_start'] = (\n",
    "    pd.to_datetime(zone_hour_grid['date']) +\n",
    "    pd.to_timedelta(zone_hour_grid['hour'], unit='h')\n",
    ")\n",
    "zone_hour_grid['interval_end'] = zone_hour_grid['interval_start'] + pd.Timedelta(hours=1)\n",
    "\n",
    "print(f\"Zone-hour grid created: {len(zone_hour_grid):,} combinations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Calculate Occupancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Calculating lot-level occupancy...\")\n",
    "\n",
    "occupancy_list = []\n",
    "zone_count = 0\n",
    "\n",
    "for zone in specific_zones:\n",
    "    zone_count += 1\n",
    "    if zone_count % 10 == 0:\n",
    "        print(f\"Processing zone {zone_count}/{len(specific_zones)}: {zone}\")\n",
    "\n",
    "    # Filter sessions for this specific zone\n",
    "    zone_sessions = amp[amp['Zone'] == zone].copy()\n",
    "    zone_grid = zone_hour_grid[zone_hour_grid['Zone'] == zone].copy()\n",
    "\n",
    "    # For each hour, count overlapping sessions\n",
    "    for idx, row in zone_grid.iterrows():\n",
    "        interval_start = row['interval_start']\n",
    "        interval_end = row['interval_end']\n",
    "\n",
    "        # Count active sessions during this hour\n",
    "        active_sessions = zone_sessions[\n",
    "            (zone_sessions['Start_Date'] < interval_end) &\n",
    "            (zone_sessions['End_Date'] > interval_start)\n",
    "        ]\n",
    "\n",
    "        occupancy_list.append({\n",
    "            'Zone': zone,\n",
    "            'date': row['date'],\n",
    "            'hour': row['hour'],\n",
    "            'datetime': interval_start,\n",
    "            'occupancy_count': len(active_sessions)\n",
    "        })\n",
    "\n",
    "occupancy_df = pd.DataFrame(occupancy_list)\n",
    "print(f\"\\nLot-level occupancy data created: {len(occupancy_df):,} zone-hour records\")\n",
    "print(f\"Unique specific zones: {occupancy_df['Zone'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Add Temporal Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Adding temporal features...\")\n",
    "occupancy_df['year'] = occupancy_df['datetime'].dt.year\n",
    "occupancy_df['month'] = occupancy_df['datetime'].dt.month\n",
    "occupancy_df['day'] = occupancy_df['datetime'].dt.day\n",
    "occupancy_df['day_of_week'] = occupancy_df['datetime'].dt.dayofweek\n",
    "occupancy_df['is_weekend'] = (occupancy_df['day_of_week'] >= 5).astype(int)\n",
    "\n",
    "def categorize_time_of_day(hour):\n",
    "    if 0 <= hour < 6:\n",
    "        return 'Late Night'\n",
    "    elif 6 <= hour < 12:\n",
    "        return 'Morning'\n",
    "    elif 12 <= hour < 18:\n",
    "        return 'Afternoon'\n",
    "    elif 18 <= hour < 22:\n",
    "        return 'Evening'\n",
    "    else:\n",
    "        return 'Night'\n",
    "\n",
    "occupancy_df['time_of_day'] = occupancy_df['hour'].apply(categorize_time_of_day)\n",
    "print(\"Temporal features added\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Merge Calendar Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Merging calendar events...\")\n",
    "games = pd.read_csv('../../data/football_games.csv')\n",
    "calendar = pd.read_csv('../../data/academic_calendar.csv')\n",
    "\n",
    "games['Date'] = pd.to_datetime(games['Date'])\n",
    "calendar['Start_Date'] = pd.to_datetime(calendar['Start_Date']).dt.normalize()\n",
    "calendar['End_Date'] = pd.to_datetime(calendar['End_Date']).dt.normalize()\n",
    "\n",
    "occupancy_df['date'] = pd.to_datetime(occupancy_df['date'])\n",
    "game_dates = games['Date'].dt.normalize()\n",
    "occupancy_df['is_game_day'] = occupancy_df['date'].isin(game_dates).astype(int)\n",
    "\n",
    "# Calendar events\n",
    "for event_type in ['Dead_Week', 'Finals_Week', 'Spring_Break', 'Thanksgiving_Break', 'Winter_Break']:\n",
    "    event_periods = calendar[calendar['Event_Type'] == event_type]\n",
    "    occupancy_df[f'is_{event_type.lower()}'] = 0\n",
    "\n",
    "    for _, period in event_periods.iterrows():\n",
    "        mask = (occupancy_df['date'] >= period['Start_Date']) & \\\n",
    "               (occupancy_df['date'] <= period['End_Date'])\n",
    "        occupancy_df.loc[mask, f'is_{event_type.lower()}'] = 1\n",
    "\n",
    "occupancy_df['is_any_break'] = (\n",
    "    occupancy_df['is_spring_break'] |\n",
    "    occupancy_df['is_thanksgiving_break'] |\n",
    "    occupancy_df['is_winter_break']\n",
    ").astype(int)\n",
    "\n",
    "print(\"Calendar events merged\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Merge Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Merging weather data...\")\n",
    "weather = pd.read_csv('../../data/weather_pullman_2020_2025.csv')\n",
    "weather['date'] = pd.to_datetime(weather['date']).dt.normalize()\n",
    "\n",
    "occupancy_df = occupancy_df.merge(weather, left_on='date', right_on='date', how='left')\n",
    "print(\"Weather data merged\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Load and Map Capacity Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading capacity data...\")\n",
    "zone_capacity = pd.read_csv('../../data/zone_capacity.csv')\n",
    "lot_mapping = pd.read_csv('../../data/lot_mapping_enhanced_with_coords.csv')\n",
    "\n",
    "# Build capacity dict for specific zones\n",
    "capacity_dict = {}\n",
    "\n",
    "# Map from alternative descriptions\n",
    "for _, row in lot_mapping.iterrows():\n",
    "    alt_desc = row.get('alternative_location_description', '')\n",
    "    if pd.notna(alt_desc) and alt_desc:\n",
    "        for name in str(alt_desc).split('|'):\n",
    "            name = name.strip()\n",
    "            zone_name = row['Zone_Name']\n",
    "            if zone_name in zone_capacity['Zone'].values:\n",
    "                cap = zone_capacity[zone_capacity['Zone'] == zone_name]['Max_Capacity'].values[0]\n",
    "                capacity_dict[name] = cap\n",
    "\n",
    "# Also add direct mappings\n",
    "for _, row in zone_capacity.iterrows():\n",
    "    capacity_dict[row['Zone']] = row['Max_Capacity']\n",
    "\n",
    "# Map capacities\n",
    "occupancy_df['Max_Capacity'] = occupancy_df['Zone'].map(capacity_dict)\n",
    "\n",
    "# Estimate capacity for zones without data (95th percentile)\n",
    "zones_without_cap = occupancy_df[occupancy_df['Max_Capacity'].isna()]['Zone'].unique()\n",
    "if len(zones_without_cap) > 0:\n",
    "    print(f\"Estimating capacity for {len(zones_without_cap)} zones...\")\n",
    "    for zone in zones_without_cap:\n",
    "        zone_data = occupancy_df[occupancy_df['Zone'] == zone]['occupancy_count']\n",
    "        estimated_cap = max(zone_data.quantile(0.95), 10)\n",
    "        occupancy_df.loc[occupancy_df['Zone'] == zone, 'Max_Capacity'] = estimated_cap\n",
    "\n",
    "# Calculate availability metrics\n",
    "occupancy_df['occupancy_ratio'] = occupancy_df['occupancy_count'] / occupancy_df['Max_Capacity'].replace(0, 1)\n",
    "occupancy_df['available_spaces'] = (occupancy_df['Max_Capacity'] - occupancy_df['occupancy_count']).clip(lower=0)\n",
    "occupancy_df['is_near_full'] = (occupancy_df['occupancy_ratio'] >= 0.85).astype(int)\n",
    "occupancy_df['is_very_full'] = (occupancy_df['occupancy_ratio'] >= 0.95).astype(int)\n",
    "\n",
    "print(\"Capacity data mapped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Create Train/Validation/Test Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating train/validation/test splits...\")\n",
    "\n",
    "train_end = pd.Timestamp('2024-08-31')\n",
    "val_end = pd.Timestamp('2025-05-31')\n",
    "\n",
    "occupancy_train = occupancy_df[occupancy_df['datetime'] <= train_end].copy()\n",
    "occupancy_val = occupancy_df[(occupancy_df['datetime'] > train_end) & (occupancy_df['datetime'] <= val_end)].copy()\n",
    "occupancy_test = occupancy_df[occupancy_df['datetime'] > val_end].copy()\n",
    "\n",
    "print(f\"Training: {len(occupancy_train):,} records ({occupancy_train['date'].min()} to {occupancy_train['date'].max()})\")\n",
    "print(f\"Validation: {len(occupancy_val):,} records ({occupancy_val['date'].min()} to {occupancy_val['date'].max()})\")\n",
    "print(f\"Test: {len(occupancy_test):,} records ({occupancy_test['date'].min()} to {occupancy_test['date'].max()})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Saving lot-level occupancy data (AMP-based)...\")\n",
    "\n",
    "occupancy_df.to_csv('../../data/processed/occupancy_lot_level_amp_full.csv', index=False)\n",
    "occupancy_train.to_csv('../../data/processed/occupancy_lot_level_amp_train.csv', index=False)\n",
    "occupancy_val.to_csv('../../data/processed/occupancy_lot_level_amp_val.csv', index=False)\n",
    "occupancy_test.to_csv('../../data/processed/occupancy_lot_level_amp_test.csv', index=False)\n",
    "\n",
    "print(f\"Full lot-level data saved: {len(occupancy_df):,} records\")\n",
    "print(f\"Train set saved: {len(occupancy_train):,} records\")\n",
    "print(f\"Validation set saved: {len(occupancy_val):,} records\")\n",
    "print(f\"Test set saved: {len(occupancy_test):,} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"LOT-LEVEL DATA SUMMARY (AMP SESSION-BASED)\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Specific zones (lots): {occupancy_df['Zone'].nunique()}\")\n",
    "print(f\"Average occupancy: {occupancy_df['occupancy_count'].mean():.1f} cars\")\n",
    "print(f\"Date range: {occupancy_df['date'].min()} to {occupancy_df['date'].max()}\")\n",
    "print(\"\\nTop 10 busiest specific zones:\")\n",
    "print(occupancy_df.groupby('Zone')['occupancy_count'].mean().sort_values(ascending=False).head(10))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DONE!\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"1. Train lot-level model using this data\")\n",
    "print(\"2. Compare with LPR-based lot-level predictions (notebook 04)\")\n",
    "print(\"3. Update API to support both AMP and LPR-based predictions\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
