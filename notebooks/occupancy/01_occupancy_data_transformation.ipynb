{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Occupancy Data Transformation\n",
    "This notebook transforms individual parking session data into hourly occupancy predictions \n",
    "## The Shift in Approach\n",
    "**Previous approach (notebooks 10-11):** Predict individual session durations\n",
    "- Target: `duration_hours` per parking session\n",
    "**New approach (this notebook):** Predict hourly occupancy rates\n",
    "- Target: `occupancy_count` or `occupancy_rate` per zone per hour\n",
    "- More predictable: Aggregate patterns smooth out individual variance\n",
    "- Directly useful: \"CUE Garage will be 85% full at 10am Monday\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom datetime import datetime, timedelta\nimport warnings\nwarnings.filterwarnings('ignore')\n# Set visualization style\nsns.set_style('whitegrid')\nplt.rcParams['figure.figsize'] = (14, 6)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load AMP Data\n",
    "Load the base preprocessed AMP parking session data (without enrichment).\n",
    "Calendar and weather features will be added to the occupancy data later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load AMP preprocessed CLEANED data (excludes B St, JumpTest, non-existent lots)\n# This is the cleaned version from notebook 14\namp = pd.read_csv('../../data/processed/amp_preprocessed_clean.csv', parse_dates=['Start_Date', 'End_Date'])\nprint(f\"Total parking sessions: {len(amp):,}\")\nprint(f\"Date range: {amp['Start_Date'].min()} to {amp['Start_Date'].max()}\")\nprint(f\"Unique zones: {amp['Zone'].nunique()}\")\nprint(f\"\\nZones: {sorted(amp['Zone'].unique())}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create 15-Minute Time Grid\n",
    "Generate all possible (Date, Hour, Minute) combinations for the date range.\n",
    "Each day has 96 intervals (24 hours × 4 intervals per hour)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Get date range\nstart_date = amp['Start_Date'].min().date()\nend_date = amp['Start_Date'].max().date()\n# Create date range\ndate_range = pd.date_range(start=start_date, end=end_date, freq='D')\n# Create hour range (0-23) and minute intervals (0, 15, 30, 45)\nhours = range(24)\nminutes = [0, 15, 30, 45]\n# Create all combinations of date, hour, and minute (15-min intervals)\ntime_grid = pd.MultiIndex.from_product(\n    [date_range, hours, minutes],\n    names=['date', 'hour', 'minute']\n).to_frame(index=False)\n# Create datetime column for easier processing\ntime_grid['datetime'] = (\n    pd.to_datetime(time_grid['date']) + \n    pd.to_timedelta(time_grid['hour'], unit='h') +\n    pd.to_timedelta(time_grid['minute'], unit='m')\n)\nprint(f\"Time grid created: {len(time_grid):,} 15-minute intervals\")\nprint(f\"Intervals per day: {len(hours) * len(minutes)}\")\nprint(f\"Date range: {time_grid['date'].min()} to {time_grid['date'].max()}\")\nprint(f\"\\nFirst few rows:\")\nprint(time_grid.head(10))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Occupancy for Each 15-Minute Interval\n",
    "For each zone and 15-minute interval, count how many parking sessions were active during that interval.\n",
    "A session is \"active\" during an interval if:\n",
    "- Start_Date <= interval_end AND End_Date >= interval_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Get unique zones\nzones = amp['Zone'].unique()\nprint(f\"Processing occupancy for {len(zones)} zones...\")\nprint(\"This will take 20-40 minutes for 15-minute intervals...\")\nprint(f\"Processing {len(zones) * len(date_range) * 24 * 4:,} zone-interval combinations\")\n# Create zone-interval grid (15-minute intervals)\nzone_interval_grid = pd.MultiIndex.from_product(\n    [zones, date_range, hours, minutes],\n    names=['Zone', 'date', 'hour', 'minute']\n).to_frame(index=False)\n# Create datetime columns for interval start and end\nzone_interval_grid['interval_start'] = (\n    pd.to_datetime(zone_interval_grid['date']) + \n    pd.to_timedelta(zone_interval_grid['hour'], unit='h') +\n    pd.to_timedelta(zone_interval_grid['minute'], unit='m')\n)\nzone_interval_grid['interval_end'] = zone_interval_grid['interval_start'] + pd.Timedelta(minutes=15)\nprint(f\"Zone-interval grid created: {len(zone_interval_grid):,} combinations\")\nprint(f\"\\nCalculating occupancy counts for 15-minute intervals...\")\nprint(f\"Sample intervals:\")\nprint(zone_interval_grid[['Zone', 'interval_start', 'interval_end']].head(8))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Calculate occupancy using a vectorized approach\n# For each zone-interval, count sessions that overlap with that 15-minute interval\noccupancy_list = []\nzone_count=0\nfor zone in zones:\n    zone_count += 1\n    print(f\"Processing zone: {zone}: {round(zone_count/len(zones),2)} ({zone_count/len(zones)*100:.1f}%)\")\n    # Filter sessions for this zone\n    zone_sessions = amp[amp['Zone'] == zone].copy()\n    # Get time grid for this zone\n    zone_grid = zone_interval_grid[zone_interval_grid['Zone'] == zone].copy()\n    # For each 15-minute interval in the grid, count overlapping sessions\n    for idx, row in zone_grid.iterrows():\n        interval_start = row['interval_start']\n        interval_end = row['interval_end']\n        # Count sessions active during this 15-minute interval\n        # Session overlaps if: session_start < interval_end AND session_end > interval_start\n        active_sessions = zone_sessions[\n            (zone_sessions['Start_Date'] < interval_end) & \n            (zone_sessions['End_Date'] > interval_start)\n        ]\n        occupancy_list.append({\n            'Zone': zone,\n            'date': row['date'],\n            'hour': row['hour'],\n            'minute': row['minute'],\n            'datetime': interval_start,\n            'occupancy_count': len(active_sessions)\n        })\n# Convert to DataFrame\noccupancy_df = pd.DataFrame(occupancy_list)\nprint(f\"\\nOccupancy data created: {len(occupancy_df):,} zone-interval records (15-min granularity)\")\nprint(f\"Date range: {occupancy_df['date'].min()} to {occupancy_df['date'].max()}\")\nprint(f\"Sample data:\")\nprint(occupancy_df.head(20))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Temporal Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Extract temporal features\noccupancy_df['year'] = occupancy_df['datetime'].dt.year\noccupancy_df['month'] = occupancy_df['datetime'].dt.month\noccupancy_df['day'] = occupancy_df['datetime'].dt.day\noccupancy_df['day_of_week'] = occupancy_df['datetime'].dt.dayofweek\noccupancy_df['day_name'] = occupancy_df['datetime'].dt.day_name()\noccupancy_df['is_weekend'] = (occupancy_df['day_of_week'] >= 5).astype(int)\n# Add minute_interval as a feature (0, 15, 30, 45)\noccupancy_df['minute_interval'] = occupancy_df['minute']\n# Time of day categories\ndef categorize_time_of_day(hour):\n    if 0 <= hour < 6:\n        return 'Late Night'\n    elif 6 <= hour < 12:\n        return 'Morning'\n    elif 12 <= hour < 18:\n        return 'Afternoon'\n    elif 18 <= hour < 22:\n        return 'Evening'\n    else:\n        return 'Night'\noccupancy_df['time_of_day'] = occupancy_df['hour'].apply(categorize_time_of_day)\nprint(\"Temporal features added (including 15-minute intervals)\")\nprint(f\"\\nSample data:\")\nprint(occupancy_df[['Zone', 'datetime', 'hour', 'minute', 'occupancy_count']].head(10))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Calendar Events\n",
    "Add game days, finals weeks, and breaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load calendar data\ngames = pd.read_csv('../../data/football_games.csv')\ncalendar = pd.read_csv('../../data/academic_calendar.csv')\n# Parse dates\ngames['Date'] = pd.to_datetime(games['Date'])\ncalendar['Start_Date'] = pd.to_datetime(calendar['Start_Date'])\ncalendar['End_Date'] = pd.to_datetime(calendar['End_Date'])\n# Convert occupancy_df['date'] to datetime for comparison\noccupancy_df['date'] = pd.to_datetime(occupancy_df['date'])\n# Mark game days\ngame_dates = games['Date'].dt.date.unique()\noccupancy_df['is_game_day'] = occupancy_df['date'].dt.date.isin(game_dates).astype(int)\n# Mark calendar events\nfor event_type in ['Dead_Week', 'Finals_Week', 'Spring_Break', 'Thanksgiving_Break', 'Winter_Break', 'University_Holiday']:\n    event_periods = calendar[calendar['Event_Type'] == event_type]\n    occupancy_df[f'is_{event_type.lower()}'] = 0\n    for _, period in event_periods.iterrows():\n        # Compare datetime columns directly\n        mask = (occupancy_df['date'] >= period['Start_Date']) & \\\n               (occupancy_df['date'] <= period['End_Date'])\n        occupancy_df.loc[mask, f'is_{event_type.lower()}'] = 1\n# Create combined break indicator\noccupancy_df['is_any_break'] = (\n    occupancy_df['is_spring_break'] | \n    occupancy_df['is_thanksgiving_break'] | \n    occupancy_df['is_winter_break']\n).astype(int)\nprint(\"Calendar events merged\")\nprint(f\"\\nGame days: {occupancy_df['is_game_day'].sum():,}\")\nprint(f\"Dead weeks: {occupancy_df['is_dead_week'].sum():,}\")\nprint(f\"Finals weeks: {occupancy_df['is_finals_week'].sum():,}\")\nprint(f\"Break periods: {occupancy_df['is_any_break'].sum():,}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load weather data\nweather = pd.read_csv('../../data/weather_pullman_2020_2025.csv')\nweather['date'] = pd.to_datetime(weather['date']).dt.date\n# Convert occupancy_df['date'] to date object for merging with weather\noccupancy_df['date_for_merge'] = occupancy_df['date'].dt.date\n# Merge weather\noccupancy_df = occupancy_df.merge(weather, left_on='date_for_merge', right_on='date', how='left')\n# Drop the temporary merge column and the redundant date column from weather\noccupancy_df = occupancy_df.drop(columns=['date_for_merge', 'date_y'])\noccupancy_df = occupancy_df.rename(columns={'date_x': 'date'})\nprint(\"Weather data merged\")\nprint(f\"\\nWeather columns added: {[col for col in weather.columns if col != 'date']}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Camera Classification\n",
    "Add fixed camera features from notebook 16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load camera classification\ntry:\n    camera_features = pd.read_csv('../../data/processed/fixed_camera_classification.csv')\n    print(f\"Camera classification loaded: {len(camera_features)} lots\")\n    # Convert Lot_number to string for merging\n    camera_features['Lot_number'] = camera_features['Lot_number'].astype(str)\n    # Create binary has_fixed_camera feature\n    camera_features['has_fixed_camera'] = (camera_features['camera_classification_v2'] == 'FIXED_CAMERA_HIGH').astype(int)\n    # Get lot-to-zone mapping\n    lot_mapping = pd.read_csv('../../data/lot_mapping_enhanced.csv')\n    lot_mapping['Lot_number'] = lot_mapping['Lot_number'].astype(str)\n    # Merge camera with lot mapping to get zones\n    camera_with_zones = camera_features.merge(\n        lot_mapping[['Lot_number', 'Zone_Name']],\n        on='Lot_number',\n        how='left'\n    )\n    # Rename Zone_Name to Zone for consistency\n    camera_with_zones = camera_with_zones.rename(columns={'Zone_Name': 'Zone'})\n    # Aggregate to zone level (take max scores per zone)\n    zone_camera_features = camera_with_zones.groupby('Zone').agg({\n        'entrance_camera_score': 'max',\n        'bulk_patrol_score': 'max',\n        'avg_scans_per_active_hour': 'mean',\n        'has_fixed_camera': 'max'\n    }).reset_index()\n    # Merge with occupancy data\n    occupancy_df = occupancy_df.merge(zone_camera_features, on='Zone', how='left')\n    # Fill NaN for zones without camera data\n    occupancy_df['entrance_camera_score'] = occupancy_df['entrance_camera_score'].fillna(0)\n    occupancy_df['bulk_patrol_score'] = occupancy_df['bulk_patrol_score'].fillna(0)\n    occupancy_df['avg_scans_per_active_hour'] = occupancy_df['avg_scans_per_active_hour'].fillna(0)\n    occupancy_df['has_fixed_camera'] = occupancy_df['has_fixed_camera'].fillna(0).astype(int)\n    print(f\"\\n Camera features merged\")\n    print(f\"  Zones with fixed cameras: {(occupancy_df.groupby('Zone')['has_fixed_camera'].first() == 1).sum()}\")\nexcept FileNotFoundError:\n    print(\"⚠️ Camera classification file not found - skipping camera features\")\n    occupancy_df['entrance_camera_score'] = 0\n    occupancy_df['bulk_patrol_score'] = 0\n    occupancy_df['avg_scans_per_active_hour'] = 0\n    occupancy_df['has_fixed_camera'] = 0"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Ground Truth Capacity & Calculate Availability Metrics\n",
    "Use actual max capacity from Transportation Services instead of percentile estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load ground truth capacity data from Transportation Services\nprint(\"=\"*70)\nprint(\"LOADING GROUND TRUTH CAPACITY\")\nprint(\"=\"*70)\nzone_capacity = pd.read_csv('../../data/zone_capacity.csv')\nprint(f\"\\nCapacity data loaded for {len(zone_capacity)} zones\")\nprint(f\"\\nTop 10 zones by capacity:\")\nprint(zone_capacity.nlargest(10, 'Max_Capacity'))\n# Merge capacity data with occupancy - using a more memory-efficient approach\n# Convert to dictionary for faster lookups\ncapacity_dict = dict(zip(zone_capacity['Zone'], zone_capacity['Max_Capacity']))\n# Add Max_Capacity column using map (more memory efficient than merge)\noccupancy_df['Max_Capacity'] = occupancy_df['Zone'].map(capacity_dict)\n# Check for zones without capacity\nzones_without_capacity = occupancy_df[occupancy_df['Max_Capacity'].isna()]['Zone'].unique()\nif len(zones_without_capacity) > 0:\n    print(f\"\\n⚠️ WARNING: {len(zones_without_capacity)} zones have no capacity data:\")\n    for zone in zones_without_capacity[:5]:\n        print(f\"  - {zone}\")\n    if len(zones_without_capacity) > 5:\n        print(f\"  ... and {len(zones_without_capacity) - 5} more\")\n    # For zones without capacity, fall back to 95th percentile as estimate\n    print(f\"\\n  Using 95th percentile as fallback estimate for zones without capacity\")\n    for zone in zones_without_capacity:\n        zone_data = occupancy_df[occupancy_df['Zone'] == zone]['occupancy_count']\n        estimated_capacity = zone_data.quantile(0.95)\n        occupancy_df.loc[occupancy_df['Zone'] == zone, 'Max_Capacity'] = max(estimated_capacity, 20)\n# Calculate occupancy ratio using ACTUAL CAPACITY\noccupancy_df['occupancy_ratio'] = occupancy_df['occupancy_count'] / occupancy_df['Max_Capacity'].replace(0, 1)\n# Calculate available spaces (NEW - this is what users want to see!)\noccupancy_df['available_spaces'] = (occupancy_df['Max_Capacity'] - occupancy_df['occupancy_count']).clip(lower=0)\n# Binary indicators\noccupancy_df['is_near_full'] = (occupancy_df['occupancy_ratio'] >= 0.85).astype(int)\noccupancy_df['is_very_full'] = (occupancy_df['occupancy_ratio'] >= 0.95).astype(int)\noccupancy_df['availability_score'] = (1 - occupancy_df['occupancy_ratio']).clip(0, 1)\n# Categorize availability\ndef categorize_availability(ratio):\n    if ratio >= 0.95:\n        return 'VERY_LOW'  # 95%+ full - very hard to find spot\n    elif ratio >= 0.80:\n        return 'LOW'  # 80-95% full - hard to find spot\n    elif ratio >= 0.60:\n        return 'MODERATE'  # 60-80% full - moderate chance\n    elif ratio >= 0.40:\n        return 'HIGH'  # 40-60% full - good chance\n    else:\n        return 'VERY_HIGH'  # <40% full - very easy\noccupancy_df['availability_category'] = occupancy_df['occupancy_ratio'].apply(categorize_availability)\nprint(f\"\\n Availability metrics calculated using GROUND TRUTH CAPACITY\")\nprint(f\"\\nCapacity statistics:\")\nprint(f\"  Average zone capacity: {occupancy_df.groupby('Zone')['Max_Capacity'].first().mean():.0f} spaces\")\nprint(f\"  Total parking capacity: {occupancy_df.groupby('Zone')['Max_Capacity'].first().sum():.0f} spaces\")\nprint(f\"\\nAvailability distribution:\")\nprint(occupancy_df['availability_category'].value_counts().sort_index())"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(\"=\"*70)\n",
    "print(\"OCCUPANCY SUMMARY STATISTICS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nTotal zone-interval observations: {len(occupancy_df):,} (15-minute granularity)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Camera Classification\n",
    "Add fixed camera features from notebook 16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load camera classification\ntry:\n    camera_features = pd.read_csv('../../data/processed/fixed_camera_classification.csv')\n    print(f\"Camera classification loaded: {len(camera_features)} lots\")\n    # Convert Lot_number to string for merging\n    camera_features['Lot_number'] = camera_features['Lot_number'].astype(str)\n    # Create binary has_fixed_camera feature from classification\n    camera_features['has_fixed_camera'] = (camera_features['camera_classification_v2'] == 'FIXED_CAMERA_HIGH').astype(int)\n    # Get lot-to-zone mapping from lot_mapping_enhanced.csv (single source of truth)\n    \"    lot_mapping = pd.read_csv('../../data/lot_mapping_enhanced.csv')\\n\",\n    lot_mapping['Lot_number'] = lot_mapping['Lot_number'].astype(str)\n    # Merge camera with lot mapping to get zones\n    camera_with_zones = camera_features.merge(\n        lot_mapping[['Lot_number', 'Zone_Name']],\n        on='Lot_number',\n        how='left'\n    )\n    # Rename Zone_Name to Zone for consistency\n    camera_with_zones = camera_with_zones.rename(columns={'Zone_Name': 'Zone'})\n    # Drop rows where Zone is NaN (lots not in mapping)\n    camera_with_zones = camera_with_zones.dropna(subset=['Zone'])\n    print(f\"  Lots matched to zones: {len(camera_with_zones)}\")\n    # Aggregate to zone level (take max scores per zone)\n    zone_camera_features = camera_with_zones.groupby('Zone').agg({\n        'entrance_camera_score': 'max',\n        'bulk_patrol_score': 'max',\n        'avg_scans_per_active_hour': 'mean',\n        'has_fixed_camera': 'max'\n    }).reset_index()\n    print(f\"  Unique zones with camera data: {len(zone_camera_features)}\")\n    # Merge with occupancy data\n    occupancy_df = occupancy_df.merge(zone_camera_features, on='Zone', how='left')\n    # Fill NaN for zones without camera data (use .get() to safely access columns)\n    for col in ['entrance_camera_score', 'bulk_patrol_score', 'avg_scans_per_active_hour']:\n        if col in occupancy_df.columns:\n            occupancy_df[col] = occupancy_df[col].fillna(0)\n        else:\n            occupancy_df[col] = 0\n    if 'has_fixed_camera' in occupancy_df.columns:\n        occupancy_df['has_fixed_camera'] = occupancy_df['has_fixed_camera'].fillna(0).astype(int)\n    else:\n        occupancy_df['has_fixed_camera'] = 0\n    print(f\"\\n Camera features merged\")\n    print(f\"  Zones with fixed cameras: {(occupancy_df.groupby('Zone')['has_fixed_camera'].first() == 1).sum()}\")\nexcept FileNotFoundError:\n    print(\"⚠️ Camera classification file not found - skipping camera features\")\n    occupancy_df['entrance_camera_score'] = 0\n    occupancy_df['bulk_patrol_score'] = 0\n    occupancy_df['avg_scans_per_active_hour'] = 0\n    occupancy_df['has_fixed_camera'] = 0"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Zone Baselines & Availability Metrics\n",
    "Create \"typical full\" baselines using percentiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Summary statistics\nprint(\"=\"*70)\nprint(\"OCCUPANCY SUMMARY STATISTICS\")\nprint(\"=\"*70)\nprint(f\"\\nTotal zone-hour observations: {len(occupancy_df):,}\")\nprint(f\"\\nOccupancy count distribution:\")\nprint(occupancy_df['occupancy_count'].describe())\nprint(f\"\\n\\nBusiest zones (average occupancy):\")\nzone_avg = occupancy_df.groupby('Zone')['occupancy_count'].mean().sort_values(ascending=False)\nprint(zone_avg.head(10))\nprint(f\"\\n\\nPeak hours (average occupancy):\")\nhour_avg = occupancy_df.groupby('hour')['occupancy_count'].mean().sort_values(ascending=False)\nprint(hour_avg.head(10))\nprint(f\"\\n\\nNear-full frequency by zone (% of time zone is 85%+ full):\")\nnear_full_freq = occupancy_df.groupby('Zone')['is_near_full'].mean().sort_values(ascending=False)\nprint((near_full_freq.head(10) * 100).round(2))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Visualize occupancy patterns\nfig, axes = plt.subplots(2, 2, figsize=(16, 12))\n# 1. Average occupancy by hour\nhour_avg.plot(kind='bar', ax=axes[0,0], color='steelblue')\naxes[0,0].set_title('Average Occupancy by Hour of Day', fontsize=14, fontweight='bold')\naxes[0,0].set_xlabel('Hour')\naxes[0,0].set_ylabel('Average Cars Parked')\naxes[0,0].grid(axis='y', alpha=0.3)\n# 2. Average occupancy by day of week\nday_avg = occupancy_df.groupby('day_of_week')['occupancy_count'].mean()\nday_names = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\naxes[0,1].bar(range(7), day_avg, color='coral')\naxes[0,1].set_xticks(range(7))\naxes[0,1].set_xticklabels(day_names)\naxes[0,1].set_title('Average Occupancy by Day of Week', fontsize=14, fontweight='bold')\naxes[0,1].set_ylabel('Average Cars Parked')\naxes[0,1].grid(axis='y', alpha=0.3)\n# 3. Top zones by occupancy\nzone_avg.head(10).plot(kind='barh', ax=axes[1,0], color='teal')\naxes[1,0].set_title('Top 10 Zones by Average Occupancy', fontsize=14, fontweight='bold')\naxes[1,0].set_xlabel('Average Cars Parked')\naxes[1,0].grid(axis='x', alpha=0.3)\n# 4. Game day vs regular day\ngame_comparison = occupancy_df.groupby(['is_game_day', 'hour'])['occupancy_count'].mean().unstack(0)\ngame_comparison.plot(ax=axes[1,1], marker='o')\naxes[1,1].set_title('Game Day vs Regular Day Occupancy', fontsize=14, fontweight='bold')\naxes[1,1].set_xlabel('Hour of Day')\naxes[1,1].set_ylabel('Average Cars Parked')\naxes[1,1].legend(['Regular Day', 'Game Day'])\naxes[1,1].grid(alpha=0.3)\nplt.tight_layout()\nplt.savefig('../../data/processed/occupancy_patterns.png', dpi=300, bbox_inches='tight')\nplt.show()\nprint(\"Occupancy patterns visualization saved to: data/processed/occupancy_patterns.png\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Train/Validation/Test Splits\n",
    "Using the same time-based splits as before:\n",
    "- Training: 2020-08 to 2023-12 (~70%)\n",
    "- Validation: 2024-01 to 2024-08 (~15%)\n",
    "- Test: 2024-09 to 2025-11 (~15%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Define split dates - UPDATED to include 2024 data in training\ntrain_end = pd.Timestamp('2024-08-31')\nval_end = pd.Timestamp('2025-05-31')\n# Create splits\noccupancy_train = occupancy_df[occupancy_df['datetime'] <= train_end].copy()\noccupancy_val = occupancy_df[(occupancy_df['datetime'] > train_end) & (occupancy_df['datetime'] <= val_end)].copy()\noccupancy_test = occupancy_df[occupancy_df['datetime'] > val_end].copy()\nprint(\"=\"*70)\nprint(\"DATA SPLITS (UPDATED WITH 2024 IN TRAINING)\")\nprint(\"=\"*70)\nprint(f\"\\nTraining set:\")\nprint(f\"  Records: {len(occupancy_train):,}\")\nprint(f\"  Date range: {occupancy_train['date'].min()} to {occupancy_train['date'].max()}\")\nprint(f\"  Avg occupancy: {occupancy_train['occupancy_count'].mean():.2f}\")\nprint(f\"\\nValidation set:\")\nprint(f\"  Records: {len(occupancy_val):,}\")\nprint(f\"  Date range: {occupancy_val['date'].min()} to {occupancy_val['date'].max()}\")\nprint(f\"  Avg occupancy: {occupancy_val['occupancy_count'].mean():.2f}\")\nprint(f\"\\nTest set:\")\nprint(f\"  Records: {len(occupancy_test):,}\")\nprint(f\"  Date range: {occupancy_test['date'].min()} to {occupancy_test['date'].max()}\")\nprint(f\"  Avg occupancy: {occupancy_test['occupancy_count'].mean():.2f}\")\n# Show year distribution\nprint(f\"\\nYear distribution in training set:\")\ntrain_years = occupancy_train.groupby(occupancy_train['datetime'].dt.year).size()\nfor year, count in train_years.items():\n    print(f\"  {year}: {count:,} records ({count/len(occupancy_train)*100:.1f}%)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Save full occupancy data\noccupancy_df.to_csv('../../data/processed/occupancy_full.csv', index=False)\nprint(f\"Full occupancy data saved: {len(occupancy_df):,} records\")\n# Save splits\noccupancy_train.to_csv('../../data/processed/occupancy_train.csv', index=False)\noccupancy_val.to_csv('../../data/processed/occupancy_val.csv', index=False)\noccupancy_test.to_csv('../../data/processed/occupancy_test.csv', index=False)\nprint(f\"\\nTrain set saved: {len(occupancy_train):,} records\")\nprint(f\"Validation set saved: {len(occupancy_val):,} records\")\nprint(f\"Test set saved: {len(occupancy_test):,} records\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}