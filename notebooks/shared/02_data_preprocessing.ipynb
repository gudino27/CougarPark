{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing and Cleaning\n",
    "\n",
    "This notebook provides two preprocessing approaches:\n",
    "\n",
    "1. **Approach 1 (with LPR):** Combines AMP and LPR data using lot mapping\n",
    "2. **Approach 2 (AMP only):** Uses only AMP data which already has zone names\n",
    "\n",
    "Both approaches include:\n",
    "- Data consolidation from multiple sheets\n",
    "- Temporal feature engineering\n",
    "- Semester-based filtering capabilities\n",
    "- Data quality checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries loaded successfully\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(\"Libraries loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data loaded successfully\n",
      "\n",
      "AMP data: 1,703,404 total rows\n",
      "LPR data: 1,780,187 total rows\n",
      "Lot mappings: 189 lots\n"
     ]
    }
   ],
   "source": [
    "# Load Excel file\n",
    "excel_file = pd.ExcelFile('../data/raw/Data_For_Class_Project.xlsx')\n",
    "\n",
    "# Load AMP sheets (Automated Metered Parking)\n",
    "amp1 = pd.read_excel(excel_file, sheet_name='AMP1')\n",
    "amp2 = pd.read_excel(excel_file, sheet_name='AMP2')\n",
    "amp3 = pd.read_excel(excel_file, sheet_name='AMP3')\n",
    "\n",
    "# Load LPR sheets (License Plate Recognition)\n",
    "lpr_fy23 = pd.read_excel(excel_file, sheet_name='LPR_Reads_FY23')\n",
    "lpr_fy24 = pd.read_excel(excel_file, sheet_name='LPR_Reads_FY24')\n",
    "lpr_fy25 = pd.read_excel(excel_file, sheet_name='LPR_Reads_FY25')\n",
    "\n",
    "# Load lot mapping (force Lot_number as string to preserve leading zeros)\n",
    "lot_mapping = pd.read_csv('../data/lot_mapping_enhanced.csv', dtype={'Lot_number': str})\n",
    "\n",
    "print(\"All data loaded successfully\")\n",
    "print(f\"\\nAMP data: {len(amp1) + len(amp2) + len(amp3):,} total rows\")\n",
    "print(f\"LPR data: {len(lpr_fy23) + len(lpr_fy24) + len(lpr_fy25):,} total rows\")\n",
    "print(f\"Lot mappings: {len(lot_mapping)} lots\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 1: Combine AMP + LPR Data (with lot mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Consolidate and Clean AMP Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined AMP data: 1,703,404 rows\n",
      "\n",
      "Columns: ['Zone', 'Start_Date', 'End_Date']\n",
      "\n",
      "Date range: 2020-08-10 07:51:00 to 2025-11-02 12:38:00\n",
      "\n",
      "Missing values:\n",
      "Zone          0\n",
      "Start_Date    0\n",
      "End_Date      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Consolidate all AMP sheets\n",
    "amp_combined = pd.concat([amp1, amp2, amp3], ignore_index=True)\n",
    "\n",
    "print(f\"Combined AMP data: {len(amp_combined):,} rows\")\n",
    "print(f\"\\nColumns: {amp_combined.columns.tolist()}\")\n",
    "print(f\"\\nDate range: {amp_combined['Start_Date'].min()} to {amp_combined['End_Date'].max()}\")\n",
    "\n",
    "# Check for missing values\n",
    "print(f\"\\nMissing values:\")\n",
    "print(amp_combined.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Duration statistics before cleaning:\n",
      "count    1.703404e+06\n",
      "mean     2.123014e+00\n",
      "std      2.229149e+00\n",
      "min     -2.400000e+01\n",
      "25%      1.000000e+00\n",
      "50%      1.500000e+00\n",
      "75%      2.483333e+00\n",
      "max      3.259167e+02\n",
      "Name: duration_hours, dtype: float64\n",
      "\n",
      "Rows removed: 537\n",
      "Remaining rows: 1,702,867\n"
     ]
    }
   ],
   "source": [
    "# Convert date columns to datetime\n",
    "amp_combined['Start_Date'] = pd.to_datetime(amp_combined['Start_Date'])\n",
    "amp_combined['End_Date'] = pd.to_datetime(amp_combined['End_Date'])\n",
    "\n",
    "# Calculate parking duration in hours\n",
    "amp_combined['duration_hours'] = (amp_combined['End_Date'] - amp_combined['Start_Date']).dt.total_seconds() / 3600\n",
    "\n",
    "# Remove invalid/outlier durations (e.g., negative or extremely long)\n",
    "print(f\"\\nDuration statistics before cleaning:\")\n",
    "print(amp_combined['duration_hours'].describe())\n",
    "\n",
    "# Filter out unrealistic durations (negative or > 7 days)\n",
    "amp_clean = amp_combined[\n",
    "    (amp_combined['duration_hours'] > 0) & \n",
    "    (amp_combined['duration_hours'] <= 168)  # 7 days max\n",
    "].copy()\n",
    "\n",
    "print(f\"\\nRows removed: {len(amp_combined) - len(amp_clean):,}\")\n",
    "print(f\"Remaining rows: {len(amp_clean):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Consolidate and Clean LPR Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined LPR data: 1,780,187 rows\n",
      "\n",
      "Columns: ['Date_Time', 'LOT']\n",
      "\n",
      "Date range: 2022-07-01 05:24:26 to 2025-06-30 21:58:49\n",
      "\n",
      "Missing values:\n",
      "Date_Time    0\n",
      "LOT          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Consolidate all LPR sheets\n",
    "lpr_combined = pd.concat([lpr_fy23, lpr_fy24, lpr_fy25], ignore_index=True)\n",
    "\n",
    "print(f\"Combined LPR data: {len(lpr_combined):,} rows\")\n",
    "print(f\"\\nColumns: {lpr_combined.columns.tolist()}\")\n",
    "print(f\"\\nDate range: {lpr_combined['Date_Time'].min()} to {lpr_combined['Date_Time'].max()}\")\n",
    "\n",
    "# Check for missing values\n",
    "print(f\"\\nMissing values:\")\n",
    "print(lpr_combined.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rows removed: 0\n",
      "Remaining rows: 1,780,187\n",
      "Unique lots: 185\n"
     ]
    }
   ],
   "source": [
    "# Convert date column to datetime\n",
    "lpr_combined['Date_Time'] = pd.to_datetime(lpr_combined['Date_Time'])\n",
    "\n",
    "# Extract lot number from 'LOT XXX' format (take only first 3 digits/characters)\n",
    "# This handles cases like \"LOT 020 HOURLY\" â†’ \"020\"\n",
    "lpr_combined['Lot_number'] = lpr_combined['LOT'].str.replace('LOT ', '').str.strip().str[:3]\n",
    "\n",
    "# Remove rows with missing lot numbers\n",
    "lpr_clean = lpr_combined.dropna(subset=['Lot_number']).copy()\n",
    "\n",
    "print(f\"\\nRows removed: {len(lpr_combined) - len(lpr_clean):,}\")\n",
    "print(f\"Remaining rows: {len(lpr_clean):,}\")\n",
    "print(f\"Unique lots: {lpr_clean['Lot_number'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Merge LPR Data with Lot Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping coverage:\n",
      "  Mapped records: 1,780,207 (100.0%)\n",
      "  Unmapped records: 184 (0.0%)\n",
      "\n",
      "Unmapped lot numbers (2):\n",
      "['021', '101']\n"
     ]
    }
   ],
   "source": [
    "# Ensure lot_number format is consistent\n",
    "lot_mapping['Lot_number'] = lot_mapping['Lot_number'].astype(str).str.strip()\n",
    "lpr_clean['Lot_number'] = lpr_clean['Lot_number'].astype(str).str.strip()\n",
    "\n",
    "# Merge LPR data with lot mapping\n",
    "lpr_mapped = lpr_clean.merge(\n",
    "    lot_mapping[['Lot_number', 'Zone_Name', 'zone_type', 'location_description']], \n",
    "    on='Lot_number', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Check mapping coverage\n",
    "mapped_count = lpr_mapped['Zone_Name'].notna().sum()\n",
    "total_count = len(lpr_mapped)\n",
    "coverage_pct = (mapped_count / total_count * 100)\n",
    "\n",
    "print(f\"Mapping coverage:\")\n",
    "print(f\"  Mapped records: {mapped_count:,} ({coverage_pct:.1f}%)\")\n",
    "print(f\"  Unmapped records: {total_count - mapped_count:,} ({100-coverage_pct:.1f}%)\")\n",
    "\n",
    "# Show unmapped lots\n",
    "unmapped_lots = lpr_mapped[lpr_mapped['Zone_Name'].isna()]['Lot_number'].unique()\n",
    "print(f\"\\nUnmapped lot numbers ({len(unmapped_lots)}):\")\n",
    "print(sorted(unmapped_lots)[:20])  # Show first 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Add Temporal Features to Both Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temporal features added successfully\n",
      "\n",
      "New columns in AMP data: ['duration_hours', 'year', 'month', 'day', 'hour', 'day_of_week', 'day_name', 'week_of_year', 'is_weekend', 'time_of_day']\n",
      "New columns in LPR data: ['location_description', 'year', 'month', 'day', 'hour', 'day_of_week', 'day_name', 'week_of_year', 'is_weekend', 'time_of_day']\n"
     ]
    }
   ],
   "source": [
    "def add_temporal_features(df, datetime_col):\n",
    "    \"\"\"\n",
    "    Add temporal features for time-based analysis and filtering.\n",
    "    \n",
    "    Parameters:\n",
    "    df: DataFrame with datetime column\n",
    "    datetime_col: Name of the datetime column\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Basic time features\n",
    "    df['year'] = df[datetime_col].dt.year\n",
    "    df['month'] = df[datetime_col].dt.month\n",
    "    df['day'] = df[datetime_col].dt.day\n",
    "    df['hour'] = df[datetime_col].dt.hour\n",
    "    df['day_of_week'] = df[datetime_col].dt.dayofweek  # 0=Monday, 6=Sunday\n",
    "    df['day_name'] = df[datetime_col].dt.day_name()\n",
    "    df['week_of_year'] = df[datetime_col].dt.isocalendar().week\n",
    "    \n",
    "    # Is weekend?\n",
    "    df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)\n",
    "    \n",
    "    # Time of day categories\n",
    "    df['time_of_day'] = pd.cut(\n",
    "        df['hour'],\n",
    "        bins=[-1, 6, 12, 17, 21, 24],\n",
    "        labels=['Night', 'Morning', 'Afternoon', 'Evening', 'Late Night']\n",
    "    )\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Add temporal features to AMP data\n",
    "amp_clean = add_temporal_features(amp_clean, 'Start_Date')\n",
    "\n",
    "# Add temporal features to LPR data\n",
    "lpr_mapped = add_temporal_features(lpr_mapped, 'Date_Time')\n",
    "\n",
    "print(\"Temporal features added successfully\")\n",
    "print(f\"\\nNew columns in AMP data: {amp_clean.columns.tolist()[-10:]}\")\n",
    "print(f\"New columns in LPR data: {lpr_mapped.columns.tolist()[-10:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Add Semester Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMP Data - Semester Distribution:\n",
      "semester\n",
      "Fall 2020       10518\n",
      "Fall 2021       76206\n",
      "Fall 2022      138616\n",
      "Fall 2023      219145\n",
      "Fall 2024      221559\n",
      "Fall 2025      138565\n",
      "Spring 2021     20202\n",
      "Spring 2022    109230\n",
      "Spring 2023    203690\n",
      "Spring 2024    235645\n",
      "Spring 2025    240084\n",
      "Summer 2021      7184\n",
      "Summer 2022     12591\n",
      "Summer 2023     20971\n",
      "Summer 2024     24688\n",
      "Summer 2025     23973\n",
      "Name: count, dtype: int64\n",
      "\n",
      "LPR Data - Semester Distribution:\n",
      "semester\n",
      "Fall 2022      165863\n",
      "Fall 2023      323961\n",
      "Fall 2024      312261\n",
      "Spring 2023    314784\n",
      "Spring 2024    258281\n",
      "Spring 2025    271918\n",
      "Summer 2022     20571\n",
      "Summer 2023     25893\n",
      "Summer 2024     54947\n",
      "Summer 2025     31912\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def assign_semester(date):\n",
    "    \"\"\"\n",
    "    Assign academic semester based on date.\n",
    "    \n",
    "    WSU academic calendar approximation:\n",
    "    - Fall: August - December\n",
    "    - Spring: January - May\n",
    "    - Summer: June - July\n",
    "    \"\"\"\n",
    "    month = date.month\n",
    "    year = date.year\n",
    "    \n",
    "    if month >= 8:  # August onwards = Fall\n",
    "        return f\"Fall {year}\"\n",
    "    elif month <= 5:  # January to May = Spring\n",
    "        return f\"Spring {year}\"\n",
    "    else:  # June-July = Summer\n",
    "        return f\"Summer {year}\"\n",
    "\n",
    "# Add semester to AMP data\n",
    "amp_clean['semester'] = amp_clean['Start_Date'].apply(assign_semester)\n",
    "\n",
    "# Add semester to LPR data\n",
    "lpr_mapped['semester'] = lpr_mapped['Date_Time'].apply(assign_semester)\n",
    "\n",
    "# Show semester distribution\n",
    "print(\"AMP Data - Semester Distribution:\")\n",
    "print(amp_clean['semester'].value_counts().sort_index())\n",
    "\n",
    "print(\"\\nLPR Data - Semester Distribution:\")\n",
    "print(lpr_mapped['semester'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Save Preprocessed Data (Approach 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approach 1 data saved:\n",
      "  ../data/processed/amp_preprocessed.csv (1,702,867 rows)\n",
      "  ../data/processed/lpr_preprocessed.csv (1,780,391 rows)\n"
     ]
    }
   ],
   "source": [
    "# Save preprocessed data\n",
    "amp_clean.to_csv('../data/processed/amp_preprocessed.csv', index=False)\n",
    "lpr_mapped.to_csv('../data/processed/lpr_preprocessed.csv', index=False)\n",
    "\n",
    "print(\"Approach 1 data saved:\")\n",
    "print(f\"  ../data/processed/amp_preprocessed.csv ({len(amp_clean):,} rows)\")\n",
    "print(f\"  ../data/processed/lpr_preprocessed.csv ({len(lpr_mapped):,} rows)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 2: AMP Data Only (without LPR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process AMP Data with Enhanced Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zone type distribution:\n",
      "zone_type\n",
      "Permit    1009019\n",
      "Paid       693848\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Unique zones in data:\n",
      "Zone\n",
      "CUE Garage                                                        399151\n",
      "Library Garage                                                    291173\n",
      "Student Rec Center                                                247802\n",
      "Columbia Street Lot Top Bays                                      135279\n",
      "Green 5 South Beasley                                             104820\n",
      "Wilson Road on Street Meters                                       88960\n",
      "Cougar Way on Street Meters                                        50527\n",
      "Ferdinand's Ice Cream Shoppe Parking                               35275\n",
      "Green 1 PACCAR South                                               30520\n",
      "Green 3: (Gravel lot) College/Spokane                              27784\n",
      "Green 2 KMac Lot                                                   27357\n",
      "Green 3: Washington St street-side & Spark                         24397\n",
      "Thatuna Rd. on Street Meters                                       23046\n",
      "B St Hourly Lot                                                    19849\n",
      "Cougar Health Services: Patron Parking                             18076\n",
      "Yellow 3: Spring Street Lot                                        15753\n",
      "Green 3: Commons                                                   13420\n",
      "Green 3: (Gravel lot) Columbia/Spokane                             12627\n",
      "Bustad - AMP Marked spots                                          12181\n",
      "Green 3: Washington St                                             11706\n",
      "Yellow 1 IPF Lot                                                   10344\n",
      "Red 5 Tennis Courts Lot                                            10012\n",
      "ESF Cultural Center Lot                                             6604\n",
      "Green 3: Spokane St                                                 6419\n",
      "Green 3: Football General Parking                                   6267\n",
      "Green 4 Gravel Lot                                                  5428\n",
      "Scott-Coman: AMP Marked Spot                                        5074\n",
      "Green 1 Rotunda/Gannon-Goldsworthy                                  5004\n",
      "Yellow 2 Carver Farm                                                4916\n",
      "Duncan-Dunn Parking                                                 4616\n",
      "Don't Activate: Lighty East Meters                                  4099\n",
      "Red 1 Cooper East                                                   3814\n",
      "Streit-Perham AMP spots                                             3701\n",
      "Regents: AMP Marked Spot                                            3690\n",
      "Green 3: College Avenue -or- Idaho St                               3673\n",
      "Stephenson_AMP Spots                                                3421\n",
      "Green 3: Thermal Fluids/Dana West                                   3227\n",
      "Fine Arts Garage                                                    2687\n",
      "Olympia Hall_AMP Spots                                              2130\n",
      "McEachern Hall_Amp Spots                                            1790\n",
      "Rogers_AMP Spots                                                    1618\n",
      "McCluskey Services Visitor Spaces                                   1572\n",
      "Thatuna & Linden Lots/Streetside: Football General Parking          1411\n",
      "Forest Way (Red 4) Lots: Football General Parking                   1391\n",
      "McClusky: Football General Parking                                  1298\n",
      "Perham Rear Entrance AMP spot                                       1141\n",
      "Red 1 Grimes Feed Lot                                                988\n",
      "SPARK: Football General Parking                                      982\n",
      "Carver Farms Lot: Football General Parking                           852\n",
      "Daggy Garage                                                         837\n",
      "Spokane St Gravel Lots: Football General Parking                     829\n",
      "Cougar Way: Football General Parking                                 711\n",
      "PACCAR: (Don't Activate)                                             568\n",
      "Spring Street Lot                                                    482\n",
      "Orton_Amp Spots                                                      387\n",
      "McCoy Hall Lot: Football General Parking                             377\n",
      "Streit-Perham Lot: Football General Parking                          242\n",
      "Environmental Health Services                                        199\n",
      "B St Lots: Football General Parking                                  159\n",
      "Green 1 Bustad Lot                                                   144\n",
      "Green 2 McAllister                                                    29\n",
      "Testing Zone with an extra long label to read (Don't activate)        22\n",
      "Disability Parking CUE (Don't Activate)                                9\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Start with the already cleaned AMP data\n",
    "amp_only = amp_clean.copy()\n",
    "\n",
    "# Add zone type classification based on Zone_Name\n",
    "def classify_zone_type(zone_name):\n",
    "    \"\"\"\n",
    "    Classify zone type based on zone name.\n",
    "    \"\"\"\n",
    "    zone_name = str(zone_name).lower()\n",
    "    \n",
    "    if any(x in zone_name for x in ['orange', 'garage']):\n",
    "        return 'Paid'\n",
    "    elif any(x in zone_name for x in ['gray', 'crimson', 'resident']):\n",
    "        return 'Resident'\n",
    "    else:\n",
    "        return 'Permit'\n",
    "\n",
    "amp_only['zone_type'] = amp_only['Zone'].apply(classify_zone_type)\n",
    "\n",
    "print(\"Zone type distribution:\")\n",
    "print(amp_only['zone_type'].value_counts())\n",
    "\n",
    "# Show sample of unique zones\n",
    "print(\"\\nUnique zones in data:\")\n",
    "print(amp_only['Zone'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Hourly Parking Events from Sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanded 1,000 sessions into 3,422 hourly records\n",
      "\n",
      "Sample of hourly data:\n",
      "             datetime                          zone zone_type   semester\n",
      "0 2020-08-10 07:00:00   Cougar Way on Street Meters    Permit  Fall 2020\n",
      "1 2020-08-10 08:00:00   Cougar Way on Street Meters    Permit  Fall 2020\n",
      "2 2020-08-10 08:00:00  Thatuna Rd. on Street Meters    Permit  Fall 2020\n",
      "3 2020-08-10 09:00:00  Thatuna Rd. on Street Meters    Permit  Fall 2020\n",
      "4 2020-08-10 08:00:00                Library Garage      Paid  Fall 2020\n",
      "5 2020-08-10 09:00:00                Library Garage      Paid  Fall 2020\n",
      "6 2020-08-10 08:00:00          Green 1 PACCAR South    Permit  Fall 2020\n",
      "7 2020-08-10 09:00:00          Green 1 PACCAR South    Permit  Fall 2020\n",
      "8 2020-08-10 09:00:00                Library Garage      Paid  Fall 2020\n",
      "9 2020-08-18 11:00:00                    CUE Garage      Paid  Fall 2020\n"
     ]
    }
   ],
   "source": [
    "# For each parking session, create hourly records\n",
    "# This helps track occupancy over time\n",
    "\n",
    "def expand_session_to_hours(row):\n",
    "    \"\"\"\n",
    "    Expand a parking session into hourly records.\n",
    "    Each hour the vehicle was parked creates one record.\n",
    "    \"\"\"\n",
    "    start = row['Start_Date']\n",
    "    end = row['End_Date']\n",
    "    \n",
    "    # Create hourly range\n",
    "    hours = pd.date_range(start=start.floor('h'), end=end.floor('h'), freq='h')\n",
    "    \n",
    "    return hours\n",
    "\n",
    "# Sample first 1000 rows for demonstration (processing all rows may take time)\n",
    "sample_amp = amp_only.head(1000).copy()\n",
    "\n",
    "# Expand to hourly records\n",
    "hourly_records = []\n",
    "for idx, row in sample_amp.iterrows():\n",
    "    hours = expand_session_to_hours(row)\n",
    "    for hour in hours:\n",
    "        hourly_records.append({\n",
    "            'datetime': hour,\n",
    "            'zone': row['Zone'],\n",
    "            'zone_type': row['zone_type'],\n",
    "            'semester': row['semester']\n",
    "        })\n",
    "\n",
    "hourly_df = pd.DataFrame(hourly_records)\n",
    "\n",
    "print(f\"Expanded {len(sample_amp):,} sessions into {len(hourly_df):,} hourly records\")\n",
    "print(\"\\nSample of hourly data:\")\n",
    "print(hourly_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Hourly Occupancy per Zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hourly occupancy data:\n",
      "              datetime                                   zone zone_type  \\\n",
      "0  2020-08-10 07:00:00            Cougar Way on Street Meters    Permit   \n",
      "1  2020-08-10 08:00:00            Cougar Way on Street Meters    Permit   \n",
      "2  2020-08-10 08:00:00                   Green 1 PACCAR South    Permit   \n",
      "3  2020-08-10 08:00:00                         Library Garage      Paid   \n",
      "4  2020-08-10 08:00:00           Thatuna Rd. on Street Meters    Permit   \n",
      "5  2020-08-10 09:00:00                   Green 1 PACCAR South    Permit   \n",
      "6  2020-08-10 09:00:00                         Library Garage      Paid   \n",
      "7  2020-08-10 09:00:00           Thatuna Rd. on Street Meters    Permit   \n",
      "8  2020-08-18 11:00:00                             CUE Garage      Paid   \n",
      "9  2020-08-18 12:00:00                             CUE Garage      Paid   \n",
      "10 2020-08-18 12:00:00  Green 3: College Avenue -or- Idaho St    Permit   \n",
      "11 2020-08-18 12:00:00           Wilson Road on Street Meters    Permit   \n",
      "12 2020-08-18 13:00:00                             CUE Garage      Paid   \n",
      "13 2020-08-18 13:00:00  Green 3: College Avenue -or- Idaho St    Permit   \n",
      "14 2020-08-18 13:00:00           Wilson Road on Street Meters    Permit   \n",
      "15 2020-08-18 14:00:00                             CUE Garage      Paid   \n",
      "16 2020-08-18 14:00:00           Wilson Road on Street Meters    Permit   \n",
      "17 2020-08-18 15:00:00                             CUE Garage      Paid   \n",
      "18 2020-08-18 15:00:00           Wilson Road on Street Meters    Permit   \n",
      "19 2020-08-18 16:00:00                             CUE Garage      Paid   \n",
      "\n",
      "     semester  vehicle_count  \n",
      "0   Fall 2020              1  \n",
      "1   Fall 2020              1  \n",
      "2   Fall 2020              1  \n",
      "3   Fall 2020              1  \n",
      "4   Fall 2020              1  \n",
      "5   Fall 2020              1  \n",
      "6   Fall 2020              2  \n",
      "7   Fall 2020              1  \n",
      "8   Fall 2020              1  \n",
      "9   Fall 2020              1  \n",
      "10  Fall 2020              1  \n",
      "11  Fall 2020              1  \n",
      "12  Fall 2020              1  \n",
      "13  Fall 2020              1  \n",
      "14  Fall 2020              1  \n",
      "15  Fall 2020              1  \n",
      "16  Fall 2020              1  \n",
      "17  Fall 2020              1  \n",
      "18  Fall 2020              1  \n",
      "19  Fall 2020              1  \n",
      "\n",
      "Occupancy statistics by zone:\n",
      "                                            count      mean       std  min  \\\n",
      "zone                                                                         \n",
      "Bustad - AMP Marked spots                    69.0  3.159420  1.975014  1.0   \n",
      "CUE Garage                                  229.0  3.646288  2.561823  1.0   \n",
      "Columbia Street Lot Top Bays                 86.0  2.662791  1.712312  1.0   \n",
      "Cougar Way on Street Meters                 107.0  1.186916  0.415066  1.0   \n",
      "ESF Cultural Center Lot                       1.0  1.000000       NaN  1.0   \n",
      "Green 1 PACCAR South                         71.0  1.577465  0.889012  1.0   \n",
      "Green 2 McAllister                            8.0  1.000000  0.000000  1.0   \n",
      "Green 3: (Gravel lot) College/Spokane        27.0  1.259259  0.446576  1.0   \n",
      "Green 3: (Gravel lot) Columbia/Spokane        6.0  1.500000  0.836660  1.0   \n",
      "Green 3: College Avenue -or- Idaho St        40.0  1.200000  0.405096  1.0   \n",
      "Green 3: Washington St street-side & Spark   94.0  1.510638  0.813127  1.0   \n",
      "Green 4 Gravel Lot                           21.0  1.047619  0.218218  1.0   \n",
      "Green 5 South Beasley                       116.0  3.905172  2.280269  1.0   \n",
      "Library Garage                              195.0  2.020513  1.235051  1.0   \n",
      "Red 1 Cooper East                            30.0  1.266667  0.449776  1.0   \n",
      "Red 1 Grimes Feed Lot                        11.0  1.000000  0.000000  1.0   \n",
      "Red 5 Tennis Courts Lot                      54.0  1.277778  0.529031  1.0   \n",
      "Thatuna Rd. on Street Meters                186.0  1.580645  0.816354  1.0   \n",
      "Wilson Road on Street Meters                 96.0  2.750000  1.562724  1.0   \n",
      "Yellow 1 IPF Lot                             78.0  1.461538  0.501745  1.0   \n",
      "\n",
      "                                             25%  50%   75%   max  \n",
      "zone                                                               \n",
      "Bustad - AMP Marked spots                   1.00  3.0  5.00   9.0  \n",
      "CUE Garage                                  2.00  3.0  5.00  14.0  \n",
      "Columbia Street Lot Top Bays                1.00  2.0  3.75   7.0  \n",
      "Cougar Way on Street Meters                 1.00  1.0  1.00   3.0  \n",
      "ESF Cultural Center Lot                     1.00  1.0  1.00   1.0  \n",
      "Green 1 PACCAR South                        1.00  1.0  2.00   5.0  \n",
      "Green 2 McAllister                          1.00  1.0  1.00   1.0  \n",
      "Green 3: (Gravel lot) College/Spokane       1.00  1.0  1.50   2.0  \n",
      "Green 3: (Gravel lot) Columbia/Spokane      1.00  1.0  1.75   3.0  \n",
      "Green 3: College Avenue -or- Idaho St       1.00  1.0  1.00   2.0  \n",
      "Green 3: Washington St street-side & Spark  1.00  1.0  2.00   5.0  \n",
      "Green 4 Gravel Lot                          1.00  1.0  1.00   2.0  \n",
      "Green 5 South Beasley                       2.00  3.0  6.00  11.0  \n",
      "Library Garage                              1.00  1.0  3.00   5.0  \n",
      "Red 1 Cooper East                           1.00  1.0  1.75   2.0  \n",
      "Red 1 Grimes Feed Lot                       1.00  1.0  1.00   1.0  \n",
      "Red 5 Tennis Courts Lot                     1.00  1.0  1.00   3.0  \n",
      "Thatuna Rd. on Street Meters                1.00  1.0  2.00   4.0  \n",
      "Wilson Road on Street Meters                1.75  3.0  3.00   9.0  \n",
      "Yellow 1 IPF Lot                            1.00  1.0  2.00   2.0  \n"
     ]
    }
   ],
   "source": [
    "# Count vehicles per hour per zone\n",
    "occupancy = hourly_df.groupby(['datetime', 'zone', 'zone_type', 'semester']).size().reset_index(name='vehicle_count')\n",
    "\n",
    "print(\"Hourly occupancy data:\")\n",
    "print(occupancy.head(20))\n",
    "\n",
    "print(\"\\nOccupancy statistics by zone:\")\n",
    "print(occupancy.groupby('zone')['vehicle_count'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Preprocessed Data (Approach 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approach 2 data saved:\n",
      "  ../data/processed/amp_only_preprocessed.csv (1,702,867 rows)\n",
      "  ../data/processed/hourly_occupancy_sample.csv (1,525 rows)\n"
     ]
    }
   ],
   "source": [
    "# Save AMP-only preprocessed data\n",
    "amp_only.to_csv('../data/processed/amp_only_preprocessed.csv', index=False)\n",
    "\n",
    "# Save sample hourly occupancy (for demonstration)\n",
    "occupancy.to_csv('../data/processed/hourly_occupancy_sample.csv', index=False)\n",
    "\n",
    "print(\"Approach 2 data saved:\")\n",
    "print(f\"  ../data/processed/amp_only_preprocessed.csv ({len(amp_only):,} rows)\")\n",
    "print(f\"  ../data/processed/hourly_occupancy_sample.csv ({len(occupancy):,} rows)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Quality Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATA PREPROCESSING SUMMARY\n",
      "============================================================\n",
      "\n",
      "APPROACH 1: AMP + LPR (with lot mapping)\n",
      "  AMP records: 1,702,867\n",
      "  LPR records: 1,780,391\n",
      "  LPR mapping coverage: 100.0%\n",
      "  Date range: 2020-08-10 to 2025-11-02\n",
      "  Semesters covered: 16\n",
      "\n",
      "APPROACH 2: AMP only\n",
      "  AMP records: 1,702,867\n",
      "  Unique zones: 63\n",
      "  Zone types: {'Permit': 1009019, 'Paid': 693848}\n",
      "  Date range: 2020-08-10 to 2025-11-02\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"DATA PREPROCESSING SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nAPPROACH 1: AMP + LPR (with lot mapping)\")\n",
    "print(f\"  AMP records: {len(amp_clean):,}\")\n",
    "print(f\"  LPR records: {len(lpr_mapped):,}\")\n",
    "print(f\"  LPR mapping coverage: {coverage_pct:.1f}%\")\n",
    "print(f\"  Date range: {amp_clean['Start_Date'].min().date()} to {amp_clean['End_Date'].max().date()}\")\n",
    "print(f\"  Semesters covered: {amp_clean['semester'].nunique()}\")\n",
    "\n",
    "print(\"\\nAPPROACH 2: AMP only\")\n",
    "print(f\"  AMP records: {len(amp_only):,}\")\n",
    "print(f\"  Unique zones: {amp_only['Zone'].nunique()}\")\n",
    "print(f\"  Zone types: {amp_only['zone_type'].value_counts().to_dict()}\")\n",
    "print(f\"  Date range: {amp_only['Start_Date'].min().date()} to {amp_only['End_Date'].max().date()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semester-Based Filtering Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fall 2023 AMP records: 219,145\n",
      "Fall 2023 LPR records: 323,961\n",
      "\n",
      "Weekday AMP records: 1,633,676\n",
      "Peak hours AMP records: 1,482,363\n",
      "\n",
      "Fall 2023 weekday peak hours: 180,024 records\n"
     ]
    }
   ],
   "source": [
    "# Example: Filter data for Fall 2023 semester\n",
    "fall_2023_amp = amp_clean[amp_clean['semester'] == 'Fall 2023']\n",
    "fall_2023_lpr = lpr_mapped[lpr_mapped['semester'] == 'Fall 2023']\n",
    "\n",
    "print(f\"Fall 2023 AMP records: {len(fall_2023_amp):,}\")\n",
    "print(f\"Fall 2023 LPR records: {len(fall_2023_lpr):,}\")\n",
    "\n",
    "# Example: Filter for weekdays only\n",
    "weekday_amp = amp_clean[amp_clean['is_weekend'] == 0]\n",
    "print(f\"\\nWeekday AMP records: {len(weekday_amp):,}\")\n",
    "\n",
    "# Example: Filter for peak hours (8 AM - 5 PM)\n",
    "peak_hours_amp = amp_clean[(amp_clean['hour'] >= 8) & (amp_clean['hour'] <= 17)]\n",
    "print(f\"Peak hours AMP records: {len(peak_hours_amp):,}\")\n",
    "\n",
    "# Example: Combine filters (Fall 2023, weekdays, peak hours)\n",
    "filtered = amp_clean[\n",
    "    (amp_clean['semester'] == 'Fall 2023') & \n",
    "    (amp_clean['is_weekend'] == 0) &\n",
    "    (amp_clean['hour'] >= 8) & \n",
    "    (amp_clean['hour'] <= 17)\n",
    "]\n",
    "print(f\"\\nFall 2023 weekday peak hours: {len(filtered):,} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Semester-Based Filtering (2020-2025)\n",
    "\n",
    "Comprehensive filtering examples for all available semesters in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "COMPREHENSIVE SEMESTER FILTERING GUIDE (2020-2025)\n",
      "==================================================\n",
      "\n",
      "Total semesters available: 16\n",
      "\n",
      "ALL AVAILABLE SEMESTERS:\n",
      "  Fall 2020       | AMP:   10,518 records | LPR:        0 records\n",
      "  Fall 2021       | AMP:   76,206 records | LPR:        0 records\n",
      "  Fall 2022       | AMP:  138,616 records | LPR:  165,863 records\n",
      "  Fall 2023       | AMP:  219,145 records | LPR:  323,961 records\n",
      "  Fall 2024       | AMP:  221,559 records | LPR:  312,261 records\n",
      "  Fall 2025       | AMP:  138,565 records | LPR:        0 records\n",
      "  Spring 2021     | AMP:   20,202 records | LPR:        0 records\n",
      "  Spring 2022     | AMP:  109,230 records | LPR:        0 records\n",
      "  Spring 2023     | AMP:  203,690 records | LPR:  314,784 records\n",
      "  Spring 2024     | AMP:  235,645 records | LPR:  258,281 records\n",
      "  Spring 2025     | AMP:  240,084 records | LPR:  271,918 records\n",
      "  Summer 2021     | AMP:    7,184 records | LPR:        0 records\n",
      "  Summer 2022     | AMP:   12,591 records | LPR:   20,571 records\n",
      "  Summer 2023     | AMP:   20,971 records | LPR:   25,893 records\n",
      "  Summer 2024     | AMP:   24,688 records | LPR:   54,947 records\n",
      "  Summer 2025     | AMP:   23,973 records | LPR:   31,912 records\n",
      "\n",
      "==================================================\n",
      "FILTERING EXAMPLES BY YEAR\n",
      "==================================================\n",
      "\n",
      "### YEAR 2020 ###\n",
      "\n",
      "Fall 2020:\n",
      "  All records: 10,518\n",
      "  Weekdays only: 10,123\n",
      "  Peak hours (8AM-5PM): 8,846\n",
      "  Weekdays + Peak hours: 8,517\n",
      "  Date range: 2020-08-10 to 2020-12-31\n",
      "\n",
      "### YEAR 2021 ###\n",
      "\n",
      "Fall 2021:\n",
      "  All records: 76,206\n",
      "  Weekdays only: 70,600\n",
      "  Peak hours (8AM-5PM): 67,276\n",
      "  Weekdays + Peak hours: 62,606\n",
      "  Date range: 2021-08-01 to 2021-12-23\n",
      "\n",
      "Spring 2021:\n",
      "  All records: 20,202\n",
      "  Weekdays only: 19,405\n",
      "  Peak hours (8AM-5PM): 17,625\n",
      "  Weekdays + Peak hours: 16,943\n",
      "  Date range: 2021-01-01 to 2021-05-31\n",
      "\n",
      "Summer 2021:\n",
      "  All records: 7,184\n",
      "  Weekdays only: 7,044\n",
      "  Peak hours (8AM-5PM): 6,313\n",
      "  Weekdays + Peak hours: 6,190\n",
      "  Date range: 2021-06-01 to 2021-07-31\n",
      "\n",
      "### YEAR 2022 ###\n",
      "\n",
      "Fall 2022:\n",
      "  All records: 138,616\n",
      "  Weekdays only: 130,322\n",
      "  Peak hours (8AM-5PM): 123,994\n",
      "  Weekdays + Peak hours: 117,018\n",
      "  Date range: 2022-08-01 to 2022-12-31\n",
      "\n",
      "Spring 2022:\n",
      "  All records: 109,230\n",
      "  Weekdays only: 103,972\n",
      "  Peak hours (8AM-5PM): 97,114\n",
      "  Weekdays + Peak hours: 93,037\n",
      "  Date range: 2022-01-03 to 2022-05-31\n",
      "\n",
      "Summer 2022:\n",
      "  All records: 12,591\n",
      "  Weekdays only: 12,236\n",
      "  Peak hours (8AM-5PM): 11,400\n",
      "  Weekdays + Peak hours: 11,095\n",
      "  Date range: 2022-06-01 to 2022-07-31\n",
      "\n",
      "### YEAR 2023 ###\n",
      "\n",
      "Fall 2023:\n",
      "  All records: 219,145\n",
      "  Weekdays only: 209,650\n",
      "  Peak hours (8AM-5PM): 188,176\n",
      "  Weekdays + Peak hours: 180,024\n",
      "  Date range: 2023-08-01 to 2023-12-31\n",
      "\n",
      "Spring 2023:\n",
      "  All records: 203,690\n",
      "  Weekdays only: 195,981\n",
      "  Peak hours (8AM-5PM): 176,829\n",
      "  Weekdays + Peak hours: 170,864\n",
      "  Date range: 2023-01-01 to 2023-05-31\n",
      "\n",
      "Summer 2023:\n",
      "  All records: 20,971\n",
      "  Weekdays only: 20,464\n",
      "  Peak hours (8AM-5PM): 17,614\n",
      "  Weekdays + Peak hours: 17,186\n",
      "  Date range: 2023-06-01 to 2023-07-31\n",
      "\n",
      "### YEAR 2024 ###\n",
      "\n",
      "Fall 2024:\n",
      "  All records: 221,559\n",
      "  Weekdays only: 213,388\n",
      "  Peak hours (8AM-5PM): 191,612\n",
      "  Weekdays + Peak hours: 184,964\n",
      "  Date range: 2024-08-01 to 2024-12-31\n",
      "\n",
      "Spring 2024:\n",
      "  All records: 235,645\n",
      "  Weekdays only: 228,051\n",
      "  Peak hours (8AM-5PM): 206,227\n",
      "  Weekdays + Peak hours: 200,209\n",
      "  Date range: 2024-01-01 to 2024-05-31\n",
      "\n",
      "Summer 2024:\n",
      "  All records: 24,688\n",
      "  Weekdays only: 24,056\n",
      "  Peak hours (8AM-5PM): 20,891\n",
      "  Weekdays + Peak hours: 20,335\n",
      "  Date range: 2024-06-01 to 2024-07-31\n",
      "\n",
      "### YEAR 2025 ###\n",
      "\n",
      "Fall 2025:\n",
      "  All records: 138,565\n",
      "  Weekdays only: 131,296\n",
      "  Peak hours (8AM-5PM): 118,743\n",
      "  Weekdays + Peak hours: 112,681\n",
      "  Date range: 2025-08-01 to 2025-10-31\n",
      "\n",
      "Spring 2025:\n",
      "  All records: 240,084\n",
      "  Weekdays only: 233,541\n",
      "  Peak hours (8AM-5PM): 209,887\n",
      "  Weekdays + Peak hours: 204,470\n",
      "  Date range: 2025-01-02 to 2025-05-31\n",
      "\n",
      "Summer 2025:\n",
      "  All records: 23,973\n",
      "  Weekdays only: 23,547\n",
      "  Peak hours (8AM-5PM): 19,816\n",
      "  Weekdays + Peak hours: 19,433\n",
      "  Date range: 2025-06-01 to 2025-07-31\n"
     ]
    }
   ],
   "source": [
    "# Create comprehensive semester filtering summary for ALL years\n",
    "print(\"=\"*50)\n",
    "print(\"COMPREHENSIVE SEMESTER FILTERING GUIDE (2020-2025)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Get all unique semesters\n",
    "all_semesters = sorted(amp_clean['semester'].unique())\n",
    "\n",
    "print(f\"\\nTotal semesters available: {len(all_semesters)}\")\n",
    "print(\"\\nALL AVAILABLE SEMESTERS:\")\n",
    "for sem in all_semesters:\n",
    "    amp_count = len(amp_clean[amp_clean['semester'] == sem])\n",
    "    lpr_count = len(lpr_mapped[lpr_mapped['semester'] == sem])\n",
    "    print(f\"  {sem:15} | AMP: {amp_count:>8,} records | LPR: {lpr_count:>8,} records\")\n",
    "\n",
    "# Show filtering examples for each year\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"FILTERING EXAMPLES BY YEAR\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "for year in [2020, 2021, 2022, 2023, 2024, 2025]:\n",
    "    print(f\"\\n### YEAR {year} ###\")\n",
    "    \n",
    "    # Get all semesters for this year\n",
    "    year_semesters = [s for s in all_semesters if str(year) in s]\n",
    "    \n",
    "    if not year_semesters:\n",
    "        print(f\"  No data available for {year}\")\n",
    "        continue\n",
    "    \n",
    "    # Show each semester for this year\n",
    "    for semester in year_semesters:\n",
    "        semester_data = amp_clean[amp_clean['semester'] == semester]\n",
    "        \n",
    "        # Basic filter\n",
    "        print(f\"\\n{semester}:\")\n",
    "        print(f\"  All records: {len(semester_data):,}\")\n",
    "        \n",
    "        # Weekday filter\n",
    "        weekday_data = semester_data[semester_data['is_weekend'] == 0]\n",
    "        print(f\"  Weekdays only: {len(weekday_data):,}\")\n",
    "        \n",
    "        # Peak hours filter\n",
    "        peak_data = semester_data[(semester_data['hour'] >= 8) & (semester_data['hour'] <= 17)]\n",
    "        print(f\"  Peak hours (8AM-5PM): {len(peak_data):,}\")\n",
    "        \n",
    "        # Combined filter: weekdays + peak hours\n",
    "        combined = semester_data[\n",
    "            (semester_data['is_weekend'] == 0) &\n",
    "            (semester_data['hour'] >= 8) &\n",
    "            (semester_data['hour'] <= 17)\n",
    "        ]\n",
    "        print(f\"  Weekdays + Peak hours: {len(combined):,}\")\n",
    "        \n",
    "        # Show date range\n",
    "        print(f\"  Date range: {semester_data['Start_Date'].min().date()} to {semester_data['Start_Date'].max().date()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
