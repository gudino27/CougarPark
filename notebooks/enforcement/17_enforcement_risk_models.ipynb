{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3dbe4a2",
   "metadata": {},
   "source": [
    "# Enforcement Risk Prediction Models\n",
    "\n",
    "Build machine learning models to predict parking ticket risk.\n",
    "\n",
    "## Business Question\n",
    "\n",
    "**\"If I park without a permit in zone X at time Y, what's my risk of getting a ticket?\"**\n",
    "\n",
    "## Approach\n",
    "\n",
    "We'll build multiple model types:\n",
    "1. **Classification**: Will I get a ticket? (Yes/No)\n",
    "2. **Regression**: How many tickets are expected in this zone-hour?\n",
    "3. **Risk Score**: Probability of enforcement (0-100%)\n",
    "\n",
    "## Data\n",
    "\n",
    "Using `enforcement_with_features.csv` from notebook 15:\n",
    "- Zone-hour aggregates with engineered features\n",
    "- Calendar events, weather, camera classification\n",
    "- Historical enforcement patterns\n",
    "\n",
    "## Models to Test\n",
    "\n",
    "- Logistic Regression (baseline)\n",
    "- Random Forest\n",
    "- XGBoost\n",
    "- Neural Network (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b2397a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, roc_auc_score, roc_curve,\n",
    "    mean_squared_error, mean_absolute_error, r2_score\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingClassifier\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "print(\"✓ Libraries loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2fb15e",
   "metadata": {},
   "source": [
    "## Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694076ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load enforcement data with features (from notebook 15)\n",
    "df = pd.read_csv('../../data/processed/enforcement_with_features.csv', parse_dates=['date', 'datetime'])\n",
    "\n",
    "print(f\"Data loaded: {len(df):,} zone-hour records\")\n",
    "print(f\"Date range: {df['date'].min()} to {df['date'].max()}\")\n",
    "print(f\"Zones: {df['Zone'].nunique()}\")\n",
    "print(f\"\\nColumns: {len(df.columns)}\")\n",
    "print(f\"\\nSample features: {list(df.columns[:20])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d2a29a",
   "metadata": {},
   "source": [
    "## Feature Selection & Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c67f9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature columns for modeling\n",
    "# Numerical features\n",
    "numerical_features = [\n",
    "    'lpr_scans',\n",
    "    'amp_sessions',\n",
    "    'unpaid_estimate',\n",
    "    'compliance_ratio',\n",
    "    'zone_avg_enforcement',\n",
    "    'vulnerability_score',\n",
    "    'hour',\n",
    "    'day_of_week',\n",
    "    'month',\n",
    "]\n",
    "\n",
    "# Weather features (if available)\n",
    "if 'temperature_f' in df.columns:\n",
    "    numerical_features.extend(['temperature_f', 'precipitation_inches', 'wind_mph'])\n",
    "elif 'temperature' in df.columns:\n",
    "    numerical_features.extend(['temperature', 'precipitation'])\n",
    "\n",
    "# Camera features (from notebook 16)\n",
    "if 'entrance_camera_score' in df.columns:\n",
    "    numerical_features.extend(['entrance_camera_score', 'bulk_patrol_score', 'avg_scans_per_active_hour'])\n",
    "\n",
    "# Binary features\n",
    "binary_features = [\n",
    "    'is_weekend',\n",
    "    'is_game_day',\n",
    "    'is_finals_week',\n",
    "    'is_any_break',\n",
    "    'high_risk',\n",
    "]\n",
    "\n",
    "# Weather binary features\n",
    "if 'is_rainy' in df.columns:\n",
    "    binary_features.extend(['is_rainy', 'is_snowy', 'is_cold'])\n",
    "\n",
    "# Camera binary feature\n",
    "if 'has_fixed_camera' in df.columns:\n",
    "    binary_features.append('has_fixed_camera')\n",
    "\n",
    "# Categorical features (need encoding)\n",
    "categorical_features = ['Zone', 'time_of_day']\n",
    "\n",
    "# Target variables\n",
    "target_classification = 'has_ticket'  # Binary: any tickets issued?\n",
    "target_regression = 'tickets_issued'  # Count: how many tickets?\n",
    "\n",
    "# Create binary classification target\n",
    "df['has_ticket'] = (df['tickets_issued'] > 0).astype(int)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"FEATURE SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nNumerical features ({len(numerical_features)}):\")\n",
    "for f in numerical_features:\n",
    "    if f in df.columns:\n",
    "        print(f\"  ✓ {f}\")\n",
    "    else:\n",
    "        print(f\"  ✗ {f} (missing)\")\n",
    "\n",
    "print(f\"\\nBinary features ({len(binary_features)}):\")\n",
    "for f in binary_features:\n",
    "    if f in df.columns:\n",
    "        print(f\"  ✓ {f}\")\n",
    "    else:\n",
    "        print(f\"  ✗ {f} (missing)\")\n",
    "\n",
    "print(f\"\\nCategorical features ({len(categorical_features)}):\")\n",
    "for f in categorical_features:\n",
    "    if f in df.columns:\n",
    "        print(f\"  ✓ {f} ({df[f].nunique()} unique values)\")\n",
    "\n",
    "print(f\"\\nTarget variables:\")\n",
    "print(f\"  Classification: {target_classification}\")\n",
    "print(f\"    - Positive cases (has ticket): {df['has_ticket'].sum():,} ({df['has_ticket'].mean()*100:.2f}%)\")\n",
    "print(f\"    - Negative cases (no ticket): {(df['has_ticket']==0).sum():,} ({(df['has_ticket']==0).mean()*100:.2f}%)\")\n",
    "print(f\"  Regression: {target_regression}\")\n",
    "print(f\"    - Mean tickets: {df['tickets_issued'].mean():.3f}\")\n",
    "print(f\"    - Max tickets: {df['tickets_issued'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a93b83f",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157a6e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter valid features that exist in the dataset\n",
    "numerical_features = [f for f in numerical_features if f in df.columns]\n",
    "binary_features = [f for f in binary_features if f in df.columns]\n",
    "categorical_features = [f for f in categorical_features if f in df.columns]\n",
    "\n",
    "# Handle missing values\n",
    "print(\"Handling missing values...\")\n",
    "for col in numerical_features:\n",
    "    if df[col].isna().sum() > 0:\n",
    "        print(f\"  Filling {col}: {df[col].isna().sum()} missing values\")\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "# One-hot encode categorical features\n",
    "print(f\"\\nEncoding categorical features...\")\n",
    "df_encoded = df.copy()\n",
    "for col in categorical_features:\n",
    "    dummies = pd.get_dummies(df[col], prefix=col, drop_first=True)\n",
    "    df_encoded = pd.concat([df_encoded, dummies], axis=1)\n",
    "    print(f\"  {col}: Created {len(dummies.columns)} dummy variables\")\n",
    "\n",
    "# Get all feature column names (numerical + binary + encoded categorical)\n",
    "encoded_cat_cols = [col for col in df_encoded.columns if any(col.startswith(f\"{cat}_\") for cat in categorical_features)]\n",
    "all_features = numerical_features + binary_features + encoded_cat_cols\n",
    "\n",
    "print(f\"\\nTotal features for modeling: {len(all_features)}\")\n",
    "\n",
    "# Create feature matrix X and targets y\n",
    "X = df_encoded[all_features].copy()\n",
    "y_class = df_encoded[target_classification]\n",
    "y_reg = df_encoded[target_regression]\n",
    "\n",
    "print(f\"\\nFeature matrix shape: {X.shape}\")\n",
    "print(f\"Classification target shape: {y_class.shape}\")\n",
    "print(f\"Regression target shape: {y_reg.shape}\")\n",
    "\n",
    "# Check for any remaining NaN values\n",
    "if X.isna().sum().sum() > 0:\n",
    "    print(f\"\\n WARNING: {X.isna().sum().sum()} NaN values remaining!\")\n",
    "    print(\"Columns with NaN:\")\n",
    "    print(X.isna().sum()[X.isna().sum() > 0])\n",
    "    # Fill remaining NaN with 0\n",
    "    X = X.fillna(0)\n",
    "    print(\"✓ Filled remaining NaN with 0\")\n",
    "else:\n",
    "    print(\"\\n✓ No missing values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a29118",
   "metadata": {},
   "source": [
    "## Train-Test Split\n",
    "\n",
    "Use **temporal split** (not random) to avoid data leakage:\n",
    "- Training: Earlier time periods\n",
    "- Testing: Most recent time period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1205bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal split: Use last 20% of data as test set\n",
    "split_date = df_encoded['date'].quantile(0.8)\n",
    "\n",
    "train_mask = df_encoded['date'] < split_date\n",
    "test_mask = df_encoded['date'] >= split_date\n",
    "\n",
    "X_train = X[train_mask]\n",
    "X_test = X[test_mask]\n",
    "y_train_class = y_class[train_mask]\n",
    "y_test_class = y_class[test_mask]\n",
    "y_train_reg = y_reg[train_mask]\n",
    "y_test_reg = y_reg[test_mask]\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"TRAIN-TEST SPLIT (Temporal)\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nSplit date: {split_date}\")\n",
    "print(f\"\\nTraining set:\")\n",
    "print(f\"  Date range: {df_encoded[train_mask]['date'].min()} to {df_encoded[train_mask]['date'].max()}\")\n",
    "print(f\"  Records: {len(X_train):,} ({len(X_train)/len(X)*100:.1f}%)\")\n",
    "print(f\"  Tickets: {y_train_class.sum():,} ({y_train_class.mean()*100:.2f}% positive rate)\")\n",
    "\n",
    "print(f\"\\nTest set:\")\n",
    "print(f\"  Date range: {df_encoded[test_mask]['date'].min()} to {df_encoded[test_mask]['date'].max()}\")\n",
    "print(f\"  Records: {len(X_test):,} ({len(X_test)/len(X)*100:.1f}%)\")\n",
    "print(f\"  Tickets: {y_test_class.sum():,} ({y_test_class.mean()*100:.2f}% positive rate)\")\n",
    "\n",
    "# Scale features (important for logistic regression and neural networks)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"\\n✓ Features scaled using StandardScaler\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e325a7dc",
   "metadata": {},
   "source": [
    "## Model 1: Logistic Regression (Baseline)\n",
    "\n",
    "Simple, interpretable baseline for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a503ce20",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"LOGISTIC REGRESSION - CLASSIFICATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Train model\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42, class_weight='balanced')\n",
    "lr_model.fit(X_train_scaled, y_train_class)\n",
    "\n",
    "# Predictions\n",
    "y_pred_lr = lr_model.predict(X_test_scaled)\n",
    "y_pred_lr_proba = lr_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Evaluation\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_class, y_pred_lr, target_names=['No Ticket', 'Ticket']))\n",
    "\n",
    "# ROC-AUC\n",
    "roc_auc_lr = roc_auc_score(y_test_class, y_pred_lr_proba)\n",
    "print(f\"ROC-AUC Score: {roc_auc_lr:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm_lr = confusion_matrix(y_test_class, y_pred_lr)\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(cm_lr)\n",
    "\n",
    "# Feature importance (top 20)\n",
    "feature_importance_lr = pd.DataFrame({\n",
    "    'feature': all_features,\n",
    "    'coefficient': lr_model.coef_[0]\n",
    "}).sort_values('coefficient', key=abs, ascending=False)\n",
    "\n",
    "print(f\"\\nTop 20 Most Important Features:\")\n",
    "print(feature_importance_lr.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d70460b",
   "metadata": {},
   "source": [
    "## Model 2: Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4ed3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"RANDOM FOREST - CLASSIFICATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Train model (use unscaled data for tree-based models)\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=15,\n",
    "    min_samples_split=100,\n",
    "    min_samples_leaf=50,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Training Random Forest (this may take a few minutes)...\")\n",
    "rf_model.fit(X_train, y_train_class)\n",
    "\n",
    "# Predictions\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "y_pred_rf_proba = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluation\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_class, y_pred_rf, target_names=['No Ticket', 'Ticket']))\n",
    "\n",
    "# ROC-AUC\n",
    "roc_auc_rf = roc_auc_score(y_test_class, y_pred_rf_proba)\n",
    "print(f\"ROC-AUC Score: {roc_auc_rf:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm_rf = confusion_matrix(y_test_class, y_pred_rf)\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(cm_rf)\n",
    "\n",
    "# Feature importance\n",
    "feature_importance_rf = pd.DataFrame({\n",
    "    'feature': all_features,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(f\"\\nTop 20 Most Important Features:\")\n",
    "print(feature_importance_rf.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74b1062",
   "metadata": {},
   "source": [
    "## Model 3: XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005f6bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"XGBOOST - CLASSIFICATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Calculate scale_pos_weight for class imbalance\n",
    "scale_pos_weight = (y_train_class == 0).sum() / (y_train_class == 1).sum()\n",
    "\n",
    "# Train model\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    learning_rate=0.1,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "print(f\"Training XGBoost (scale_pos_weight={scale_pos_weight:.2f})...\")\n",
    "xgb_model.fit(X_train, y_train_class)\n",
    "\n",
    "# Predictions\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "y_pred_xgb_proba = xgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluation\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_class, y_pred_xgb, target_names=['No Ticket', 'Ticket']))\n",
    "\n",
    "# ROC-AUC\n",
    "roc_auc_xgb = roc_auc_score(y_test_class, y_pred_xgb_proba)\n",
    "print(f\"ROC-AUC Score: {roc_auc_xgb:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm_xgb = confusion_matrix(y_test_class, y_pred_xgb)\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(cm_xgb)\n",
    "\n",
    "# Feature importance\n",
    "feature_importance_xgb = pd.DataFrame({\n",
    "    'feature': all_features,\n",
    "    'importance': xgb_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(f\"\\nTop 20 Most Important Features:\")\n",
    "print(feature_importance_xgb.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14feed2e",
   "metadata": {},
   "source": [
    "## Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5936b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare models\n",
    "print(\"=\"*80)\n",
    "print(\"MODEL COMPARISON - CLASSIFICATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "comparison = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'Random Forest', 'XGBoost'],\n",
    "    'ROC-AUC': [roc_auc_lr, roc_auc_rf, roc_auc_xgb]\n",
    "}).sort_values('ROC-AUC', ascending=False)\n",
    "\n",
    "print(\"\\n\" + comparison.to_string(index=False))\n",
    "print(f\"\\n Best model: {comparison.iloc[0]['Model']} (ROC-AUC: {comparison.iloc[0]['ROC-AUC']:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1831f4",
   "metadata": {},
   "source": [
    "## Visualize Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015c9891",
   "metadata": {},
   "source": [
    "## Advanced Improvements: Lag Features\n",
    "\n",
    "Similar to occupancy prediction, enforcement patterns have strong temporal autocorrelation.\n",
    "- **Previous hour enforcement** in same zone\n",
    "- **Previous day same hour** enforcement\n",
    "- **Rolling enforcement patterns** (3-hour, 24-hour)\n",
    "- **Zone-specific temporal patterns**\n",
    "\n",
    "**Goal**: Push ROC-AUC from 0.9778 to 0.985+ while eliminating any NaN issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ee7207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add lag features to the enforcement data\n",
    "print(\"=\"*80)\n",
    "print(\"ADDING TEMPORAL LAG FEATURES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Work with original df before encoding\n",
    "df_sorted = df.sort_values(['Zone', 'datetime']).reset_index(drop=True)\n",
    "\n",
    "def add_enforcement_lag_features(df):\n",
    "    \"\"\"Add temporal lag features for enforcement prediction\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # 1. Lag 1 hour (previous hour enforcement in same zone)\n",
    "    df['enforcement_lag_1'] = df.groupby('Zone')['has_ticket'].shift(1)\n",
    "    df['tickets_lag_1'] = df.groupby('Zone')['tickets_issued'].shift(1)\n",
    "    \n",
    "    # 2. Lag 24 hours (same hour yesterday)\n",
    "    df['enforcement_lag_24'] = df.groupby('Zone')['has_ticket'].shift(24)\n",
    "    df['tickets_lag_24'] = df.groupby('Zone')['tickets_issued'].shift(24)\n",
    "    \n",
    "    # 3. Rolling enforcement rate (last 3 hours)\n",
    "    df['enforcement_rolling_3'] = df.groupby('Zone')['has_ticket'].shift(1).rolling(\n",
    "        window=3, min_periods=1\n",
    "    ).mean().values\n",
    "    \n",
    "    # 4. Rolling enforcement rate (last 24 hours)\n",
    "    df['enforcement_rolling_24'] = df.groupby('Zone')['has_ticket'].shift(1).rolling(\n",
    "        window=24, min_periods=1\n",
    "    ).mean().values\n",
    "    \n",
    "    # 5. Rolling ticket count (last 24 hours)\n",
    "    df['tickets_rolling_24'] = df.groupby('Zone')['tickets_issued'].shift(1).rolling(\n",
    "        window=24, min_periods=1\n",
    "    ).sum().values\n",
    "    \n",
    "    # 6. Day-of-week + hour enforcement average (expanding mean to avoid leakage)\n",
    "    df['enforcement_dow_hour_avg'] = df.groupby(['Zone', 'day_of_week', 'hour'])['has_ticket'].transform(\n",
    "        lambda x: x.shift(1).expanding().mean()\n",
    "    )\n",
    "    \n",
    "    # Fill NaN values with 0 (for first observations) - CRITICAL FIX\n",
    "    lag_cols = [\n",
    "        'enforcement_lag_1', 'tickets_lag_1',\n",
    "        'enforcement_lag_24', 'tickets_lag_24',\n",
    "        'enforcement_rolling_3', 'enforcement_rolling_24',\n",
    "        'tickets_rolling_24', 'enforcement_dow_hour_avg'\n",
    "    ]\n",
    "    \n",
    "    for col in lag_cols:\n",
    "        # Fill NaN with 0\n",
    "        df[col] = df[col].fillna(0)\n",
    "        # Verify no NaN remaining\n",
    "        if df[col].isna().sum() > 0:\n",
    "            print(f\"⚠️ WARNING: {col} still has {df[col].isna().sum()} NaN values!\")\n",
    "            df[col] = df[col].fillna(0)  # Force fill\n",
    "    \n",
    "    return df, lag_cols\n",
    "\n",
    "# Apply lag features\n",
    "print(\"\\nCreating lag features...\")\n",
    "df_with_lags, lag_feature_names = add_enforcement_lag_features(df_sorted)\n",
    "\n",
    "print(f\"\\n✓ Added {len(lag_feature_names)} lag features:\")\n",
    "for col in lag_feature_names:\n",
    "    nan_count = df_with_lags[col].isna().sum()\n",
    "    print(f\"  ✓ {col} (NaN count: {nan_count})\")\n",
    "\n",
    "# Verify no NaN in lag features\n",
    "total_nan = df_with_lags[lag_feature_names].isna().sum().sum()\n",
    "if total_nan > 0:\n",
    "    print(f\"\\n⚠️ ERROR: {total_nan} NaN values remaining in lag features!\")\n",
    "    print(\"Forcing fill with 0...\")\n",
    "    df_with_lags[lag_feature_names] = df_with_lags[lag_feature_names].fillna(0)\n",
    "else:\n",
    "    print(f\"\\n All lag features clean - NO NaN values!\")\n",
    "\n",
    "print(f\"\\nNew dataframe shape: {df_with_lags.shape}\")\n",
    "print(f\"Original shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da63a925",
   "metadata": {},
   "source": [
    "### Prepare Features with Lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c4df9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features with lag variables\n",
    "print(\"=\"*80)\n",
    "print(\"FEATURE ENGINEERING WITH LAGS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# One-hot encode categorical features\n",
    "df_encoded_lags = df_with_lags.copy()\n",
    "for col in categorical_features:\n",
    "    dummies = pd.get_dummies(df_with_lags[col], prefix=col, drop_first=True)\n",
    "    df_encoded_lags = pd.concat([df_encoded_lags, dummies], axis=1)\n",
    "\n",
    "# Get encoded categorical columns\n",
    "encoded_cat_cols_lags = [col for col in df_encoded_lags.columns \n",
    "                         if any(col.startswith(f\"{cat}_\") for cat in categorical_features)]\n",
    "\n",
    "# Feature columns: original + lag features\n",
    "all_features_lags = numerical_features + binary_features + encoded_cat_cols_lags + lag_feature_names\n",
    "\n",
    "print(f\"\\nTotal features with lags: {len(all_features_lags)}\")\n",
    "print(f\"  Original features: {len(numerical_features + binary_features + encoded_cat_cols_lags)}\")\n",
    "print(f\"  Lag features: {len(lag_feature_names)}\")\n",
    "\n",
    "# Create feature matrix\n",
    "X_lags = df_encoded_lags[all_features_lags].copy()\n",
    "y_class_lags = df_encoded_lags['has_ticket']\n",
    "y_reg_lags = df_encoded_lags['tickets_issued']\n",
    "\n",
    "# Check for NaN values - CRITICAL\n",
    "print(f\"\\n NaN CHECK:\")\n",
    "nan_counts = X_lags.isna().sum()\n",
    "if nan_counts.sum() > 0:\n",
    "    print(f\"⚠️ WARNING: {nan_counts.sum()} NaN values found!\")\n",
    "    print(\"\\nColumns with NaN:\")\n",
    "    print(nan_counts[nan_counts > 0])\n",
    "    print(\"\\n Filling NaN values with 0...\")\n",
    "    X_lags = X_lags.fillna(0)\n",
    "    print(\" NaN values filled!\")\n",
    "else:\n",
    "    print(\" No NaN values detected!\")\n",
    "\n",
    "# Temporal split (same as before)\n",
    "split_date = df_encoded_lags['date'].quantile(0.8)\n",
    "\n",
    "train_mask_lags = df_encoded_lags['date'] < split_date\n",
    "test_mask_lags = df_encoded_lags['date'] >= split_date\n",
    "\n",
    "X_train_lags = X_lags[train_mask_lags]\n",
    "X_test_lags = X_lags[test_mask_lags]\n",
    "y_train_class_lags = y_class_lags[train_mask_lags]\n",
    "y_test_class_lags = y_class_lags[test_mask_lags]\n",
    "y_train_reg_lags = y_reg_lags[train_mask_lags]\n",
    "y_test_reg_lags = y_reg_lags[test_mask_lags]\n",
    "\n",
    "# Final NaN verification\n",
    "print(f\"\\n FINAL NaN VERIFICATION:\")\n",
    "print(f\"  X_train_lags NaN: {X_train_lags.isna().sum().sum()}\")\n",
    "print(f\"  X_test_lags NaN: {X_test_lags.isna().sum().sum()}\")\n",
    "print(f\"  y_train_class_lags NaN: {y_train_class_lags.isna().sum()}\")\n",
    "print(f\"  y_test_class_lags NaN: {y_test_class_lags.isna().sum()}\")\n",
    "\n",
    "if X_train_lags.isna().sum().sum() > 0 or X_test_lags.isna().sum().sum() > 0:\n",
    "    print(\"\\n EMERGENCY: Forcing all NaN to 0...\")\n",
    "    X_train_lags = X_train_lags.fillna(0)\n",
    "    X_test_lags = X_test_lags.fillna(0)\n",
    "\n",
    "print(f\"\\n Data prepared:\")\n",
    "print(f\"  Training: {len(X_train_lags):,} records\")\n",
    "print(f\"  Test: {len(X_test_lags):,} records\")\n",
    "print(f\"  Features: {len(all_features_lags)}\")\n",
    "print(f\"  NO NaN VALUES REMAINING!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84115347",
   "metadata": {},
   "source": [
    "### XGBoost with Lag Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8035e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train XGBoost with lag features\n",
    "print(\"=\"*80)\n",
    "print(\"XGBOOST WITH LAG FEATURES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Calculate scale_pos_weight for class imbalance\n",
    "scale_pos_weight_lags = (y_train_class_lags == 0).sum() / (y_train_class_lags == 1).sum()\n",
    "\n",
    "# Train XGBoost with more estimators\n",
    "xgb_model_lags = xgb.XGBClassifier(\n",
    "    n_estimators=150,  # Increased from 100\n",
    "    max_depth=10,\n",
    "    learning_rate=0.1,\n",
    "    scale_pos_weight=scale_pos_weight_lags,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "print(f\"Training XGBoost with {len(all_features_lags)} features (including {len(lag_feature_names)} lag features)...\")\n",
    "xgb_model_lags.fit(X_train_lags, y_train_class_lags)\n",
    "\n",
    "# Predictions\n",
    "y_pred_xgb_lags = xgb_model_lags.predict(X_test_lags)\n",
    "y_pred_xgb_proba_lags = xgb_model_lags.predict_proba(X_test_lags)[:, 1]\n",
    "\n",
    "# Evaluation\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_class_lags, y_pred_xgb_lags, target_names=['No Ticket', 'Ticket']))\n",
    "\n",
    "# ROC-AUC\n",
    "roc_auc_xgb_lags = roc_auc_score(y_test_class_lags, y_pred_xgb_proba_lags)\n",
    "print(f\"ROC-AUC Score: {roc_auc_xgb_lags:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm_xgb_lags = confusion_matrix(y_test_class_lags, y_pred_xgb_lags)\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(cm_xgb_lags)\n",
    "\n",
    "# Feature importance with lags\n",
    "feature_importance_xgb_lags = pd.DataFrame({\n",
    "    'feature': all_features_lags,\n",
    "    'importance': xgb_model_lags.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(f\"\\nTop 20 Most Important Features (with lags):\")\n",
    "print(feature_importance_xgb_lags.head(20).to_string(index=False))\n",
    "\n",
    "# Improvement comparison\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"IMPROVEMENT vs ORIGINAL XGBOOST\")\n",
    "print(\"=\"*80)\n",
    "print(f\"ROC-AUC: {roc_auc_xgb:.4f} → {roc_auc_xgb_lags:.4f} ({roc_auc_xgb_lags - roc_auc_xgb:+.4f})\")\n",
    "\n",
    "if roc_auc_xgb_lags > roc_auc_xgb:\n",
    "    improvement_pct = ((roc_auc_xgb_lags - roc_auc_xgb) / roc_auc_xgb) * 100\n",
    "    print(f\" IMPROVED by {improvement_pct:.2f}%!\")\n",
    "    if roc_auc_xgb_lags > 0.985:\n",
    "        print(f\" Exceeded 0.985 target! Current: {roc_auc_xgb_lags:.4f}\")\n",
    "else:\n",
    "    print(f\"⚠️ No improvement - lag features may not help this model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f88d0f",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning with Lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6810879a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning with RandomizedSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"HYPERPARAMETER TUNING WITH LAG FEATURES\")\n",
    "print(\"=\"*80)\n",
    "print(\"This may take 10-15 minutes...\")\n",
    "\n",
    "# Parameter grid\n",
    "param_grid_enf = {\n",
    "    'n_estimators': [100, 150, 200],\n",
    "    'max_depth': [8, 10, 12, 15],\n",
    "    'learning_rate': [0.05, 0.1, 0.15],\n",
    "    'subsample': [0.7, 0.8, 0.9],\n",
    "    'colsample_bytree': [0.7, 0.8, 0.9],\n",
    "    'reg_alpha': [0, 0.1, 0.5],\n",
    "    'reg_lambda': [0.5, 1, 2],\n",
    "    'scale_pos_weight': [scale_pos_weight_lags]  # Use calculated value\n",
    "}\n",
    "\n",
    "# RandomizedSearchCV\n",
    "random_search_enf = RandomizedSearchCV(\n",
    "    xgb.XGBClassifier(random_state=42, n_jobs=-1, eval_metric='logloss'),\n",
    "    param_distributions=param_grid_enf,\n",
    "    n_iter=20,  # Try 20 random combinations\n",
    "    scoring='roc_auc',  # Use ROC-AUC for evaluation\n",
    "    cv=3,  # 3-fold cross-validation\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "random_search_enf.fit(X_train_lags, y_train_class_lags)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TUNING RESULTS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nBest parameters found:\")\n",
    "for param, value in random_search_enf.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "print(f\"\\nBest CV ROC-AUC: {random_search_enf.best_score_:.4f}\")\n",
    "\n",
    "# Use best model\n",
    "xgb_best_enf = random_search_enf.best_estimator_\n",
    "\n",
    "# Predictions with best model\n",
    "y_pred_xgb_best_enf = xgb_best_enf.predict(X_test_lags)\n",
    "y_pred_xgb_proba_best_enf = xgb_best_enf.predict_proba(X_test_lags)[:, 1]\n",
    "\n",
    "# Evaluation\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"XGBOOST TUNED - RESULTS\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_class_lags, y_pred_xgb_best_enf, target_names=['No Ticket', 'Ticket']))\n",
    "\n",
    "# ROC-AUC\n",
    "roc_auc_xgb_best_enf = roc_auc_score(y_test_class_lags, y_pred_xgb_proba_best_enf)\n",
    "print(f\"ROC-AUC Score: {roc_auc_xgb_best_enf:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm_xgb_best_enf = confusion_matrix(y_test_class_lags, y_pred_xgb_best_enf)\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(cm_xgb_best_enf)\n",
    "\n",
    "# Improvement summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"IMPROVEMENT SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Original XGBoost:        ROC-AUC = {roc_auc_xgb:.4f}\")\n",
    "print(f\"XGBoost + Lags:          ROC-AUC = {roc_auc_xgb_lags:.4f} ({roc_auc_xgb_lags - roc_auc_xgb:+.4f})\")\n",
    "print(f\"XGBoost Tuned + Lags:    ROC-AUC = {roc_auc_xgb_best_enf:.4f} ({roc_auc_xgb_best_enf - roc_auc_xgb:+.4f})\")\n",
    "\n",
    "if roc_auc_xgb_best_enf > 0.985:\n",
    "    print(f\"\\n SUCCESS! Exceeded 0.985 target!\")\n",
    "elif roc_auc_xgb_best_enf > roc_auc_xgb:\n",
    "    print(f\"\\n IMPROVED! Better than original by {((roc_auc_xgb_best_enf - roc_auc_xgb) / roc_auc_xgb * 100):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8022831e",
   "metadata": {},
   "source": [
    "### Final Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1368a847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive comparison\n",
    "comparison_enforcement = []\n",
    "\n",
    "# Original models\n",
    "try:\n",
    "    comparison_enforcement.append({\n",
    "        'Model': 'Logistic Regression',\n",
    "        'ROC-AUC': roc_auc_lr,\n",
    "        'Features': len(all_features)\n",
    "    })\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    comparison_enforcement.append({\n",
    "        'Model': 'Random Forest',\n",
    "        'ROC-AUC': roc_auc_rf,\n",
    "        'Features': len(all_features)\n",
    "    })\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    comparison_enforcement.append({\n",
    "        'Model': 'XGBoost (Original)',\n",
    "        'ROC-AUC': roc_auc_xgb,\n",
    "        'Features': len(all_features)\n",
    "    })\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Models with lags\n",
    "try:\n",
    "    comparison_enforcement.append({\n",
    "        'Model': 'XGBoost + Lags',\n",
    "        'ROC-AUC': roc_auc_xgb_lags,\n",
    "        'Features': len(all_features_lags)\n",
    "    })\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    comparison_enforcement.append({\n",
    "        'Model': 'XGBoost Tuned + Lags',\n",
    "        'ROC-AUC': roc_auc_xgb_best_enf,\n",
    "        'Features': len(all_features_lags)\n",
    "    })\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Create comparison DataFrame\n",
    "comparison_df_enf = pd.DataFrame(comparison_enforcement)\n",
    "comparison_df_enf = comparison_df_enf.sort_values('ROC-AUC', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"FINAL ENFORCEMENT MODEL COMPARISON - ALL APPROACHES\")\n",
    "print(\"=\"*100)\n",
    "print(comparison_df_enf.to_string(index=False))\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Highlight best model\n",
    "best_model_enf = comparison_df_enf.iloc[0]\n",
    "print(f\"\\n BEST MODEL: {best_model_enf['Model']}\")\n",
    "print(f\"   ROC-AUC: {best_model_enf['ROC-AUC']:.4f}\")\n",
    "print(f\"   Features: {best_model_enf['Features']}\")\n",
    "\n",
    "# Success criteria\n",
    "if best_model_enf['ROC-AUC'] > 0.985:\n",
    "    print(f\"\\n EXCELLENT! Exceeded 0.985 ROC-AUC target!\")\n",
    "elif best_model_enf['ROC-AUC'] > 0.98:\n",
    "    print(f\"\\n GREAT! Above 0.98 ROC-AUC!\")\n",
    "elif best_model_enf['ROC-AUC'] > 0.975:\n",
    "    print(f\"\\n GOOD! Above 0.975 ROC-AUC!\")\n",
    "else:\n",
    "    print(f\"\\n✓ Solid performance at {best_model_enf['ROC-AUC']:.4f} ROC-AUC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abffbf7",
   "metadata": {},
   "source": [
    "### Save Production Model with API-Ready Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5e9ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best enforcement model for production API\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"SAVING PRODUCTION ENFORCEMENT MODEL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Save the best XGBoost model (tuned with lags)\n",
    "with open('../../models/enforcement_xgboost_tuned.pkl', 'wb') as f:\n",
    "    pickle.dump(xgb_best_enf, f)\n",
    "print(\" Saved: models/enforcement_xgboost_tuned.pkl\")\n",
    "\n",
    "# Save feature names for API\n",
    "with open('../../models/enforcement_feature_list_lags.pkl', 'wb') as f:\n",
    "    pickle.dump(all_features_lags, f)\n",
    "print(\" Saved: models/enforcement_feature_list_lags.pkl\")\n",
    "\n",
    "# Calculate risk thresholds for API interpretation\n",
    "# Analyze the probability distribution to set meaningful thresholds\n",
    "probabilities = y_pred_xgb_proba_best_enf\n",
    "percentiles = {\n",
    "    '10th': np.percentile(probabilities, 10),\n",
    "    '25th': np.percentile(probabilities, 25),\n",
    "    '50th': np.percentile(probabilities, 50),\n",
    "    '75th': np.percentile(probabilities, 75),\n",
    "    '90th': np.percentile(probabilities, 90),\n",
    "    '95th': np.percentile(probabilities, 95)\n",
    "}\n",
    "\n",
    "# Define risk thresholds based on actual distribution\n",
    "# These will be used in the API to classify risk levels\n",
    "risk_thresholds = {\n",
    "    'VERY_LOW': 0.05,      # < 5% chance of ticket\n",
    "    'LOW': 0.15,           # 5-15% chance\n",
    "    'MODERATE': 0.30,      # 15-30% chance\n",
    "    'HIGH': 0.50,          # 30-50% chance\n",
    "    'VERY_HIGH': 0.50      # > 50% chance\n",
    "}\n",
    "\n",
    "# API response messages for each risk level\n",
    "risk_messages = {\n",
    "    'VERY_LOW': \"You will likely NOT get a ticket at this time. Safe to park!\",\n",
    "    'LOW': \"Low risk - tickets are uncommon at this time, but not impossible.\",\n",
    "    'MODERATE': \"Moderate risk - enforcement happens sometimes at this time.\",\n",
    "    'HIGH': \"HIGH chance of getting a ticket! Consider another time or zone.\",\n",
    "    'VERY_HIGH': \"VERY HIGH chance of ticket! Enforcement is very active at this time.\"\n",
    "}\n",
    "\n",
    "# Save metadata with performance metrics and risk interpretation\n",
    "metadata = {\n",
    "    'model_type': 'XGBoost Tuned with Lag Features - Enforcement Risk',\n",
    "    'performance': {\n",
    "        'test_roc_auc': float(roc_auc_xgb_best_enf),\n",
    "        'best_cv_roc_auc': float(random_search_enf.best_score_),\n",
    "        'test_accuracy': float(np.mean(y_pred_xgb_best_enf == y_test_class_lags)),\n",
    "        'confusion_matrix': cm_xgb_best_enf.tolist()\n",
    "    },\n",
    "    'hyperparameters': random_search_enf.best_params_,\n",
    "    'features': {\n",
    "        'total': len(all_features_lags),\n",
    "        'original': len(numerical_features + binary_features + encoded_cat_cols_lags),\n",
    "        'lag_features': len(lag_feature_names),\n",
    "        'lag_names': lag_feature_names\n",
    "    },\n",
    "    'risk_thresholds': risk_thresholds,\n",
    "    'risk_messages': risk_messages,\n",
    "    'probability_percentiles': {k: float(v) for k, v in percentiles.items()},\n",
    "    'training_date': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'data_summary': {\n",
    "        'train_records': len(X_train_lags),\n",
    "        'test_records': len(X_test_lags),\n",
    "        'zones': int(df['Zone'].nunique()),\n",
    "        'date_range': f\"{df['date'].min()} to {df['date'].max()}\"\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('../../models/enforcement_model_metadata.json', 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "print(\" Saved: models/enforcement_model_metadata.json\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" PRODUCTION MODEL READY FOR API!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Model: XGBoost Tuned with Lag Features\")\n",
    "print(f\"Test ROC-AUC: {roc_auc_xgb_best_enf:.4f}\")\n",
    "print(f\"Test Accuracy: {np.mean(y_pred_xgb_best_enf == y_test_class_lags)*100:.2f}%\")\n",
    "print(f\"\\n Risk Thresholds for API:\")\n",
    "for level, threshold in risk_thresholds.items():\n",
    "    print(f\"  {level}: {threshold*100:.1f}%\")\n",
    "print(f\"\\n Example API Response:\")\n",
    "print(f\"  Probability: 0.35 (35%)\")\n",
    "print(f\"  Risk Level: HIGH\")\n",
    "print(f\"  Message: '{risk_messages['HIGH']}'\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667ca4bd",
   "metadata": {},
   "source": [
    "## Summary: Enforcement Model Results\n",
    "\n",
    "### Performance Improvements\n",
    "\n",
    "**Original Model (XGBoost):** ROC-AUC = 0.9778  \n",
    "**With Lag Features:** ROC-AUC = 0.9771 (similar, with better NaN handling)  \n",
    "**Tuned + Lags:** ROC-AUC = 0.9771 (production-ready)\n",
    "\n",
    "### Key Achievements\n",
    "\n",
    " **No NaN Issues** - All lag features properly filled with 0  \n",
    " **8 Temporal Lag Features** - Previous hour, 24-hour, rolling patterns  \n",
    " **User-Friendly API Messages** - Clear risk levels (VERY_LOW to VERY_HIGH)  \n",
    " **Production Model Saved** - Ready for deployment  \n",
    "\n",
    "### API Integration\n",
    "\n",
    "The saved model provides:\n",
    "- **Probability Score**: 0.0 to 1.0 (0% to 100% chance of ticket)\n",
    "- **Risk Level**: VERY_LOW, LOW, MODERATE, HIGH, VERY_HIGH\n",
    "- **User Message**: \"You will likely NOT get a ticket\" vs \"HIGH chance of ticket!\"\n",
    "- **Recommendation**: Actionable advice for users\n",
    "- **Color Indicator**:     for quick visual feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d621d2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. ROC Curves\n",
    "fpr_lr, tpr_lr, _ = roc_curve(y_test_class, y_pred_lr_proba)\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test_class, y_pred_rf_proba)\n",
    "fpr_xgb, tpr_xgb, _ = roc_curve(y_test_class, y_pred_xgb_proba)\n",
    "\n",
    "axes[0,0].plot(fpr_lr, tpr_lr, label=f'Logistic Regression (AUC={roc_auc_lr:.3f})', linewidth=2)\n",
    "axes[0,0].plot(fpr_rf, tpr_rf, label=f'Random Forest (AUC={roc_auc_rf:.3f})', linewidth=2)\n",
    "axes[0,0].plot(fpr_xgb, tpr_xgb, label=f'XGBoost (AUC={roc_auc_xgb:.3f})', linewidth=2)\n",
    "axes[0,0].plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
    "axes[0,0].set_xlabel('False Positive Rate')\n",
    "axes[0,0].set_ylabel('True Positive Rate')\n",
    "axes[0,0].set_title('ROC Curves - Classification Models', fontweight='bold')\n",
    "axes[0,0].legend()\n",
    "axes[0,0].grid(alpha=0.3)\n",
    "\n",
    "# 2. Feature Importance (Random Forest)\n",
    "top_features_rf = feature_importance_rf.head(15)\n",
    "axes[0,1].barh(range(len(top_features_rf)), top_features_rf['importance'], color='steelblue')\n",
    "axes[0,1].set_yticks(range(len(top_features_rf)))\n",
    "axes[0,1].set_yticklabels(top_features_rf['feature'])\n",
    "axes[0,1].set_xlabel('Importance')\n",
    "axes[0,1].set_title('Top 15 Features - Random Forest', fontweight='bold')\n",
    "axes[0,1].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# 3. Feature Importance (XGBoost)\n",
    "top_features_xgb = feature_importance_xgb.head(15)\n",
    "axes[1,0].barh(range(len(top_features_xgb)), top_features_xgb['importance'], color='coral')\n",
    "axes[1,0].set_yticks(range(len(top_features_xgb)))\n",
    "axes[1,0].set_yticklabels(top_features_xgb['feature'])\n",
    "axes[1,0].set_xlabel('Importance')\n",
    "axes[1,0].set_title('Top 15 Features - XGBoost', fontweight='bold')\n",
    "axes[1,0].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# 4. Confusion Matrix (Best model - likely XGBoost)\n",
    "best_cm = cm_xgb  # Assuming XGBoost is best\n",
    "sns.heatmap(best_cm, annot=True, fmt='d', cmap='Blues', ax=axes[1,1])\n",
    "axes[1,1].set_xlabel('Predicted')\n",
    "axes[1,1].set_ylabel('Actual')\n",
    "axes[1,1].set_title('Confusion Matrix - XGBoost', fontweight='bold')\n",
    "axes[1,1].set_xticklabels(['No Ticket', 'Ticket'])\n",
    "axes[1,1].set_yticklabels(['No Ticket', 'Ticket'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../../data/processed/enforcement_model_performance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Model performance visualization saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d34950",
   "metadata": {},
   "source": [
    "## Regression Models: Predict Ticket Count\n",
    "\n",
    "Instead of yes/no, predict HOW MANY tickets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f721cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"REGRESSION MODELS - TICKET COUNT PREDICTION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Random Forest Regressor\n",
    "rf_reg = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=15,\n",
    "    min_samples_split=100,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"\\nTraining Random Forest Regressor...\")\n",
    "rf_reg.fit(X_train, y_train_reg)\n",
    "y_pred_rf_reg = rf_reg.predict(X_test)\n",
    "\n",
    "# XGBoost Regressor\n",
    "xgb_reg = xgb.XGBRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Training XGBoost Regressor...\")\n",
    "xgb_reg.fit(X_train, y_train_reg)\n",
    "y_pred_xgb_reg = xgb_reg.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"REGRESSION RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nRandom Forest Regressor:\")\n",
    "print(f\"  MAE: {mean_absolute_error(y_test_reg, y_pred_rf_reg):.4f}\")\n",
    "print(f\"  RMSE: {np.sqrt(mean_squared_error(y_test_reg, y_pred_rf_reg)):.4f}\")\n",
    "print(f\"  R²: {r2_score(y_test_reg, y_pred_rf_reg):.4f}\")\n",
    "\n",
    "print(\"\\nXGBoost Regressor:\")\n",
    "print(f\"  MAE: {mean_absolute_error(y_test_reg, y_pred_xgb_reg):.4f}\")\n",
    "print(f\"  RMSE: {np.sqrt(mean_squared_error(y_test_reg, y_pred_xgb_reg)):.4f}\")\n",
    "print(f\"  R²: {r2_score(y_test_reg, y_pred_xgb_reg):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be269600",
   "metadata": {},
   "source": [
    "## Create Risk Scoring Function\n",
    "\n",
    "Practical application: Given zone, time, and conditions, predict ticket risk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecaea50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ticket_risk(zone, hour, day_of_week, is_game_day=0, is_finals=0, \n",
    "                        temperature=60, is_rainy=0, model='xgboost'):\n",
    "    \"\"\"\n",
    "    Predict parking ticket risk for given conditions.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    zone : str\n",
    "        Parking zone name (e.g., 'Green 5')\n",
    "    hour : int\n",
    "        Hour of day (0-23)\n",
    "    day_of_week : int\n",
    "        Day of week (0=Monday, 6=Sunday)\n",
    "    is_game_day : int\n",
    "        1 if game day, 0 otherwise\n",
    "    is_finals : int\n",
    "        1 if finals week, 0 otherwise\n",
    "    temperature : float\n",
    "        Temperature in Fahrenheit\n",
    "    is_rainy : int\n",
    "        1 if raining, 0 otherwise\n",
    "    model : str\n",
    "        'xgboost', 'random_forest', or 'logistic'\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict with probability, risk_level, and expected_tickets\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # Get zone historical enforcement rate\n",
    "    zone_stats = df[df['Zone'] == zone].agg({\n",
    "        'zone_avg_enforcement': 'mean',\n",
    "        'unpaid_estimate': 'mean'\n",
    "    })\n",
    "    \n",
    "    if len(zone_stats) == 0:\n",
    "        return {\"error\": f\"Zone '{zone}' not found in historical data\"}\n",
    "    \n",
    "    # Select model\n",
    "    if model == 'xgboost':\n",
    "        clf = xgb_model\n",
    "        reg = xgb_reg\n",
    "    elif model == 'random_forest':\n",
    "        clf = rf_model\n",
    "        reg = rf_reg\n",
    "    else:\n",
    "        clf = lr_model\n",
    "        reg = None\n",
    "    \n",
    "  \n",
    "    \n",
    "    # For now, return zone-based statistics\n",
    "    zone_risk = df[df['Zone'] == zone].groupby('hour')['has_ticket'].mean()\n",
    "    hour_risk = zone_risk.get(hour, zone_risk.mean()) if hour in zone_risk else zone_risk.mean()\n",
    "    \n",
    "    # Risk level\n",
    "    if hour_risk > 0.15:\n",
    "        risk_level = \"HIGH\"\n",
    "    elif hour_risk > 0.05:\n",
    "        risk_level = \"MEDIUM\"\n",
    "    else:\n",
    "        risk_level = \"LOW\"\n",
    "    \n",
    "    return {\n",
    "        'zone': zone,\n",
    "        'hour': hour,\n",
    "        'probability': hour_risk,\n",
    "        'risk_level': risk_level,\n",
    "        'expected_tickets': df[(df['Zone']==zone) & (df['hour']==hour)]['tickets_issued'].mean(),\n",
    "        'note': 'Simplified prediction - production version needs full feature encoding'\n",
    "    }\n",
    "\n",
    "# Test the function\n",
    "print(\"=\"*80)\n",
    "print(\"EXAMPLE RISK PREDICTIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "test_cases = [\n",
    "    {'zone': 'Green 5', 'hour': 10, 'day_of_week': 1, 'is_game_day': 0},\n",
    "    {'zone': 'Green 5', 'hour': 14, 'day_of_week': 1, 'is_game_day': 1},\n",
    "    {'zone': 'Red 6', 'hour': 9, 'day_of_week': 0, 'is_game_day': 0},\n",
    "]\n",
    "\n",
    "for case in test_cases:\n",
    "    result = predict_ticket_risk(**case)\n",
    "    print(f\"\\nZone: {result.get('zone', 'N/A')}, Hour: {result.get('hour', 'N/A')}\")\n",
    "    print(f\"  Probability: {result.get('probability', 0)*100:.1f}%\")\n",
    "    print(f\"  Risk Level: {result.get('risk_level', 'UNKNOWN')}\")\n",
    "    print(f\"  Expected Tickets: {result.get('expected_tickets', 0):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb307e60",
   "metadata": {},
   "source": [
    "## Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119733ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save best models\n",
    "models_to_save = {\n",
    "    'xgb_classifier': xgb_model,\n",
    "    'xgb_regressor': xgb_reg,\n",
    "    'rf_classifier': rf_model,\n",
    "    'rf_regressor': rf_reg,\n",
    "    'scaler': scaler,\n",
    "    'feature_names': all_features\n",
    "}\n",
    "\n",
    "for name, model in models_to_save.items():\n",
    "    filename = f'../../data/processed/enforcement_model_{name}.pkl'\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "    print(f\"✓ Saved: {filename}\")\n",
    "\n",
    "print(\"\\n All models saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f0d965",
   "metadata": {},
   "source": [
    "## Summary & Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97c2d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"ENFORCEMENT RISK MODELING - SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n MODELS BUILT:\")\n",
    "print(\"  1. Classification (Will I get a ticket?)\")\n",
    "print(f\"     - Logistic Regression: ROC-AUC = {roc_auc_lr:.4f}\")\n",
    "print(f\"     - Random Forest: ROC-AUC = {roc_auc_rf:.4f}\")\n",
    "print(f\"     - XGBoost: ROC-AUC = {roc_auc_xgb:.4f} \")\n",
    "\n",
    "print(\"\\n  2. Regression (How many tickets expected?)\")\n",
    "print(f\"     - Random Forest: R² = {r2_score(y_test_reg, y_pred_rf_reg):.4f}\")\n",
    "print(f\"     - XGBoost: R² = {r2_score(y_test_reg, y_pred_xgb_reg):.4f}\")\n",
    "\n",
    "print(\"\\n KEY FEATURES (Top 5):\")\n",
    "for i, row in feature_importance_xgb.head(5).iterrows():\n",
    "    print(f\"  {i+1}. {row['feature']}: {row['importance']:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d80c25f",
   "metadata": {},
   "source": [
    "## Integration Test: Load Both Models and Make Combined Predictions\n",
    "\n",
    "Let's test the complete parking recommendation system combining occupancy and enforcement predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f097f13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load both saved models and test integration\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"INTEGRATION TEST: LOADING BOTH MODELS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load Occupancy Model\n",
    "print(\"\\n Loading Occupancy Model...\")\n",
    "with open('../../models/occupancy_xgboost_tuned.pkl', 'rb') as f:\n",
    "    occupancy_model = pickle.load(f)\n",
    "print(\" Occupancy model loaded\")\n",
    "\n",
    "with open('../../models/occupancy_zone_encoder.pkl', 'rb') as f:\n",
    "    occupancy_encoder = pickle.load(f)\n",
    "print(\" Zone encoder loaded\")\n",
    "\n",
    "with open('../../models/occupancy_feature_list_lags.pkl', 'rb') as f:\n",
    "    occupancy_features = pickle.load(f)\n",
    "print(f\" Feature list loaded ({len(occupancy_features)} features)\")\n",
    "\n",
    "with open('../../models/occupancy_model_metadata.json', 'r') as f:\n",
    "    occupancy_metadata = json.load(f)\n",
    "print(f\" Metadata loaded (Test MAE: {occupancy_metadata['performance']['test_mae']:.3f} cars)\")\n",
    "\n",
    "# Load Enforcement Model\n",
    "print(\"\\n Loading Enforcement Model...\")\n",
    "with open('../../models/enforcement_xgboost_tuned.pkl', 'rb') as f:\n",
    "    enforcement_model = pickle.load(f)\n",
    "print(\" Enforcement model loaded\")\n",
    "\n",
    "with open('../../models/enforcement_feature_list_lags.pkl', 'rb') as f:\n",
    "    enforcement_features = pickle.load(f)\n",
    "print(f\" Feature list loaded ({len(enforcement_features)} features)\")\n",
    "\n",
    "with open('../../models/enforcement_model_metadata.json', 'r') as f:\n",
    "    enforcement_metadata = json.load(f)\n",
    "print(f\" Metadata loaded (Test ROC-AUC: {enforcement_metadata['performance']['test_roc_auc']:.4f})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" BOTH MODELS LOADED SUCCESSFULLY!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\n Occupancy Model: {occupancy_metadata['model_type']}\")\n",
    "print(f\"   - Test MAE: {occupancy_metadata['performance']['test_mae']:.3f} cars\")\n",
    "print(f\"   - Test R²: {occupancy_metadata['performance']['test_r2']:.3f}\")\n",
    "print(f\"   - Val MAE: {occupancy_metadata['performance']['val_mae']:.3f} cars\")\n",
    "print(f\"   - Training records: {occupancy_metadata['data_summary']['train_records']:,}\")\n",
    "\n",
    "print(f\"\\n Enforcement Model: {enforcement_metadata['model_type']}\")\n",
    "print(f\"   - Test ROC-AUC: {enforcement_metadata['performance']['test_roc_auc']:.4f}\")\n",
    "print(f\"   - Test Accuracy: {enforcement_metadata['performance']['test_accuracy']*100:.2f}%\")\n",
    "print(f\"   - Training records: {enforcement_metadata['data_summary']['train_records']:,}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e809c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load lot mapping to show lot descriptions\n",
    "print(\"\\n Loading Lot Mapping...\")\n",
    "lot_mapping = pd.read_csv('../../data/lot_mapping_enhanced.csv')\n",
    "\n",
    "# Clean up the lot mapping\n",
    "lot_mapping = lot_mapping[['Lot_number', 'Zone_Name', 'location_description']].copy()\n",
    "lot_mapping = lot_mapping.dropna(subset=['Zone_Name', 'location_description'])\n",
    "lot_mapping['Zone_Name'] = lot_mapping['Zone_Name'].str.strip()\n",
    "lot_mapping['location_description'] = lot_mapping['location_description'].str.strip()\n",
    "\n",
    "print(f\" Lot mapping loaded: {len(lot_mapping)} lots\")\n",
    "print(f\"\\nExample lots for Green 5:\")\n",
    "green_5_lots = lot_mapping[lot_mapping['Zone_Name'] == 'Green 5']\n",
    "for _, row in green_5_lots.head(5).iterrows():\n",
    "    print(f\"  Lot {int(row['Lot_number'])}: {row['location_description']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b89ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load occupancy data to get realistic availability predictions\n",
    "print(\"\\n Loading Occupancy Data...\")\n",
    "occupancy_data = pd.read_csv('../../data/processed/occupancy_test.csv', parse_dates=['datetime'])\n",
    "print(f\" Occupancy data loaded: {len(occupancy_data):,} records\")\n",
    "\n",
    "# Show occupancy statistics by zone\n",
    "print(f\"\\nOccupancy statistics by zone:\")\n",
    "zone_stats = occupancy_data.groupby('Zone')['occupancy_count'].agg(['mean', 'max', 'std'])\n",
    "print(zone_stats.head(10))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee86d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check enforcement zones and ticket data\n",
    "print(\" Checking Enforcement Data Zones...\")\n",
    "print(f\"\\nTotal enforcement records: {len(df_with_lags):,}\")\n",
    "print(f\"\\nUnique zones in enforcement data: {df_with_lags['Zone'].nunique()}\")\n",
    "print(\"\\nSample zones with ticket data:\")\n",
    "zone_ticket_stats = df_with_lags.groupby('Zone').agg({\n",
    "    'has_ticket': 'mean',\n",
    "    'tickets_issued': 'sum'\n",
    "}).sort_values('has_ticket', ascending=False).head(10)\n",
    "print(zone_ticket_stats)\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ddfdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show occupancy coverage by enforcement zone\n",
    "print(\" OCCUPANCY DATA COVERAGE BY ENFORCEMENT ZONE\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nShowing which enforcement zones have occupancy approximation data:\\n\")\n",
    "\n",
    "for enf_zone in sorted(df_with_lags['Zone'].unique()):\n",
    "    # Check if there are any occupancy zones that start with this enforcement zone\n",
    "    matching_occ_zones = occupancy_data[occupancy_data['Zone'].str.startswith(enf_zone, na=False)]['Zone'].unique()\n",
    "    \n",
    "    if len(matching_occ_zones) > 0:\n",
    "        print(f\" {enf_zone:25s} → {len(matching_occ_zones):2d} lot(s) with occupancy data\")\n",
    "        for occ_zone in sorted(matching_occ_zones)[:3]:  # Show first 3\n",
    "            avg = occupancy_data[occupancy_data['Zone'] == occ_zone]['occupancy_count'].mean()\n",
    "            print(f\"   • {occ_zone:50s} (avg: {avg:5.1f} cars)\")\n",
    "        if len(matching_occ_zones) > 3:\n",
    "            print(f\"   ... and {len(matching_occ_zones) - 3} more\")\n",
    "    else:\n",
    "        print(f\" {enf_zone:25s} → No occupancy data\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"\\n Coverage Summary:\")\n",
    "zones_with_data = sum(1 for z in df_with_lags['Zone'].unique() \n",
    "                      if len(occupancy_data[occupancy_data['Zone'].str.startswith(z, na=False)]) > 0)\n",
    "total_zones = len(df_with_lags['Zone'].unique())\n",
    "print(f\"   Enforcement zones with occupancy data: {zones_with_data}/{total_zones} ({zones_with_data/total_zones*100:.1f}%)\")\n",
    "print(f\"   Total occupancy data records: {len(occupancy_data):,}\")\n",
    "print(f\"   Unique lots/zones tracked: {occupancy_data['Zone'].nunique()}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d112fa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the time granularity of the occupancy data\n",
    "print(\" ANALYZING OCCUPANCY DATA TIME GRANULARITY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Check columns\n",
    "print(\"\\n1️⃣ Occupancy Data Columns:\")\n",
    "print(occupancy_data.columns.tolist())\n",
    "\n",
    "# Check datetime format\n",
    "print(\"\\n2️⃣ Sample Datetime Values:\")\n",
    "print(occupancy_data['datetime'].head(20))\n",
    "\n",
    "# Check if there's sub-hourly granularity\n",
    "print(\"\\n3️⃣ Time Granularity Analysis:\")\n",
    "print(f\"   Total records: {len(occupancy_data):,}\")\n",
    "print(f\"   Unique dates: {occupancy_data['date'].nunique():,}\")\n",
    "print(f\"   Unique hours: {occupancy_data['hour'].nunique()}\")\n",
    "print(f\"   Unique datetimes: {occupancy_data['datetime'].nunique():,}\")\n",
    "\n",
    "# Calculate records per unique datetime\n",
    "records_per_datetime = len(occupancy_data) / occupancy_data['datetime'].nunique()\n",
    "print(f\"   Average records per unique datetime: {records_per_datetime:.1f}\")\n",
    "print(f\"   (If > 1, multiple zones share same datetime)\")\n",
    "\n",
    "# Check a specific zone to see time granularity\n",
    "sample_zone = 'Green 5 South Beasley'\n",
    "sample_data = occupancy_data[occupancy_data['Zone'] == sample_zone]\n",
    "print(f\"\\n4️⃣ Single Zone Analysis: '{sample_zone}'\")\n",
    "print(f\"   Total records: {len(sample_data):,}\")\n",
    "print(f\"   Unique datetimes: {sample_data['datetime'].nunique():,}\")\n",
    "print(f\"   Sample datetimes:\")\n",
    "print(sample_data[['datetime', 'hour', 'occupancy_count']].head(10))\n",
    "\n",
    "# Check if datetime includes minutes\n",
    "sample_datetimes = sample_data['datetime'].head(5).tolist()\n",
    "print(f\"\\n5️⃣ Datetime Format Check:\")\n",
    "for dt in sample_datetimes:\n",
    "    print(f\"   {dt}\")\n",
    "    \n",
    "# Determine granularity\n",
    "dt_str = str(sample_datetimes[0])\n",
    "if ':' in dt_str:\n",
    "    if dt_str.count(':') == 2:\n",
    "        print(\"\\n   ⏱️ FORMAT: Datetime includes HOURS:MINUTES:SECONDS\")\n",
    "    else:\n",
    "        print(\"\\n   ⏱️ FORMAT: Datetime includes HOURS:MINUTES\")\n",
    "else:\n",
    "    print(\"\\n    FORMAT: Datetime is DATE + HOUR only (no minutes)\")\n",
    "\n",
    "# Check how many records exist for same hour on same day\n",
    "sample_day_hour = sample_data[(sample_data['date'] == sample_data['date'].iloc[0]) & \n",
    "                               (sample_data['hour'] == sample_data['hour'].iloc[0])]\n",
    "print(f\"\\n6️⃣ Records for Same Day/Hour:\")\n",
    "print(f\"   Day: {sample_data['date'].iloc[0]}, Hour: {sample_data['hour'].iloc[0]}\")\n",
    "print(f\"   Number of records: {len(sample_day_hour)}\")\n",
    "if len(sample_day_hour) == 1:\n",
    "    print(\"    ONE record per hour = Hourly aggregation\")\n",
    "elif len(sample_day_hour) > 1:\n",
    "    print(f\"    MULTIPLE records per hour = Sub-hourly granularity\")\n",
    "    print(f\"   Granularity: ~{60 / len(sample_day_hour):.0f} minute intervals\")\n",
    "    print(f\"   Sample times: {sample_day_hour['datetime'].tolist()}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de0999f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create integrated prediction function combining both models\n",
    "def get_parking_recommendation(zone, datetime_str, hour, day_of_week, \n",
    "                               is_game_day=0, is_finals_week=0, lot_number=None):\n",
    "    \"\"\"\n",
    "    Combined parking recommendation using both occupancy and enforcement models.\n",
    "    \n",
    "    This simulates what the API will do - combine predictions to give actionable advice.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    zone : str\n",
    "        Parking zone name (e.g., 'Green 5')\n",
    "    datetime_str : str\n",
    "        Display datetime for user\n",
    "    hour : int\n",
    "        Hour of day (0-23)\n",
    "    day_of_week : int\n",
    "        Day of week (0=Monday, 6=Sunday)\n",
    "    is_game_day : int\n",
    "        1 if game day, 0 otherwise\n",
    "    is_finals_week : int\n",
    "        1 if finals week, 0 otherwise\n",
    "    lot_number : int, optional\n",
    "        Specific lot number to show location description\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict with combined recommendation\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get lot information if lot_number provided\n",
    "    lot_info = None\n",
    "    if lot_number is not None:\n",
    "        lot_data = lot_mapping[lot_mapping['Lot_number'] == lot_number]\n",
    "        if len(lot_data) > 0:\n",
    "            lot_info = {\n",
    "                'lot_number': int(lot_number),\n",
    "                'location': lot_data.iloc[0]['location_description'],\n",
    "                'zone': lot_data.iloc[0]['Zone_Name']\n",
    "            }\n",
    "    \n",
    "    # If no specific lot, get example lots for this zone\n",
    "    if lot_info is None:\n",
    "        zone_lots = lot_mapping[lot_mapping['Zone_Name'] == zone]\n",
    "        if len(zone_lots) > 0:\n",
    "            # Get all lots in this zone\n",
    "            lot_list = []\n",
    "            for _, row in zone_lots.iterrows():\n",
    "                lot_list.append({\n",
    "                    'lot_number': int(row['Lot_number']),\n",
    "                    'location': row['location_description']\n",
    "                })\n",
    "            lot_info = {\n",
    "                'zone': zone,\n",
    "                'lots_available': lot_list\n",
    "            }\n",
    "    \n",
    "\n",
    "    \n",
    "    # Get zone-hour statistics from test data\n",
    "    zone_hour_data = df_with_lags[\n",
    "        (df_with_lags['Zone'] == zone) & \n",
    "        (df_with_lags['hour'] == hour)\n",
    "    ]\n",
    "    \n",
    "    if len(zone_hour_data) == 0:\n",
    "        return {\n",
    "            'error': f\"No historical data for {zone} at hour {hour}\",\n",
    "            'zone': zone,\n",
    "            'datetime': datetime_str,\n",
    "            'lot_info': lot_info\n",
    "        }\n",
    "    \n",
    "    # Enforcement prediction (use actual model prediction statistics)\n",
    "    enforcement_rate = zone_hour_data['has_ticket'].mean()\n",
    "    ticket_probability = enforcement_rate\n",
    "    \n",
    "    # Classify enforcement risk\n",
    "    if ticket_probability < 0.05:\n",
    "        enforcement_risk = 'VERY_LOW'\n",
    "        enforcement_color = ''\n",
    "        enforcement_msg = enforcement_metadata['risk_messages']['VERY_LOW']\n",
    "    elif ticket_probability < 0.15:\n",
    "        enforcement_risk = 'LOW'\n",
    "        enforcement_color = ''\n",
    "        enforcement_msg = enforcement_metadata['risk_messages']['LOW']\n",
    "    elif ticket_probability < 0.30:\n",
    "        enforcement_risk = 'MODERATE'\n",
    "        enforcement_color = ''\n",
    "        enforcement_msg = enforcement_metadata['risk_messages']['MODERATE']\n",
    "    elif ticket_probability < 0.50:\n",
    "        enforcement_risk = 'HIGH'\n",
    "        enforcement_color = ''\n",
    "        enforcement_msg = enforcement_metadata['risk_messages']['HIGH']\n",
    "    else:\n",
    "        enforcement_risk = 'VERY_HIGH'\n",
    "        enforcement_color = ''\n",
    "        enforcement_msg = enforcement_metadata['risk_messages']['VERY_HIGH']\n",
    "    \n",
    "\n",
    "    \n",
    "    # Try to find occupancy data for zones that START WITH the enforcement zone code\n",
    "    occupancy_zone_hour = occupancy_data[\n",
    "        (occupancy_data['Zone'].str.startswith(zone, na=False)) & \n",
    "        (occupancy_data['hour'] == hour)\n",
    "    ]\n",
    "    \n",
    "    if len(occupancy_zone_hour) > 0:\n",
    "        avg_occupancy = occupancy_zone_hour['occupancy_count'].mean()\n",
    "        max_occupancy = occupancy_zone_hour['occupancy_count'].max()\n",
    "    else:\n",
    "        # No occupancy data for this zone - this is expected for some zones\n",
    "        avg_occupancy = None\n",
    "        max_occupancy = None\n",
    "    \n",
    "    # Availability classification (simplified - would need lot capacity in production)\n",
    "    if avg_occupancy is None:\n",
    "        # No occupancy data available for this zone\n",
    "        availability = 'UNKNOWN'\n",
    "        availability_color = ''\n",
    "        availability_msg = \"Occupancy data not available for this zone.\"\n",
    "    elif avg_occupancy < 5:\n",
    "        availability = 'EXCELLENT'\n",
    "        availability_color = ''\n",
    "        availability_msg = f\"Typically {avg_occupancy:.1f} cars - plenty of spots!\"\n",
    "    elif avg_occupancy < 15:\n",
    "        availability = 'GOOD'\n",
    "        availability_color = ''\n",
    "        availability_msg = f\"Typically {avg_occupancy:.1f} cars - should find parking easily.\"\n",
    "    elif avg_occupancy < 30:\n",
    "        availability = 'MODERATE'\n",
    "        availability_color = ''\n",
    "        availability_msg = f\"Typically {avg_occupancy:.1f} cars - may take time to find spot.\"\n",
    "    elif avg_occupancy < 50:\n",
    "        availability = 'LIMITED'\n",
    "        availability_color = ''\n",
    "        availability_msg = f\"Typically {avg_occupancy:.1f} cars - limited availability.\"\n",
    "    else:\n",
    "        availability = 'VERY_LIMITED'\n",
    "        availability_color = ''\n",
    "        availability_msg = f\"Typically {avg_occupancy:.1f} cars - very crowded!\"\n",
    "    \n",
    "    # Combined recommendation\n",
    "    if enforcement_risk in ['HIGH', 'VERY_HIGH']:\n",
    "        recommendation = \" NOT RECOMMENDED - High ticket risk!\"\n",
    "        overall_color = ''\n",
    "    elif enforcement_risk == 'MODERATE' and availability in ['LIMITED', 'VERY_LIMITED']:\n",
    "        recommendation = \"⚠️ RISKY - Moderate ticket risk + limited parking\"\n",
    "        overall_color = ''\n",
    "    elif enforcement_risk in ['VERY_LOW', 'LOW'] and availability in ['EXCELLENT', 'GOOD']:\n",
    "        recommendation = \" RECOMMENDED - Low risk + good availability\"\n",
    "        overall_color = ''\n",
    "    elif availability == 'UNKNOWN':\n",
    "        if enforcement_risk in ['VERY_LOW', 'LOW']:\n",
    "            recommendation = \"✓ OK - Low ticket risk (availability data unavailable)\"\n",
    "            overall_color = ''\n",
    "        else:\n",
    "            recommendation = \"⚠️ USE CAUTION - Check availability before parking\"\n",
    "            overall_color = ''\n",
    "    elif enforcement_risk in ['VERY_LOW', 'LOW']:\n",
    "        recommendation = \"✓ OK - Low ticket risk, check availability\"\n",
    "        overall_color = ''\n",
    "    else:\n",
    "        recommendation = \"⚠️ USE CAUTION - Consider alternatives\"\n",
    "        overall_color = ''\n",
    "    \n",
    "    return {\n",
    "        'zone': zone,\n",
    "        'datetime': datetime_str,\n",
    "        'lot_info': lot_info,\n",
    "        'overall_recommendation': recommendation,\n",
    "        'overall_color': overall_color,\n",
    "        'enforcement': {\n",
    "            'probability': round(ticket_probability, 4),\n",
    "            'probability_percent': round(ticket_probability * 100, 1),\n",
    "            'risk_level': enforcement_risk,\n",
    "            'color': enforcement_color,\n",
    "            'message': enforcement_msg\n",
    "        },\n",
    "        'availability': {\n",
    "            'avg_occupancy': round(avg_occupancy, 1) if avg_occupancy is not None else None,\n",
    "            'max_occupancy': round(max_occupancy, 1) if max_occupancy is not None else None,\n",
    "            'level': availability,\n",
    "            'color': availability_color,\n",
    "            'message': availability_msg\n",
    "        }\n",
    "    }\n",
    "\n",
    "print(\" Integrated prediction function created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6e7f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with realistic parking scenarios using ENFORCEMENT ZONE CODES\n",
    "# (Enforcement data uses codes like \"Green 5\", \"Paid\", etc.)\n",
    "print(\"=\"*80)\n",
    "print(\"INTEGRATED PARKING RECOMMENDATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "test_scenarios = [\n",
    "    {\n",
    "        'zone': 'Green 5',\n",
    "        'datetime_str': 'Monday 9:00 AM (Peak time)',\n",
    "        'hour': 9,\n",
    "        'day_of_week': 0,\n",
    "        'is_game_day': 0,\n",
    "        'is_finals_week': 0,\n",
    "        'lot_number': 23  # STREIT PERHAM WEST\n",
    "    },\n",
    "    {\n",
    "        'zone': 'Paid',\n",
    "        'datetime_str': 'Tuesday 2:00 PM (Busy afternoon)',\n",
    "        'hour': 14,\n",
    "        'day_of_week': 1,\n",
    "        'is_game_day': 0,\n",
    "        'is_finals_week': 0,\n",
    "        'lot_number': None  # Show all Paid zone lots\n",
    "    },\n",
    "    {\n",
    "        'zone': 'Yellow 4',\n",
    "        'datetime_str': 'Saturday 10:00 AM (Game Day)',\n",
    "        'hour': 10,\n",
    "        'day_of_week': 5,\n",
    "        'is_game_day': 1,\n",
    "        'is_finals_week': 0,\n",
    "        'lot_number': None\n",
    "    },\n",
    "    {\n",
    "        'zone': 'Green 3',\n",
    "        'datetime_str': 'Wednesday 11:00 AM (Finals Week)',\n",
    "        'hour': 11,\n",
    "        'day_of_week': 2,\n",
    "        'is_game_day': 0,\n",
    "        'is_finals_week': 1,\n",
    "        'lot_number': None\n",
    "    },\n",
    "    {\n",
    "        'zone': 'Green 1',\n",
    "        'datetime_str': 'Friday 3:00 PM (Weekend start)',\n",
    "        'hour': 15,\n",
    "        'day_of_week': 4,\n",
    "        'is_game_day': 0,\n",
    "        'is_finals_week': 0,\n",
    "        'lot_number': None\n",
    "    }\n",
    "]\n",
    "\n",
    "for scenario in test_scenarios:\n",
    "    result = get_parking_recommendation(**scenario)\n",
    "    \n",
    "    if 'error' in result:\n",
    "        print(f\"\\n⚠️ {result['error']}\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    \n",
    "    # Display lot information\n",
    "    if result.get('lot_info'):\n",
    "        if 'lot_number' in result['lot_info']:\n",
    "            # Specific lot\n",
    "            print(f\"{result['overall_color']} Lot {result['lot_info']['lot_number']}: {result['lot_info']['location']}\")\n",
    "            print(f\"   Zone: {result['lot_info']['zone']} | {result['datetime']}\")\n",
    "        elif 'lots_available' in result['lot_info']:\n",
    "            # Multiple lots in zone\n",
    "            print(f\"{result['overall_color']} {result['zone']} - {result['datetime']}\")\n",
    "            print(f\"   Available lots in this zone:\")\n",
    "            for lot in result['lot_info']['lots_available'][:5]:  # Show first 5\n",
    "                print(f\"      • Lot {lot['lot_number']}: {lot['location']}\")\n",
    "            if len(result['lot_info']['lots_available']) > 5:\n",
    "                print(f\"      ... and {len(result['lot_info']['lots_available']) - 5} more lots\")\n",
    "    else:\n",
    "        print(f\"{result['overall_color']} {result['zone']} - {result['datetime']}\")\n",
    "    \n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    print(f\"\\n OVERALL: {result['overall_recommendation']}\")\n",
    "    \n",
    "    print(f\"\\n ENFORCEMENT RISK: {result['enforcement']['color']} {result['enforcement']['risk_level']}\")\n",
    "    print(f\"   Ticket Probability: {result['enforcement']['probability_percent']}%\")\n",
    "    print(f\"   {result['enforcement']['message']}\")\n",
    "    \n",
    "    print(f\"\\n🅿️ AVAILABILITY: {result['availability']['color']} {result['availability']['level']}\")\n",
    "    print(f\"   {result['availability']['message']}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
