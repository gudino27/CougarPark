{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff60d63c",
   "metadata": {},
   "source": [
    "# Enforcement Pattern Analysis: LPR, AMP, and Ticket Relationships\n",
    "\n",
    "Analyze aggregate patterns to understand enforcement dynamics and create features for predictive modeling.\n",
    "\n",
    "## Key Questions:\n",
    "\n",
    "1. **Does higher occupancy (LPR scans) lead to more tickets?**\n",
    "2. **What's the relationship between unpaid vehicles and enforcement?**\n",
    "3. **How does AMP (paid parking) correlate with ticket probability?**\n",
    "4. **Which zones/times have highest enforcement risk?**\n",
    "5. **Can we predict enforcement intensity from occupancy patterns?**\n",
    "6. **Does weather affect enforcement behavior?**\n",
    "\n",
    "\n",
    "These become **features for machine learning models**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b4df56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e64723",
   "metadata": {},
   "source": [
    "## Load Enforcement Data\n",
    "\n",
    "We already created this in notebook 12 - it has zone-hour aggregates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6594aa74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load enforcement data (created in notebook 12)\n",
    "# This already includes camera classification from notebook 16!\n",
    "enforcement = pd.read_csv('../data/processed/enforcement_full.csv', parse_dates=['date', 'datetime'])\n",
    "\n",
    "print(f\"Enforcement data: {len(enforcement):,} zone-hour records\")\n",
    "print(f\"Columns: {list(enforcement.columns)}\")\n",
    "print(f\"\\nDate range: {enforcement['date'].min()} to {enforcement['date'].max()}\")\n",
    "print(f\"Zones: {enforcement['Zone'].nunique()}\")\n",
    "\n",
    "# Check if camera classification is present\n",
    "if 'has_fixed_camera' in enforcement.columns:\n",
    "    print(f\"\\n✓ Camera classification loaded from notebook 16\")\n",
    "    print(f\"  Zone-hours with fixed cameras: {enforcement['has_fixed_camera'].sum():,}\")\n",
    "    print(f\"  Zones with cameras: {enforcement[enforcement['has_fixed_camera']==1]['Zone'].nunique()}\")\n",
    "    camera_zones = enforcement[enforcement['has_fixed_camera']==1]['Zone'].unique()\n",
    "    if len(camera_zones) > 0:\n",
    "        print(f\"  Camera zones: {sorted(camera_zones)}\")\n",
    "else:\n",
    "    print(f\"\\n  Camera classification not found - run notebook 12 first\")\n",
    "\n",
    "# Basic statistics\n",
    "print(f\"\\n{enforcement[['lpr_scans', 'amp_sessions', 'tickets_issued', 'unpaid_estimate', 'enforcement_rate']].describe()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18f8067",
   "metadata": {},
   "source": [
    "## 1. Occupancy vs Ticket Relationship\n",
    "\n",
    "Do busier zones/times get more tickets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb7a107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create occupancy categories\n",
    "enforcement['lpr_category'] = pd.cut(\n",
    "    enforcement['lpr_scans'],\n",
    "    bins=[0, 5, 20, 100, float('inf')],\n",
    "    labels=['Very Low (0-5)', 'Low (6-20)', 'Medium (21-100)', 'High (100+)']\n",
    ")\n",
    "\n",
    "# Aggregate by occupancy level\n",
    "occupancy_analysis = enforcement.groupby('lpr_category').agg({\n",
    "    'tickets_issued': ['sum', 'mean', 'median'],\n",
    "    'lpr_scans': 'mean',\n",
    "    'amp_sessions': 'mean',\n",
    "    'unpaid_estimate': 'mean',\n",
    "    'enforcement_rate': 'mean'\n",
    "}).round(3)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"TICKETS BY OCCUPANCY LEVEL\")\n",
    "print(\"=\"*80)\n",
    "print(occupancy_analysis)\n",
    "\n",
    "# Statistical test: correlation between LPR scans and tickets\n",
    "# Filter to hours with activity\n",
    "active_hours = enforcement[enforcement['lpr_scans'] > 0]\n",
    "\n",
    "if len(active_hours) > 0:\n",
    "    correlation = active_hours['lpr_scans'].corr(active_hours['tickets_issued'])\n",
    "    print(f\"\\nCorrelation between LPR scans and tickets: {correlation:.3f}\")\n",
    "    \n",
    "    # Spearman correlation (less sensitive to outliers)\n",
    "    spearman_corr, p_value = stats.spearmanr(active_hours['lpr_scans'], active_hours['tickets_issued'])\n",
    "    print(f\"Spearman correlation: {spearman_corr:.3f} (p-value: {p_value:.4f})\")\n",
    "    \n",
    "    if p_value < 0.001:\n",
    "        print(\"✓ Highly significant relationship between occupancy and tickets!\")\n",
    "    elif p_value < 0.05:\n",
    "        print(\"✓ Significant relationship between occupancy and tickets\")\n",
    "    else:\n",
    "        print(\"✗ No significant relationship found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55feec3f",
   "metadata": {},
   "source": [
    "## 2. Paid vs Unpaid Ratio Analysis\n",
    "\n",
    "What ratio of LPR/AMP predicts higher enforcement?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bd0186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create compliance ratio: AMP / LPR (what % of vehicles are paying?)\n",
    "enforcement['compliance_ratio'] = np.where(\n",
    "    enforcement['lpr_scans'] > 0,\n",
    "    enforcement['amp_sessions'] / enforcement['lpr_scans'],\n",
    "    np.nan\n",
    ")\n",
    "\n",
    "# Cap at 1.0 (can't have more AMP than LPR in theory)\n",
    "enforcement['compliance_ratio'] = enforcement['compliance_ratio'].clip(upper=1.0)\n",
    "\n",
    "# Create compliance categories\n",
    "enforcement['compliance_category'] = pd.cut(\n",
    "    enforcement['compliance_ratio'],\n",
    "    bins=[0, 0.2, 0.5, 0.8, 1.0],\n",
    "    labels=['Very Low (0-20%)', 'Low (20-50%)', 'Medium (50-80%)', 'High (80-100%)']\n",
    ")\n",
    "\n",
    "# Analyze enforcement by compliance level\n",
    "compliance_analysis = enforcement.groupby('compliance_category').agg({\n",
    "    'tickets_issued': ['sum', 'mean'],\n",
    "    'enforcement_rate': 'mean',\n",
    "    'lpr_scans': 'mean',\n",
    "    'amp_sessions': 'mean',\n",
    "    'unpaid_estimate': 'mean'\n",
    "}).round(3)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ENFORCEMENT BY COMPLIANCE LEVEL\")\n",
    "print(\"=\"*80)\n",
    "print(compliance_analysis)\n",
    "\n",
    "# Hypothesis: Lower compliance → More tickets\n",
    "print(\"\\nHypothesis: Areas with lower compliance (fewer paying) get more tickets\")\n",
    "\n",
    "valid_compliance = enforcement[enforcement['compliance_ratio'].notna() & (enforcement['lpr_scans'] > 0)]\n",
    "if len(valid_compliance) > 0:\n",
    "    corr_compliance = valid_compliance['compliance_ratio'].corr(valid_compliance['tickets_issued'])\n",
    "    print(f\"Correlation: {corr_compliance:.3f}\")\n",
    "    \n",
    "    if corr_compliance < 0:\n",
    "        print(\"✓ Negative correlation confirms: Lower compliance → More tickets\")\n",
    "    else:\n",
    "        print(\"✗ Unexpected: Higher compliance areas get more tickets (may indicate enforcement pressure)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3f24df",
   "metadata": {},
   "source": [
    "## 3. Unpaid Vehicles vs Enforcement Rate\n",
    "\n",
    "As unpaid vehicles increase, does enforcement keep up?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e678c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize unpaid vehicle counts\n",
    "enforcement['unpaid_category'] = pd.cut(\n",
    "    enforcement['unpaid_estimate'],\n",
    "    bins=[0, 5, 20, 50, float('inf')],\n",
    "    labels=['Very Low (0-5)', 'Low (6-20)', 'Medium (21-50)', 'High (50+)']\n",
    ")\n",
    "\n",
    "unpaid_analysis = enforcement.groupby('unpaid_category').agg({\n",
    "    'tickets_issued': ['sum', 'mean'],\n",
    "    'enforcement_rate': ['mean', 'median'],\n",
    "    'unpaid_estimate': 'mean'\n",
    "}).round(3)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ENFORCEMENT RATE BY UNPAID VEHICLE COUNT\")\n",
    "print(\"=\"*80)\n",
    "print(unpaid_analysis)\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"  - If enforcement_rate INCREASES with unpaid count: Active enforcement response\")\n",
    "print(\"  - If enforcement_rate DECREASES: Enforcement overwhelmed or selective targeting\")\n",
    "print(\"  - If enforcement_rate STABLE: Consistent patrol regardless of violations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171d4935",
   "metadata": {},
   "source": [
    "## 4. Zone-Specific Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f422c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate by zone\n",
    "zone_summary = enforcement.groupby('Zone').agg({\n",
    "    'lpr_scans': 'sum',\n",
    "    'amp_sessions': 'sum',\n",
    "    'tickets_issued': 'sum',\n",
    "    'unpaid_estimate': 'sum',\n",
    "    'enforcement_rate': 'mean'\n",
    "}).round(3)\n",
    "\n",
    "# Calculate additional metrics\n",
    "zone_summary['compliance_pct'] = (zone_summary['amp_sessions'] / zone_summary['lpr_scans'] * 100).round(1)\n",
    "zone_summary['tickets_per_1000_unpaid'] = (zone_summary['tickets_issued'] / zone_summary['unpaid_estimate'] * 1000).round(1)\n",
    "\n",
    "# Sort by enforcement intensity\n",
    "zone_summary = zone_summary.sort_values('tickets_issued', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TOP 15 ZONES BY ENFORCEMENT INTENSITY\")\n",
    "print(\"=\"*80)\n",
    "print(zone_summary[['lpr_scans', 'amp_sessions', 'tickets_issued', 'compliance_pct', 'tickets_per_1000_unpaid']].head(15))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ZONES WITH LOWEST COMPLIANCE (Most Unpaid Parking)\")\n",
    "print(\"=\"*80)\n",
    "low_compliance = zone_summary[zone_summary['lpr_scans'] > 100].sort_values('compliance_pct')\n",
    "print(low_compliance[['lpr_scans', 'amp_sessions', 'tickets_issued', 'compliance_pct']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59111a27",
   "metadata": {},
   "source": [
    "## 5. Visualize Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0b4e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# 1. LPR scans vs Tickets (log scale for clarity)\n",
    "active = enforcement[(enforcement['lpr_scans'] > 0) & (enforcement['tickets_issued'] > 0)]\n",
    "axes[0,0].scatter(active['lpr_scans'], active['tickets_issued'], alpha=0.3, s=10)\n",
    "axes[0,0].set_xlabel('LPR Scans (Vehicles Detected)')\n",
    "axes[0,0].set_ylabel('Tickets Issued')\n",
    "axes[0,0].set_title('Occupancy vs Enforcement', fontweight='bold')\n",
    "axes[0,0].set_xscale('log')\n",
    "axes[0,0].set_yscale('log')\n",
    "axes[0,0].grid(alpha=0.3)\n",
    "\n",
    "# 2. Compliance ratio vs Tickets\n",
    "valid = enforcement[(enforcement['compliance_ratio'].notna()) & (enforcement['tickets_issued'] > 0)]\n",
    "axes[0,1].scatter(valid['compliance_ratio'], valid['tickets_issued'], alpha=0.3, s=10, c='coral')\n",
    "axes[0,1].set_xlabel('Compliance Ratio (AMP/LPR)')\n",
    "axes[0,1].set_ylabel('Tickets Issued')\n",
    "axes[0,1].set_title('Compliance vs Enforcement', fontweight='bold')\n",
    "axes[0,1].set_yscale('log')\n",
    "axes[0,1].grid(alpha=0.3)\n",
    "\n",
    "# 3. Unpaid vehicles vs Enforcement rate\n",
    "unpaid_active = enforcement[(enforcement['unpaid_estimate'] > 0) & (enforcement['enforcement_rate'] > 0)]\n",
    "axes[0,2].scatter(unpaid_active['unpaid_estimate'], unpaid_active['enforcement_rate'], alpha=0.3, s=10, c='green')\n",
    "axes[0,2].set_xlabel('Unpaid Vehicles (LPR - AMP)')\n",
    "axes[0,2].set_ylabel('Enforcement Rate (Tickets/Unpaid)')\n",
    "axes[0,2].set_title('Unpaid Count vs Enforcement Intensity', fontweight='bold')\n",
    "axes[0,2].set_xscale('log')\n",
    "axes[0,2].grid(alpha=0.3)\n",
    "\n",
    "# 4. Tickets by occupancy category\n",
    "occupancy_totals = enforcement.groupby('lpr_category')['tickets_issued'].sum().sort_values()\n",
    "occupancy_totals.plot(kind='barh', ax=axes[1,0], color='steelblue')\n",
    "axes[1,0].set_xlabel('Total Tickets')\n",
    "axes[1,0].set_title('Tickets by Occupancy Level', fontweight='bold')\n",
    "axes[1,0].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# 5. Tickets by compliance category\n",
    "compliance_totals = enforcement.groupby('compliance_category')['tickets_issued'].sum().sort_values()\n",
    "compliance_totals.plot(kind='barh', ax=axes[1,1], color='coral')\n",
    "axes[1,1].set_xlabel('Total Tickets')\n",
    "axes[1,1].set_title('Tickets by Compliance Level', fontweight='bold')\n",
    "axes[1,1].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# 6. Average enforcement rate by hour\n",
    "hourly_enforcement = enforcement.groupby('hour')['enforcement_rate'].mean()\n",
    "hourly_enforcement.plot(kind='line', ax=axes[1,2], marker='o', color='darkgreen', linewidth=2)\n",
    "axes[1,2].set_xlabel('Hour of Day')\n",
    "axes[1,2].set_ylabel('Average Enforcement Rate')\n",
    "axes[1,2].set_title('Enforcement Intensity Throughout Day', fontweight='bold')\n",
    "axes[1,2].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/processed/enforcement_relationships.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Visualization saved: enforcement_relationships.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4053e9",
   "metadata": {},
   "source": [
    "## 6. Feature Engineering for Prediction Models\n",
    "\n",
    "Create useful features based on patterns discovered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc160601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create engineered features\n",
    "enforcement['occupancy_level'] = pd.cut(\n",
    "    enforcement['lpr_scans'],\n",
    "    bins=[0, 5, 20, 100, float('inf')],\n",
    "    labels=['very_low', 'low', 'medium', 'high']\n",
    ")\n",
    "\n",
    "enforcement['compliance_level'] = pd.cut(\n",
    "    enforcement['compliance_ratio'],\n",
    "    bins=[0, 0.3, 0.6, 1.0],\n",
    "    labels=['low_compliance', 'medium_compliance', 'high_compliance']\n",
    ")\n",
    "\n",
    "# Vulnerability score: (Unpaid vehicles) * (Zone enforcement history)\n",
    "# REMEMBER: Only unpaid vehicles can get tickets! AMP pass holders are immune.\n",
    "zone_avg_enforcement = enforcement.groupby('Zone')['enforcement_rate'].mean()\n",
    "enforcement['zone_avg_enforcement'] = enforcement['Zone'].map(zone_avg_enforcement)\n",
    "\n",
    "enforcement['vulnerability_score'] = (\n",
    "    enforcement['unpaid_estimate'] * enforcement['zone_avg_enforcement']\n",
    ").fillna(0)\n",
    "\n",
    "# High-risk indicator (high unpaid count + high enforcement zone)\n",
    "enforcement['high_risk'] = (\n",
    "    (enforcement['unpaid_estimate'] > enforcement['unpaid_estimate'].quantile(0.75)) &\n",
    "    (enforcement['zone_avg_enforcement'] > enforcement['zone_avg_enforcement'].quantile(0.5))\n",
    ").astype(int)\n",
    "\n",
    "# Weather features (if available)\n",
    "if 'temperature' in enforcement.columns:\n",
    "    enforcement['is_bad_weather'] = (\n",
    "        (enforcement['temperature'] < 35) |  # Freezing\n",
    "        (enforcement['precipitation'] > 0.1)  # Significant rain/snow\n",
    "    ).astype(int)\n",
    "else:\n",
    "    enforcement['is_bad_weather'] = 0\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ENGINEERED FEATURES FOR MODEL TRAINING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "feature_columns = [\n",
    "    'lpr_scans', 'amp_sessions', 'unpaid_estimate',\n",
    "    'compliance_ratio', 'hour', 'day_of_week', 'is_weekend',\n",
    "    'is_game_day', 'is_finals_week', 'is_any_break',\n",
    "    'zone_avg_enforcement', 'vulnerability_score', 'high_risk',\n",
    "    'temperature', 'precipitation', 'is_bad_weather'\n",
    "]\n",
    "\n",
    "print(f\"\\nFeatures created: {len(feature_columns)}\")\n",
    "print(f\"Columns: {feature_columns}\")\n",
    "\n",
    "print(f\"\\n KEY INSIGHT:\")\n",
    "print(f\"   Total vehicles (LPR): {enforcement['lpr_scans'].sum():,.0f}\")\n",
    "print(f\"   Paid parking (AMP): {enforcement['amp_sessions'].sum():,.0f} ✓ Protected from tickets\")\n",
    "print(f\"   Unpaid (potential violators): {enforcement['unpaid_estimate'].sum():,.0f} ⚠️\")\n",
    "print(f\"   Tickets issued: {enforcement['tickets_issued'].sum():,.0f}\")\n",
    "print(f\"   Overall catch rate: {enforcement['tickets_issued'].sum() / enforcement['unpaid_estimate'].sum() * 100:.1f}%\")\n",
    "\n",
    "print(f\"\\nHigh-risk hours: {enforcement['high_risk'].sum():,} ({enforcement['high_risk'].sum()/len(enforcement)*100:.1f}%)\")\n",
    "print(f\"Tickets in high-risk hours: {enforcement[enforcement['high_risk']==1]['tickets_issued'].sum():,}\")\n",
    "print(f\"Tickets in low-risk hours: {enforcement[enforcement['high_risk']==0]['tickets_issued'].sum():,}\")\n",
    "\n",
    "if 'is_bad_weather' in enforcement.columns:\n",
    "    bad_weather_hours = enforcement[enforcement['is_bad_weather']==1]\n",
    "    good_weather_hours = enforcement[enforcement['is_bad_weather']==0]\n",
    "    print(f\"\\nBad weather hours: {len(bad_weather_hours):,}\")\n",
    "    print(f\"  Avg enforcement rate: {bad_weather_hours['enforcement_rate'].mean():.3f}\")\n",
    "    print(f\"Good weather hours: {len(good_weather_hours):,}\")\n",
    "    print(f\"  Avg enforcement rate: {good_weather_hours['enforcement_rate'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c4f130",
   "metadata": {},
   "source": [
    "## 7. Save Enhanced Enforcement Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e80cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save with new features\n",
    "output_file = '../data/processed/enforcement_with_features.csv'\n",
    "enforcement.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"\\nSaved enhanced enforcement data: {output_file}\")\n",
    "print(f\"Records: {len(enforcement):,}\")\n",
    "print(f\"Columns: {len(enforcement.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351e0a7a",
   "metadata": {},
   "source": [
    "## Key Findings Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b2027e",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_hours = enforcement[enforcement['lpr_scans'] > 0]\n",
    "if len(active_hours) > 0:\n",
    "    lpr_corr = active_hours['lpr_scans'].corr(active_hours['tickets_issued'])\n",
    "    unpaid_corr = active_hours['unpaid_estimate'].corr(active_hours['tickets_issued'])\n",
    "    \n",
    "    print(f\"\\n2. CORRELATION ANALYSIS:\")\n",
    "    print(f\"   - LPR scans → Tickets: {lpr_corr:.3f}\")\n",
    "    print(f\"   - Unpaid vehicles → Tickets: {unpaid_corr:.3f}\")\n",
    "    \n",
    "    if unpaid_corr > lpr_corr:\n",
    "        print(\"   ✓ Unpaid estimate is stronger predictor than total occupancy\")\n",
    "        print(\"   → Supports assumption: most tickets are for non-payment\")\n",
    "        print(\"   → But correlation isn't perfect due to other violation types\")\n",
    "    else:\n",
    "        print(\"   ✓ Total occupancy correlates more than unpaid count\")\n",
    "        print(\"   → May indicate: enforcement scales with overall traffic\")\n",
    "        print(\"   → Or: significant portion of tickets are non-payment violations\")\n",
    "\n",
    "print(\"\\n3. APPROXIMATE ENFORCEMENT CATCH RATE:\")\n",
    "print(\"   (With caveat: includes non-payment violations as noise)\")\n",
    "unpaid_total = enforcement['unpaid_estimate'].sum()\n",
    "tickets_total = enforcement['tickets_issued'].sum()\n",
    "if unpaid_total > 0:\n",
    "    catch_rate = tickets_total / unpaid_total * 100\n",
    "    print(f\"   Apparent rate: {catch_rate:.2f}% of unpaid vehicles get tickets\")\n",
    "    print(f\"   That's ~1 ticket per {unpaid_total/tickets_total:.0f} unpaid vehicles\")\n",
    "    print(f\"   NOTE: Actual payment violation rate is lower (some tickets are for other reasons)\")\n",
    "    \n",
    "    # By zone\n",
    "    zone_catch = enforcement.groupby('Zone').agg({\n",
    "        'unpaid_estimate': 'sum',\n",
    "        'tickets_issued': 'sum'\n",
    "    })\n",
    "    zone_catch['catch_rate'] = zone_catch['tickets_issued'] / zone_catch['unpaid_estimate'] * 100\n",
    "    zone_catch = zone_catch[zone_catch['unpaid_estimate'] > 100].sort_values('catch_rate', ascending=False)\n",
    "    \n",
    "    print(f\"\\n   Zones with highest apparent enforcement:\")\n",
    "    for zone in zone_catch.head(5).index:\n",
    "        rate = zone_catch.loc[zone, 'catch_rate']\n",
    "        print(f\"     {zone}: {rate:.2f}%\")\n",
    "\n",
    "print(\"\\n4. MODEL READY:\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98683e53",
   "metadata": {},
   "source": [
    "## 9. Visualize Weather Impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe9c4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if enforcement data already has weather\n",
    "if 'temperature' in enforcement.columns:\n",
    "    print(\"Weather data already merged!\")\n",
    "else:\n",
    "    print(\"Loading HOURLY weather data...\")\n",
    "    weather = pd.read_csv('../data/weather_pullman_hourly_2020_2025.csv', parse_dates=['datetime'])\n",
    "    \n",
    "    print(f\"Weather columns: {list(weather.columns)}\")\n",
    "    print(f\"Weather data: {len(weather):,} hourly records\")\n",
    "    \n",
    "    # Rename columns to match our expected names\n",
    "    weather = weather.rename(columns={\n",
    "        'temperature_f': 'temperature',\n",
    "        'precipitation_inches': 'precipitation',\n",
    "        'weather_category': 'conditions'\n",
    "    })\n",
    "    \n",
    "    # HOURLY merge: Match by date AND hour!\n",
    "    # Create merge keys\n",
    "    enforcement['merge_key'] = enforcement['date'].astype(str) + '_' + enforcement['hour'].astype(str)\n",
    "    weather['date_only'] = pd.to_datetime(weather['datetime']).dt.date\n",
    "    weather['merge_key'] = weather['date_only'].astype(str) + '_' + weather['hour'].astype(str)\n",
    "    \n",
    "    print(f\"\\nMerging by date + hour...\")\n",
    "    print(f\"  Enforcement records: {len(enforcement):,}\")\n",
    "    print(f\"  Weather records: {len(weather):,}\")\n",
    "    \n",
    "    enforcement = enforcement.merge(\n",
    "        weather[['merge_key', 'temperature', 'precipitation', 'conditions', 'snowfall_inches', 'wind_mph']],\n",
    "        on='merge_key',\n",
    "        how='left'\n",
    "    )\n",
    "    enforcement.drop('merge_key', axis=1, inplace=True)\n",
    "    \n",
    "    matched = enforcement['temperature'].notna().sum()\n",
    "    print(f\"✓ HOURLY weather data merged! {matched:,} / {len(enforcement):,} records matched ({matched/len(enforcement)*100:.1f}%)\")\n",
    "\n",
    "# Weather impact analysis\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"WEATHER IMPACT ON ENFORCEMENT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Temperature categories\n",
    "enforcement['temp_category'] = pd.cut(\n",
    "    enforcement['temperature'],\n",
    "    bins=[-float('inf'), 32, 50, 70, float('inf')],\n",
    "    labels=['Freezing (<32°F)', 'Cold (32-50°F)', 'Mild (50-70°F)', 'Warm (70+°F)']\n",
    ")\n",
    "\n",
    "# Precipitation categories\n",
    "enforcement['precip_category'] = pd.cut(\n",
    "    enforcement['precipitation'],\n",
    "    bins=[-0.01, 0, 0.1, 0.5, float('inf')],\n",
    "    labels=['None', 'Light (<0.1\")', 'Moderate (0.1-0.5\")', 'Heavy (>0.5\")']\n",
    ")\n",
    "\n",
    "# Analyze by temperature\n",
    "temp_analysis = enforcement.groupby('temp_category').agg({\n",
    "    'tickets_issued': ['sum', 'mean'],\n",
    "    'enforcement_rate': 'mean',\n",
    "    'lpr_scans': 'mean',\n",
    "    'unpaid_estimate': 'mean'\n",
    "}).round(3)\n",
    "\n",
    "print(\"\\nENFORCEMENT BY TEMPERATURE:\")\n",
    "print(temp_analysis)\n",
    "\n",
    "# Analyze by precipitation\n",
    "precip_analysis = enforcement.groupby('precip_category').agg({\n",
    "    'tickets_issued': ['sum', 'mean'],\n",
    "    'enforcement_rate': 'mean',\n",
    "    'lpr_scans': 'mean',\n",
    "    'unpaid_estimate': 'mean'\n",
    "}).round(3)\n",
    "\n",
    "print(\"\\nENFORCEMENT BY PRECIPITATION:\")\n",
    "print(precip_analysis)\n",
    "\n",
    "# Statistical test\n",
    "weather_data = enforcement[enforcement['temperature'].notna()]\n",
    "if len(weather_data) > 0:\n",
    "    temp_corr = weather_data['temperature'].corr(weather_data['enforcement_rate'])\n",
    "    precip_corr = weather_data['precipitation'].corr(weather_data['enforcement_rate'])\n",
    "    \n",
    "    print(f\"\\nCORRELATIONS:\")\n",
    "    print(f\"  Temperature vs Enforcement Rate: {temp_corr:.3f}\")\n",
    "    print(f\"  Precipitation vs Enforcement Rate: {precip_corr:.3f}\")\n",
    "    \n",
    "    if temp_corr > 0.05:\n",
    "        print(\"  ✓ Warmer weather → More enforcement\")\n",
    "    elif temp_corr < -0.05:\n",
    "        print(\"  ✓ Colder weather → Less enforcement\")\n",
    "    else:\n",
    "        print(\"  ~ Temperature has minimal effect on enforcement\")\n",
    "    \n",
    "    if precip_corr < -0.05:\n",
    "        print(\"  ✓ Rain/snow → Less enforcement (officers stay in vehicles/office)\")\n",
    "    elif precip_corr > 0.05:\n",
    "        print(\"  ✓ Rain/snow → More enforcement (unexpected!)\")\n",
    "    else:\n",
    "        print(\"  ~ Precipitation has minimal effect on enforcement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89d05e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "weather_data = enforcement[enforcement['temperature'].notna()]\n",
    "\n",
    "if len(weather_data) > 0:\n",
    "    # 1. Temperature vs Enforcement Rate\n",
    "    temp_bins = range(0, 100, 5)\n",
    "    temp_grouped = weather_data.groupby(pd.cut(weather_data['temperature'], bins=temp_bins))['enforcement_rate'].mean()\n",
    "    temp_grouped.plot(kind='line', ax=axes[0,0], marker='o', color='orangered', linewidth=2)\n",
    "    axes[0,0].set_xlabel('Temperature (°F)')\n",
    "    axes[0,0].set_ylabel('Average Enforcement Rate')\n",
    "    axes[0,0].set_title('Temperature vs Enforcement Intensity', fontweight='bold')\n",
    "    axes[0,0].grid(alpha=0.3)\n",
    "    axes[0,0].axhline(weather_data['enforcement_rate'].mean(), color='gray', linestyle='--', label='Overall Average')\n",
    "    axes[0,0].legend()\n",
    "    \n",
    "    # 2. Tickets by temperature category\n",
    "    temp_tickets = enforcement.groupby('temp_category')['tickets_issued'].sum().sort_values()\n",
    "    temp_tickets.plot(kind='barh', ax=axes[0,1], color='coral')\n",
    "    axes[0,1].set_xlabel('Total Tickets')\n",
    "    axes[0,1].set_title('Tickets by Temperature', fontweight='bold')\n",
    "    axes[0,1].grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    # 3. Precipitation vs Enforcement Rate\n",
    "    precip_tickets = enforcement.groupby('precip_category')['tickets_issued'].mean()\n",
    "    precip_tickets.plot(kind='bar', ax=axes[1,0], color='steelblue')\n",
    "    axes[1,0].set_xlabel('Precipitation Level')\n",
    "    axes[1,0].set_ylabel('Average Tickets per Hour')\n",
    "    axes[1,0].set_title('Precipitation vs Enforcement', fontweight='bold')\n",
    "    axes[1,0].tick_params(axis='x', rotation=45)\n",
    "    axes[1,0].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # 4. Weather conditions distribution\n",
    "    if 'conditions' in enforcement.columns:\n",
    "        condition_counts = enforcement[enforcement['tickets_issued'] > 0]['conditions'].value_counts().head(10)\n",
    "        condition_counts.plot(kind='barh', ax=axes[1,1], color='darkgreen')\n",
    "        axes[1,1].set_xlabel('Hours with Tickets')\n",
    "        axes[1,1].set_title('Top 10 Weather Conditions During Enforcement', fontweight='bold')\n",
    "        axes[1,1].grid(axis='x', alpha=0.3)\n",
    "    else:\n",
    "        axes[1,1].text(0.5, 0.5, 'Weather conditions\\ndata not available', \n",
    "                      ha='center', va='center', fontsize=14)\n",
    "        axes[1,1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../data/processed/weather_enforcement_impact.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Weather impact visualization saved: weather_enforcement_impact.png\")\n",
    "else:\n",
    "    print(\"No weather data available for visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1c692b",
   "metadata": {},
   "source": [
    "## 11. Weather Impact on Foot Patrols\n",
    "\n",
    "Foot patrols should be much more affected by bad weather than vehicle patrols."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd99a162",
   "metadata": {},
   "source": [
    "## 11. TIME-BASED PATROL CLASSIFICATION (Using Minute-Level Timestamps)\n",
    "\n",
    "Use temporal proximity to classify patrol types:\n",
    "- **Fixed Camera**: LPR scans with NO tickets within grace period (5-15 min)\n",
    "- **Vehicle Patrol**: LPR scan followed by ticket within grace period\n",
    "- **Foot Patrol**: Ticket with NO LPR scans nearby in time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c3f50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"=\"*80)\n",
    "print(\"TIME-BASED PATROL CLASSIFICATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load raw data with minute-level timestamps\n",
    "print(\"\\nLoading raw data with timestamps...\")\n",
    "tickets_raw = pd.read_csv('../data/processed/tickets_enriched.csv', parse_dates=['Issue_DateTime'])\n",
    "lpr_raw = pd.read_csv('../data/processed/lpr_enriched.csv', parse_dates=['Date_Time'])\n",
    "\n",
    "print(f\"Tickets: {len(tickets_raw):,} records\")\n",
    "print(f\"LPR scans: {len(lpr_raw):,} records\")\n",
    "\n",
    "# Grace period for linking LPR to tickets (in minutes)\n",
    "GRACE_PERIOD_MIN = 5  # 10 minutes - enforcement typically acts quickly\n",
    "\n",
    "print(f\"\\nGrace period: {GRACE_PERIOD_MIN} minutes\")\n",
    "print(f\"Logic:\")\n",
    "print(f\"  - LPR scan + ticket within {GRACE_PERIOD_MIN} min → Vehicle patrol\")\n",
    "print(f\"  - Ticket + NO LPR within {GRACE_PERIOD_MIN} min → Foot patrol\")\n",
    "print(f\"  - LPR scans + NO tickets within {GRACE_PERIOD_MIN} min → Fixed camera\")\n",
    "\n",
    "# Filter to overlap period only (where both datasets exist)\n",
    "ticket_min = tickets_raw['Issue_DateTime'].min()\n",
    "ticket_max = tickets_raw['Issue_DateTime'].max()\n",
    "lpr_min = lpr_raw['Date_Time'].min()\n",
    "lpr_max = lpr_raw['Date_Time'].max()\n",
    "\n",
    "overlap_start = max(ticket_min, lpr_min)\n",
    "overlap_end = min(ticket_max, lpr_max)\n",
    "\n",
    "print(f\"\\nFiltering to overlap period: {overlap_start} to {overlap_end}\")\n",
    "tickets_raw = tickets_raw[(tickets_raw['Issue_DateTime'] >= overlap_start) & (tickets_raw['Issue_DateTime'] <= overlap_end)]\n",
    "lpr_raw = lpr_raw[(lpr_raw['Date_Time'] >= overlap_start) & (lpr_raw['Date_Time'] <= overlap_end)]\n",
    "\n",
    "print(f\"Tickets in overlap: {len(tickets_raw):,}\")\n",
    "print(f\"LPR scans in overlap: {len(lpr_raw):,}\")\n",
    "\n",
    "# Match by ZONE_NAME not lot number (lot numbers don't align between datasets)\n",
    "# For each ticket, check if there was an LPR scan in the SAME ZONE within grace period BEFORE the ticket\n",
    "print(f\"\\nAnalyzing {len(tickets_raw):,} tickets by ZONE...\")\n",
    "print(\"This may take a few minutes...\")\n",
    "\n",
    "# Sample first 10,000 tickets for testing (remove this for full analysis)\n",
    "tickets_sample = tickets_raw.head(10000).copy()\n",
    "tickets_sample['patrol_type_detailed'] = 'UNKNOWN'\n",
    "tickets_sample['lpr_before_ticket'] = 0\n",
    "tickets_sample['minutes_since_lpr'] = None\n",
    "\n",
    "for idx, ticket in tickets_sample.iterrows():\n",
    "    if idx % 1000 == 0:\n",
    "        print(f\"  Processed {idx:,} / {len(tickets_sample)*10:,} tickets...\")\n",
    "    \n",
    "    zone = ticket['Zone_Name']\n",
    "    ticket_time = ticket['Issue_DateTime']\n",
    "    \n",
    "    # Skip if no zone mapping\n",
    "    if pd.isna(zone):\n",
    "        continue\n",
    "    \n",
    "    # Find LPR scans in same ZONE within grace period BEFORE ticket\n",
    "    lpr_in_zone = lpr_raw[\n",
    "        (lpr_raw['Zone_Name'] == zone) &\n",
    "        (lpr_raw['Date_Time'] <= ticket_time) &\n",
    "        (lpr_raw['Date_Time'] >= ticket_time - pd.Timedelta(minutes=GRACE_PERIOD_MIN))\n",
    "    ]\n",
    "    \n",
    "    if len(lpr_in_zone) > 0:\n",
    "        # Vehicle patrol: LPR scan found before ticket\n",
    "        tickets_sample.at[idx, 'patrol_type_detailed'] = 'VEHICLE_PATROL'\n",
    "        tickets_sample.at[idx, 'lpr_before_ticket'] = 1\n",
    "        # Calculate time since most recent LPR scan\n",
    "        most_recent_lpr = lpr_in_zone['Date_Time'].max()\n",
    "        minutes_diff = (ticket_time - most_recent_lpr).total_seconds() / 60\n",
    "        tickets_sample.at[idx, 'minutes_since_lpr'] = minutes_diff\n",
    "    else:\n",
    "        # Foot patrol: No LPR scan found before ticket\n",
    "        tickets_sample.at[idx, 'patrol_type_detailed'] = 'FOOT_PATROL'\n",
    "        tickets_sample.at[idx, 'lpr_before_ticket'] = 0\n",
    "\n",
    "print(\"\\nClassification complete!\")\n",
    "\n",
    "# Summary statistics\n",
    "vehicle_patrol_count = (tickets_sample['patrol_type_detailed'] == 'VEHICLE_PATROL').sum()\n",
    "foot_patrol_count = (tickets_sample['patrol_type_detailed'] == 'FOOT_PATROL').sum()\n",
    "total = len(tickets_sample)\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"PATROL TYPE CLASSIFICATION RESULTS (Sample: {total:,} tickets)\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Vehicle patrol: {vehicle_patrol_count:,} ({vehicle_patrol_count/total*100:.1f}%)\")\n",
    "print(f\"  - Had LPR scan in same lot within {GRACE_PERIOD_MIN} min before ticket\")\n",
    "print(f\"Foot patrol: {foot_patrol_count:,} ({foot_patrol_count/total*100:.1f}%)\")\n",
    "print(f\"  - NO LPR scan in same lot within {GRACE_PERIOD_MIN} min before ticket\")\n",
    "\n",
    "# Time distribution for vehicle patrol tickets\n",
    "vehicle_tickets = tickets_sample[tickets_sample['patrol_type_detailed'] == 'VEHICLE_PATROL']\n",
    "if len(vehicle_tickets) > 0:\n",
    "    print(f\"\\nVehicle patrol timing:\")\n",
    "    print(f\"  Average time from LPR to ticket: {vehicle_tickets['minutes_since_lpr'].mean():.1f} minutes\")\n",
    "    print(f\"  Median: {vehicle_tickets['minutes_since_lpr'].median():.1f} minutes\")\n",
    "    print(f\"  Min: {vehicle_tickets['minutes_since_lpr'].min():.1f} minutes\")\n",
    "    print(f\"  Max: {vehicle_tickets['minutes_since_lpr'].max():.1f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23d7880",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"=\"*80)\n",
    "print(\"PATROL TYPE CLASSIFICATION - FIXED CAMERA DETECTION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Step 1: Identify zones with FIXED CAMERAS\n",
    "# Fixed cameras have consistent LPR activity (high % of hours with scans)\n",
    "zone_lpr_stats = enforcement.groupby('Zone').agg({\n",
    "    'lpr_scans': 'count',\n",
    "    'tickets_issued': 'sum'\n",
    "})\n",
    "zone_lpr_stats.columns = ['total_hours', 'total_tickets']\n",
    "\n",
    "# Count hours with LPR activity per zone\n",
    "zone_lpr_active = enforcement[enforcement['lpr_scans'] > 0].groupby('Zone').size()\n",
    "zone_lpr_stats['hours_with_lpr'] = zone_lpr_active\n",
    "zone_lpr_stats['pct_hours_with_lpr'] = (zone_lpr_stats['hours_with_lpr'] / zone_lpr_stats['total_hours'] * 100).fillna(0)\n",
    "\n",
    "# FIXED CAMERA THRESHOLD: >50% of hours have LPR activity\n",
    "# This indicates entrance/exit cameras, not mobile patrols\n",
    "FIXED_CAMERA_THRESHOLD = 50.0\n",
    "fixed_camera_zones = zone_lpr_stats[zone_lpr_stats['pct_hours_with_lpr'] > FIXED_CAMERA_THRESHOLD].index.tolist()\n",
    "\n",
    "print(f\"\\n FIXED CAMERA ZONES IDENTIFIED:\")\n",
    "print(f\"   Threshold: >{FIXED_CAMERA_THRESHOLD}% of hours with LPR activity\")\n",
    "print(f\"   Zones with fixed cameras: {len(fixed_camera_zones)}\")\n",
    "for zone in fixed_camera_zones:\n",
    "    pct = zone_lpr_stats.loc[zone, 'pct_hours_with_lpr']\n",
    "    tickets = zone_lpr_stats.loc[zone, 'total_tickets']\n",
    "    print(f\"     - {zone}: {pct:.1f}% hours with LPR, {tickets:,} tickets\")\n",
    "\n",
    "print(f\"\\n⚠️  CLASSIFICATION LIMITATION:\")\n",
    "print(f\"   For zones WITHOUT fixed cameras (lots 071, 150, 084, etc.):\")\n",
    "print(f\"   - LPR scans could be from patrol vehicle passing through\")\n",
    "print(f\"   - Tickets could be from foot patrol at a different time\")\n",
    "print(f\"   - We CANNOT reliably link LPR scans to ticket enforcement\")\n",
    "print(f\"   → Patrol type classification is NOT RELIABLE for these zones\")\n",
    "\n",
    "# Step 2: Classification\n",
    "# Fixed camera zones: ALL tickets are foot patrol (LPR is just entrance camera)\n",
    "# Other zones: UNKNOWN (cannot determine patrol type reliably)\n",
    "\n",
    "enforcement['has_fixed_camera'] = enforcement['Zone'].isin(fixed_camera_zones).astype(int)\n",
    "\n",
    "# For fixed camera zones: tickets are foot patrol\n",
    "# For other zones: mark as UNKNOWN\n",
    "enforcement['patrol_type'] = 'UNKNOWN'\n",
    "enforcement.loc[\n",
    "    (enforcement['tickets_issued'] > 0) & \n",
    "    (enforcement['has_fixed_camera'] == 1),\n",
    "    'patrol_type'\n",
    "] = 'FOOT_PATROL'\n",
    "\n",
    "enforcement['foot_patrol_tickets'] = np.where(\n",
    "    enforcement['patrol_type'] == 'FOOT_PATROL',\n",
    "    enforcement['tickets_issued'],\n",
    "    0\n",
    ")\n",
    "\n",
    "enforcement['unknown_patrol_tickets'] = np.where(\n",
    "    (enforcement['tickets_issued'] > 0) & (enforcement['patrol_type'] == 'UNKNOWN'),\n",
    "    enforcement['tickets_issued'],\n",
    "    0\n",
    ")\n",
    "\n",
    "# Summary\n",
    "foot_total = enforcement['foot_patrol_tickets'].sum()\n",
    "unknown_total = enforcement['unknown_patrol_tickets'].sum()\n",
    "total_tickets = enforcement['tickets_issued'].sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced9e839",
   "metadata": {},
   "source": [
    "## 10. Foot Patrol vs Vehicle Patrol Analysis\n",
    "\n",
    "Separate enforcement by patrol type to better understand weather impact."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b969c85",
   "metadata": {},
   "source": [
    "## 8. Weather Impact on Enforcement\n",
    "\n",
    "Does bad weather reduce enforcement activity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af036f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'temperature' in enforcement.columns:\n",
    "    weather_data = enforcement[enforcement['temperature'].notna()]\n",
    "    \n",
    "    # Only analyze reliable foot patrol data (fixed camera zones)\n",
    "    foot_patrol = weather_data[weather_data['patrol_type'] == 'FOOT_PATROL']\n",
    "    \n",
    "    if len(foot_patrol) > 0:\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "        \n",
    "        # 1. Temperature bins for foot patrol\n",
    "        temp_bins = range(int(weather_data['temperature'].min()), int(weather_data['temperature'].max())+5, 5)\n",
    "        \n",
    "        # Foot patrol temperature - use ticket counts\n",
    "        foot_temp_sum = foot_patrol.groupby(pd.cut(foot_patrol['temperature'], bins=temp_bins))['foot_patrol_tickets'].sum()\n",
    "        foot_temp_hours = foot_patrol.groupby(pd.cut(foot_patrol['temperature'], bins=temp_bins)).size()\n",
    "        foot_temp_avg = foot_temp_sum / foot_temp_hours\n",
    "        foot_temp_avg.plot(kind='line', ax=axes[0,0], marker='o', color='blue', linewidth=2, label='Foot Patrol (Fixed Camera Zones)')\n",
    "        \n",
    "        axes[0,0].set_xlabel('Temperature (°F)')\n",
    "        axes[0,0].set_ylabel('Average Tickets per Hour')\n",
    "        axes[0,0].set_title('Foot Patrol: Temperature Impact', fontweight='bold')\n",
    "        axes[0,0].legend()\n",
    "        axes[0,0].grid(alpha=0.3)\n",
    "        \n",
    "        # 2. Precipitation comparison\n",
    "        foot_precip_sum = foot_patrol.groupby('precip_category')['foot_patrol_tickets'].sum()\n",
    "        foot_precip_hours = foot_patrol.groupby('precip_category').size()\n",
    "        foot_precip_avg = foot_precip_sum / foot_precip_hours\n",
    "        \n",
    "        foot_precip_avg.plot(kind='bar', ax=axes[0,1], color='blue', alpha=0.7)\n",
    "        axes[0,1].set_xlabel('Precipitation Level')\n",
    "        axes[0,1].set_ylabel('Average Tickets per Hour')\n",
    "        axes[0,1].set_title('Foot Patrol: Precipitation Impact', fontweight='bold')\n",
    "        axes[0,1].tick_params(axis='x', rotation=45)\n",
    "        axes[0,1].grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        # 3. Scatter: Temperature vs tickets for foot patrol\n",
    "        axes[1,0].scatter(foot_patrol['temperature'], foot_patrol['foot_patrol_tickets'], \n",
    "                         alpha=0.3, s=20, c='blue', label='Foot Patrol')\n",
    "        axes[1,0].set_xlabel('Temperature (°F)')\n",
    "        axes[1,0].set_ylabel('Tickets Issued')\n",
    "        axes[1,0].set_title('Foot Patrol: Temperature Sensitivity', fontweight='bold')\n",
    "        \n",
    "        # Add trend line\n",
    "        if len(foot_patrol) > 10:\n",
    "            z = np.polyfit(foot_patrol['temperature'], foot_patrol['foot_patrol_tickets'], 1)\n",
    "            p = np.poly1d(z)\n",
    "            axes[1,0].plot(sorted(foot_patrol['temperature']), p(sorted(foot_patrol['temperature'])), \n",
    "                          \"r--\", alpha=0.8, linewidth=2, label=f'Trend (slope={z[0]:.3f})')\n",
    "        axes[1,0].legend()\n",
    "        axes[1,0].grid(alpha=0.3)\n",
    "        \n",
    "        # 4. Info text about data limitation\n",
    "        axes[1,1].text(0.5, 0.5, \n",
    "                      f'FOOT PATROL ANALYSIS\\n\\n'\n",
    "                      f'Fixed Camera Zones Only:\\n{\", \".join(fixed_camera_zones)}\\n\\n'\n",
    "                      f'Total Hours: {len(foot_patrol):,}\\n'\n",
    "                      f'Total Tickets: {foot_patrol[\"foot_patrol_tickets\"].sum():,}\\n\\n'\n",
    "                      f'⚠️ Unknown patrol zones\\n'\n",
    "                      f'excluded from analysis\\n'\n",
    "                      f'(cannot determine patrol type)', \n",
    "                      ha='center', va='center', fontsize=12, \n",
    "                      bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "        axes[1,1].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('../data/processed/foot_patrol_weather_impact.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"Foot patrol weather impact visualization saved!\")\n",
    "    else:\n",
    "        print(\"Not enough foot patrol data for visualization\")\n",
    "else:\n",
    "    print(\"Weather data not available for visualization\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58494e48",
   "metadata": {},
   "source": [
    "## 12. Visualize Patrol Type Weather Impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfc4e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'temperature' in enforcement.columns:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"WEATHER IMPACT ON FOOT PATROL (FIXED CAMERA ZONES ONLY)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    weather_data = enforcement[enforcement['temperature'].notna()]\n",
    "    \n",
    "    # Only analyze RELIABLE foot patrol data (fixed camera zones)\n",
    "    foot_patrol = weather_data[weather_data['patrol_type'] == 'FOOT_PATROL']\n",
    "    \n",
    "    print(f\"\\nAnalyzing {len(foot_patrol):,} hours from fixed camera zones\")\n",
    "    print(f\"Total tickets in analysis: {foot_patrol['foot_patrol_tickets'].sum():,}\")\n",
    "    print(f\"Fixed camera zones: {', '.join(fixed_camera_zones)}\")\n",
    "    \n",
    "    if len(foot_patrol) > 0:\n",
    "        print(\"\\n\" + \"-\"*80)\n",
    "        print(\"FOOT PATROL - Temperature Analysis\")\n",
    "        print(\"-\"*80)\n",
    "        \n",
    "        foot_temp = foot_patrol.groupby('temp_category').agg({\n",
    "            'foot_patrol_tickets': ['sum', 'mean'],\n",
    "            'tickets_issued': 'sum'\n",
    "        }).round(3)\n",
    "        foot_temp.columns = ['Total_Tickets', 'Avg_per_Hour', 'Hours_Active']\n",
    "        print(foot_temp)\n",
    "        \n",
    "        # Correlation\n",
    "        temp_corr_foot = foot_patrol['temperature'].corr(foot_patrol['foot_patrol_tickets'])\n",
    "        print(f\"\\nTemperature → Foot patrol tickets correlation: {temp_corr_foot:.3f}\")\n",
    "        \n",
    "        print(\"\\n\" + \"-\"*80)\n",
    "        print(\"FOOT PATROL - Precipitation Analysis\")\n",
    "        print(\"-\"*80)\n",
    "        \n",
    "        foot_precip = foot_patrol.groupby('precip_category').agg({\n",
    "            'foot_patrol_tickets': ['sum', 'mean'],\n",
    "            'tickets_issued': 'sum'\n",
    "        }).round(3)\n",
    "        foot_precip.columns = ['Total_Tickets', 'Avg_per_Hour', 'Hours_Active']\n",
    "        print(foot_precip)\n",
    "        \n",
    "        precip_corr_foot = foot_patrol['precipitation'].corr(foot_patrol['foot_patrol_tickets'])\n",
    "        print(f\"\\nPrecipitation → Foot patrol tickets correlation: {precip_corr_foot:.3f}\")\n",
    "        \n",
    "        # KEY FINDINGS\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"KEY WEATHER INSIGHTS (RELIABLE FOOT PATROL DATA ONLY)\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        print(\"\\n FOOT PATROL in Fixed Camera Zones:\")\n",
    "        if temp_corr_foot < -0.1:\n",
    "            print(f\"  ✓ Strong negative temp correlation ({temp_corr_foot:.3f}) - Less enforcement in cold\")\n",
    "        elif temp_corr_foot > 0.1:\n",
    "            print(f\"  ✓ Positive temp correlation ({temp_corr_foot:.3f}) - More enforcement when warm\")\n",
    "        else:\n",
    "            print(f\"  ~ Minimal temp effect ({temp_corr_foot:.3f})\")\n",
    "        \n",
    "        if precip_corr_foot < -0.1:\n",
    "            print(f\"  ✓ Strong negative precip correlation ({precip_corr_foot:.3f}) - Less enforcement in rain/snow\")\n",
    "        else:\n",
    "            print(f\"  ~ Minimal precip effect ({precip_corr_foot:.3f})\")\n",
    "    else:\n",
    "        print(\"No foot patrol data available for weather analysis\")\n",
    "else:\n",
    "    print(\"Weather data not available for patrol type analysis\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
