{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lot-Level Enforcement Aggregation\n",
    "Recreate enforcement data at **lot number level** instead of zone level.\n",
    "This allows for accurate predictions per individual lot:\n",
    "- Lot 150 (CUE Garage)\n",
    "- Lot 71 (Library Garage)  \n",
    "- Lot 146 (Student Rec Center)\n",
    "- etc.\n",
    "Each lot has different enforcement patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    }
   ],
   "source": "import pandas as pd\nimport numpy as np\nfrom datetime import datetime, timedelta\nimport warnings\nwarnings.filterwarnings('ignore')\nprint(\"Loading data...\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Raw Data with Lot Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tickets: 192,709 records\n",
      "Date range: 2018-07-02 08:13:00 to 2025-10-30 15:56:00\n",
      "Unique lots with tickets: 187\n",
      "\n",
      "LPR scans: 1,780,391 records\n",
      "Date range: 2022-07-01 05:24:26 to 2025-06-30 21:58:49\n",
      "Unique lots in LPR: 185\n",
      "\n",
      "(Note: AMP data unavailable at lot level - using LPR as unpaid proxy)\n"
     ]
    }
   ],
   "source": "# Load tickets with lot numbers\ntickets = pd.read_csv('../../data/processed/tickets_enriched.csv', parse_dates=['Issue_DateTime'])\nprint(f\"Tickets: {len(tickets):,} records\")\nprint(f\"Date range: {tickets['Issue_DateTime'].min()} to {tickets['Issue_DateTime'].max()}\")\nprint(f\"Unique lots with tickets: {tickets['Lot_number'].nunique()}\")\n# Load LPR with lot numbers\nlpr = pd.read_csv('../../data/processed/lpr_enriched.csv', parse_dates=['Date_Time'])\nprint(f\"\\nLPR scans: {len(lpr):,} records\")\nprint(f\"Date range: {lpr['Date_Time'].min()} to {lpr['Date_Time'].max()}\")\nprint(f\"Unique lots in LPR: {lpr['Lot_number'].nunique()}\")\n# Note: AMP data is zone-level only, not lot-level\nprint(f\"\\n(Note: AMP data unavailable at lot level - using LPR as unpaid proxy)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Hourly Date Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 26,304 hourly timestamps\n",
      "\n",
      "Total unique lots: 190\n",
      "Lots: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]...\n"
     ]
    }
   ],
   "source": "# Create hourly date range from July 2022 to June 2025\nstart_date = pd.to_datetime('2022-07-01 00:00:00')\nend_date = pd.to_datetime('2025-06-30 23:00:00')\nhourly_dates = pd.date_range(start=start_date, end=end_date, freq='H')\nprint(f\"Created {len(hourly_dates):,} hourly timestamps\")\n# Get unique lot numbers from tickets and LPR only (AMP doesn't have lot numbers)\ntickets_lots = set(tickets['Lot_number'].dropna().astype(int).unique())\nlpr_lots = set(lpr['Lot_number'].dropna().astype(int).unique())\nall_lots = sorted(tickets_lots | lpr_lots)\nprint(f\"\\nTotal unique lots: {len(all_lots)}\")\nprint(f\"Lots: {all_lots[:20]}...\")  # Show first 20"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate Tickets by Lot + Hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tickets aggregated: 76,981 lot-hour combinations\n",
      "Date range: 2018-07-02 08:00:00 to 2025-10-30 15:00:00\n"
     ]
    }
   ],
   "source": "# Round tickets to hour\ntickets['datetime'] = tickets['Issue_DateTime'].dt.floor('H')\ntickets['date'] = tickets['datetime'].dt.date\n# Aggregate by lot + datetime\ntickets_hourly = tickets.groupby(['Lot_number', 'datetime']).size().reset_index(name='tickets_issued')\nprint(f\"Tickets aggregated: {len(tickets_hourly):,} lot-hour combinations\")\nprint(f\"Date range: {tickets_hourly['datetime'].min()} to {tickets_hourly['datetime'].max()}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate LPR by Lot + Hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LPR aggregated: 76,550 lot-hour combinations\n",
      "Date range: 2022-07-01 05:00:00 to 2025-06-30 21:00:00\n"
     ]
    }
   ],
   "source": "# Round LPR to hour\nlpr['datetime'] = lpr['Date_Time'].dt.floor('H')\nlpr['date'] = lpr['datetime'].dt.date\n# Aggregate by lot + datetime\nlpr_hourly = lpr.groupby(['Lot_number', 'datetime']).size().reset_index(name='lpr_scans')\nprint(f\"LPR aggregated: {len(lpr_hourly):,} lot-hour combinations\")\nprint(f\"Date range: {lpr_hourly['datetime'].min()} to {lpr_hourly['datetime'].max()}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skip AMP Aggregation\n",
    "AMP data is zone-level only and doesn't have lot numbers. We'll set amp_sessions to 0 and use LPR as proxy for unpaid estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping AMP aggregation (zone-level data only)\n",
      "Will use LPR as proxy for unpaid estimate\n"
     ]
    }
   ],
   "source": [
    "# Skip AMP aggregation - not available at lot level\n",
    "print(\"Skipping AMP aggregation (zone-level data only)\")\n",
    "print(\"Will use LPR as proxy for unpaid estimate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge All Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full grid: 4,997,760 lot-hour combinations\n",
      "\n",
      "Merged data: 4,997,760 records\n",
      "Columns: ['Lot_number', 'datetime', 'lpr_scans', 'tickets_issued', 'amp_sessions']\n"
     ]
    }
   ],
   "source": "# Create full grid of lot + hour combinations\nlot_hour_grid = pd.MultiIndex.from_product(\n    [all_lots, hourly_dates],\n    names=['Lot_number', 'datetime']\n).to_frame(index=False)\nprint(f\"Full grid: {len(lot_hour_grid):,} lot-hour combinations\")\n# Merge data (LPR and tickets only, no AMP at lot level)\nenforcement_lot = lot_hour_grid.copy()\nenforcement_lot = enforcement_lot.merge(\n    lpr_hourly,\n    on=['Lot_number', 'datetime'],\n    how='left'\n).merge(\n    tickets_hourly,\n    on=['Lot_number', 'datetime'],\n    how='left'\n)\n# Fill NaN with 0\nenforcement_lot['lpr_scans'] = enforcement_lot['lpr_scans'].fillna(0).astype(int)\nenforcement_lot['amp_sessions'] = 0  # Not available at lot level\nenforcement_lot['tickets_issued'] = enforcement_lot['tickets_issued'].fillna(0).astype(int)\nprint(f\"\\nMerged data: {len(enforcement_lot):,} records\")\nprint(f\"Columns: {list(enforcement_lot.columns)}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Enforcement Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated enforcement metrics\n",
      "\n",
      "Summary:\n",
      "          lpr_scans  amp_sessions  tickets_issued  unpaid_estimate  \\\n",
      "count  4.997760e+06     4997760.0    4.997760e+06     4.997760e+06   \n",
      "mean   3.562378e-01           0.0    1.868197e-02     3.562378e-01   \n",
      "std    5.681619e+00           0.0    3.144816e-01     5.681619e+00   \n",
      "min    0.000000e+00           0.0    0.000000e+00     0.000000e+00   \n",
      "25%    0.000000e+00           0.0    0.000000e+00     0.000000e+00   \n",
      "50%    0.000000e+00           0.0    0.000000e+00     0.000000e+00   \n",
      "75%    0.000000e+00           0.0    0.000000e+00     0.000000e+00   \n",
      "max    6.660000e+02           0.0    4.900000e+01     6.660000e+02   \n",
      "\n",
      "       enforcement_rate  \n",
      "count      4.997760e+06  \n",
      "mean       1.245646e-03  \n",
      "std        4.083554e-02  \n",
      "min        0.000000e+00  \n",
      "25%        0.000000e+00  \n",
      "50%        0.000000e+00  \n",
      "75%        0.000000e+00  \n",
      "max        2.000000e+01  \n"
     ]
    }
   ],
   "source": "# Since AMP not available at lot level, use LPR as proxy for total vehicles\n# Unpaid estimate = LPR scans (assume all LPR vehicles are potential violators)\nenforcement_lot['unpaid_estimate'] = enforcement_lot['lpr_scans']\n# Enforcement rate: tickets / unpaid vehicles (when unpaid > 0)\nenforcement_lot['enforcement_rate'] = 0.0\nmask = enforcement_lot['lpr_scans'] > 0\nenforcement_lot.loc[mask, 'enforcement_rate'] = (\n    enforcement_lot.loc[mask, 'tickets_issued'] / enforcement_lot.loc[mask, 'lpr_scans']\n)\n# Flag for estimated LPR (will be True for July-Oct 2025)\nenforcement_lot['lpr_estimated'] = False\nprint(\"Calculated enforcement metrics\")\nprint(f\"\\nSummary:\")\nprint(enforcement_lot[['lpr_scans', 'amp_sessions', 'tickets_issued', 'unpaid_estimate', 'enforcement_rate']].describe())"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Temporal Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added temporal features\n"
     ]
    }
   ],
   "source": "enforcement_lot['date'] = enforcement_lot['datetime'].dt.date\nenforcement_lot['hour'] = enforcement_lot['datetime'].dt.hour\nenforcement_lot['year'] = enforcement_lot['datetime'].dt.year\nenforcement_lot['month'] = enforcement_lot['datetime'].dt.month\nenforcement_lot['day_of_week'] = enforcement_lot['datetime'].dt.dayofweek\nenforcement_lot['is_weekend'] = (enforcement_lot['day_of_week'] >= 5).astype(int)\nprint(\"Added temporal features\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Contextual Features (Calendar, Weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged weather data\n",
      "Added calendar features\n"
     ]
    }
   ],
   "source": "# Load contextual data\ncalendar = pd.read_csv('../../data/academic_calendar.csv', parse_dates=['Start_Date', 'End_Date'])\ngames = pd.read_csv('../../data/football_games.csv', parse_dates=['Date'])\nweather = pd.read_csv('../../data/weather_pullman_hourly_2020_2025.csv', parse_dates=['datetime'])\n# Merge weather\nenforcement_lot = enforcement_lot.merge(\n    weather[['datetime', 'temperature_f', 'precipitation_inches', 'snowfall_inches', \n             'snow_depth_inches', 'wind_mph', 'weather_code', 'weather_category',\n             'is_rainy', 'is_snowy', 'is_cold', 'is_hot', 'is_windy', 'is_severe']],\n    on='datetime',\n    how='left'\n)\nprint(f\"Merged weather data\")\n# Add calendar features\nenforcement_lot['is_game_day'] = 0\nenforcement_lot['is_dead_week'] = 0\nenforcement_lot['is_finals_week'] = 0\nenforcement_lot['is_spring_break'] = 0\nenforcement_lot['is_thanksgiving_break'] = 0\nenforcement_lot['is_winter_break'] = 0\nenforcement_lot['is_any_break'] = 0\nfor _, event in calendar.iterrows():\n    mask = (enforcement_lot['date'] >= event['Start_Date'].date()) & (enforcement_lot['date'] <= event['End_Date'].date())\n    if 'Dead Week' in event['Event_Type']:\n        enforcement_lot.loc[mask, 'is_dead_week'] = 1\n    elif 'Finals Week' in event['Event_Type']:\n        enforcement_lot.loc[mask, 'is_finals_week'] = 1\n    elif 'Spring Break' in event['Event_Type']:\n        enforcement_lot.loc[mask, 'is_spring_break'] = 1\n        enforcement_lot.loc[mask, 'is_any_break'] = 1\n    elif 'Thanksgiving' in event['Event_Type']:\n        enforcement_lot.loc[mask, 'is_thanksgiving_break'] = 1\n        enforcement_lot.loc[mask, 'is_any_break'] = 1\n    elif 'Winter Break' in event['Event_Type']:\n        enforcement_lot.loc[mask, 'is_winter_break'] = 1\n        enforcement_lot.loc[mask, 'is_any_break'] = 1\n# Game days\ngame_dates = games['Date'].dt.date.unique()\nenforcement_lot.loc[enforcement_lot['date'].isin(game_dates), 'is_game_day'] = 1\nprint(\"Added calendar features\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Time of Day Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added time of day categories\n"
     ]
    }
   ],
   "source": "def categorize_time_of_day(hour):\n    if 6 <= hour < 12:\n        return 'Morning'\n    elif 12 <= hour < 17:\n        return 'Afternoon'\n    elif 17 <= hour < 21:\n        return 'Evening'\n    elif 21 <= hour < 24:\n        return 'Night'\n    else:\n        return 'Late Night'\nenforcement_lot['time_of_day'] = enforcement_lot['hour'].apply(categorize_time_of_day)\ntime_map = {'Afternoon': 0, 'Evening': 1, 'Late Night': 2, 'Morning': 3, 'Night': 4}\nenforcement_lot['time_of_day_code'] = enforcement_lot['time_of_day'].map(time_map)\nprint(\"Added time of day categories\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save July 2022 - June 2025 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data 2022-2025: 4,993,390 records\n",
      "Unique lots: 190\n",
      "Date range: 2022-07-01 00:00:00 to 2025-06-30 00:00:00\n",
      "\n",
      "Saved: ../../data/processed/enforcement_lot_level.csv\n"
     ]
    }
   ],
   "source": "# Filter to actual LPR date range (July 2022 - June 2025)\nenforcement_2022_2025 = enforcement_lot[\n    (enforcement_lot['datetime'] >= '2022-07-01') &\n    (enforcement_lot['datetime'] <= '2025-06-30')\n].copy()\nprint(f\"\\nData 2022-2025: {len(enforcement_2022_2025):,} records\")\nprint(f\"Unique lots: {enforcement_2022_2025['Lot_number'].nunique()}\")\nprint(f\"Date range: {enforcement_2022_2025['datetime'].min()} to {enforcement_2022_2025['datetime'].max()}\")\n# Save\noutput_file = '../../data/processed/enforcement_lot_level.csv'\nenforcement_2022_2025.to_csv(output_file, index=False)\nprint(f\"\\nSaved: {output_file}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extend to October 2025\n",
    "Estimate LPR scans for July-October 2025 using historical patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Historical LPR patterns: 383,040 lot-day-hour-month combinations\n",
      "Patterns per lot: count     190.0\n",
      "mean     2016.0\n",
      "std         0.0\n",
      "min      2016.0\n",
      "25%      2016.0\n",
      "50%      2016.0\n",
      "75%      2016.0\n",
      "max      2016.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": "# Calculate historical LPR patterns by lot-day-hour-month\nlpr_historical = enforcement_2022_2025[\n    (enforcement_2022_2025['datetime'] >= '2022-07-01') &\n    (enforcement_2022_2025['datetime'] <= '2024-12-31')\n].copy()\nlpr_patterns = lpr_historical.groupby(['Lot_number', 'day_of_week', 'hour', 'month']).agg({\n    'lpr_scans': 'mean',\n    'date': 'nunique'\n}).reset_index()\nlpr_patterns.columns = ['Lot_number', 'day_of_week', 'hour', 'month', 'avg_lpr_scans', 'num_dates']\n# Only use patterns with at least 2 occurrences\nlpr_patterns = lpr_patterns[lpr_patterns['num_dates'] >= 2]\nprint(f\"Historical LPR patterns: {len(lpr_patterns):,} lot-day-hour-month combinations\")\nprint(f\"Patterns per lot: {lpr_patterns.groupby('Lot_number').size().describe()}\")"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "July-Oct 2025 before estimation: 0 records\n",
      "\n",
      "Estimated LPR for 0 lot-hours (nan%)\n",
      "Total LPR scans July-Oct 2025: 0\n",
      "Total tickets July-Oct 2025: 0\n"
     ]
    }
   ],
   "source": "# Create July-October 2025 data\njuly_oct_2025 = enforcement_lot[\n    (enforcement_lot['datetime'] >= '2025-07-01') &\n    (enforcement_lot['datetime'] <= '2025-10-30')\n].copy()\nprint(f\"July-Oct 2025 before estimation: {len(july_oct_2025):,} records\")\n# Merge with historical patterns\njuly_oct_2025 = july_oct_2025.merge(\n    lpr_patterns[['Lot_number', 'day_of_week', 'hour', 'month', 'avg_lpr_scans']],\n    on=['Lot_number', 'day_of_week', 'hour', 'month'],\n    how='left'\n)\n# Use estimated LPR where we have patterns\nhas_pattern = july_oct_2025['avg_lpr_scans'].notna()\njuly_oct_2025.loc[has_pattern, 'lpr_scans'] = july_oct_2025.loc[has_pattern, 'avg_lpr_scans'].round().astype(int)\njuly_oct_2025.loc[has_pattern, 'lpr_estimated'] = True\n# Recalculate unpaid estimate and enforcement rate (using LPR as proxy)\njuly_oct_2025['unpaid_estimate'] = july_oct_2025['lpr_scans']\njuly_oct_2025['enforcement_rate'] = 0.0\nmask = july_oct_2025['lpr_scans'] > 0\njuly_oct_2025.loc[mask, 'enforcement_rate'] = (\n    july_oct_2025.loc[mask, 'tickets_issued'] / july_oct_2025.loc[mask, 'lpr_scans']\n)\njuly_oct_2025 = july_oct_2025.drop('avg_lpr_scans', axis=1)\nestimated_count = july_oct_2025['lpr_estimated'].sum()\nprint(f\"\\nEstimated LPR for {estimated_count:,} lot-hours ({estimated_count/len(july_oct_2025)*100:.1f}%)\")\nprint(f\"Total LPR scans July-Oct 2025: {july_oct_2025['lpr_scans'].sum():,}\")\nprint(f\"Total tickets July-Oct 2025: {july_oct_2025['tickets_issued'].sum():,}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine and Save Full Extended Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Full extended dataset: 4,993,390 records\n",
      "Unique lots: 190\n",
      "Date range: 2022-07-01 00:00:00 to 2025-06-30 00:00:00\n",
      "\n",
      "Records by year:\n",
      "  2022: 839,040 records\n",
      "  2023: 1,664,400 records\n",
      "  2024: 1,668,960 records\n",
      "  2025: 820,990 records\n",
      "\n",
      "Saved: ../../data/processed/enforcement_lot_level_extended.csv\n"
     ]
    }
   ],
   "source": "# Combine 2022-2025 with July-Oct 2025 extended\nenforcement_full_extended = pd.concat([\n    enforcement_2022_2025,\n    july_oct_2025\n], ignore_index=True)\n# Sort by lot and datetime\nenforcement_full_extended = enforcement_full_extended.sort_values(['Lot_number', 'datetime'])\nprint(f\"\\nFull extended dataset: {len(enforcement_full_extended):,} records\")\nprint(f\"Unique lots: {enforcement_full_extended['Lot_number'].nunique()}\")\nprint(f\"Date range: {enforcement_full_extended['datetime'].min()} to {enforcement_full_extended['datetime'].max()}\")\nprint(f\"\\nRecords by year:\")\nfor year in sorted(enforcement_full_extended['year'].unique()):\n    count = len(enforcement_full_extended[enforcement_full_extended['year'] == year])\n    print(f\"  {year}: {count:,} records\")\n# Save\noutput_file_extended = '../../data/processed/enforcement_lot_level_extended.csv'\nenforcement_full_extended.to_csv(output_file_extended, index=False)\nprint(f\"\\nSaved: {output_file_extended}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample of Lot-Specific Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lot 150 - CUE Garage:\n",
      "  Total tickets: 14,258\n",
      "  Total LPR scans: 179,315\n",
      "  Hours with enforcement: 3,556 (13.5%)\n",
      "  Monday 11 AM enforcement rate: 51.3%\n",
      "\n",
      "Lot 71 - Library Garage:\n",
      "  Total tickets: 13,418\n",
      "  Total LPR scans: 120,700\n",
      "  Hours with enforcement: 3,473 (13.2%)\n",
      "  Monday 11 AM enforcement rate: 48.1%\n",
      "\n",
      "Lot 146 - Student Rec Center:\n",
      "  Total tickets: 6,137\n",
      "  Total LPR scans: 88,426\n",
      "  Hours with enforcement: 1,054 (4.0%)\n",
      "  Monday 11 AM enforcement rate: 11.5%\n"
     ]
    }
   ],
   "source": "# Show enforcement patterns for key paid lots\nkey_lots = [150, 71, 146]  # CUE Garage, Library Garage, Student Rec Center\nlot_names = {150: 'CUE Garage', 71: 'Library Garage', 146: 'Student Rec Center'}\nfor lot in key_lots:\n    if lot not in enforcement_full_extended['Lot_number'].values:\n        continue\n    lot_data = enforcement_full_extended[enforcement_full_extended['Lot_number'] == lot]\n    tickets_total = lot_data['tickets_issued'].sum()\n    lpr_total = lot_data['lpr_scans'].sum()\n    hours_with_tickets = (lot_data['tickets_issued'] > 0).sum()\n    print(f\"\\nLot {lot} - {lot_names.get(lot, 'Unknown')}:\")\n    print(f\"  Total tickets: {tickets_total:,}\")\n    print(f\"  Total LPR scans: {lpr_total:,}\")\n    print(f\"  Hours with enforcement: {hours_with_tickets:,} ({hours_with_tickets/len(lot_data)*100:.1f}%)\")\n    # Check Monday 11 AM pattern\n    monday_11am = lot_data[(lot_data['day_of_week'] == 0) & (lot_data['hour'] == 11)]\n    if len(monday_11am) > 0:\n        enf_rate = (monday_11am['tickets_issued'] > 0).mean()\n        print(f\"  Monday 11 AM enforcement rate: {enf_rate*100:.1f}%\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "Created lot-level enforcement data:\n",
    "- Each lot has separate hourly records\n",
    "- Includes tickets, LPR scans, AMP sessions per lot\n",
    "- Extended through October 2025\n",
    "- Ready for lot-specific predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}